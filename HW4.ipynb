{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371232H/PL_Repo/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW4\n",
        "## 1. çˆ¬èŸ²è³‡æ–™æ”¶é›†èˆ‡å­˜å„²\n",
        "æŠ“å– PTT é›»å½±ç‰ˆæ–‡ç« çš„æ¨™é¡Œã€ä½œè€…ã€æ—¥æœŸèˆ‡é€£çµ\n",
        "è³‡æ–™è‡ªå‹•å¯«å…¥ Google Sheetï¼ˆã€Œçˆ¬èŸ²è³‡æ–™ã€å·¥ä½œè¡¨ï¼‰\n",
        "å¯è¨­å®šèµ·å§‹é èˆ‡æŠ“å–é æ•¸ï¼Œé¿å…çˆ¬å–éå¤šè³‡æ–™å°è‡´å»¶é²\n",
        "\n",
        "## 2. è©é »èˆ‡é—œéµè©çµ±è¨ˆ\n",
        "å¾ Google Sheet è®€å–çˆ¬å–è³‡æ–™\n",
        "ä½¿ç”¨ jieba ä¸­æ–‡åˆ†è©\n",
        "è¨ˆç®—æ¯å€‹è©çš„ TF-IDF å¹³å‡æ¬Šé‡\n",
        "æ”¯æ´åœç”¨è©éæ¿¾ï¼Œæ’é™¤é«˜é »ç„¡æ„ç¾©è©\n",
        "å‰ N ç†±é–€è©çµæœè‡ªå‹•å›å¯« Google Sheetï¼ˆã€Œé—œéµè©çµ±è¨ˆã€å·¥ä½œè¡¨ï¼‰\n",
        "\n",
        "## 3. AI æ´å¯Ÿç”Ÿæˆ\n",
        "ä½¿ç”¨ Google Gemini æ¨¡å‹ï¼ˆå¦‚ gemini-2.0-flashï¼‰ç”Ÿæˆåˆ†ææ‘˜è¦\n",
        "çµ±ä¸€ç”¢ç”Ÿ 5 å¥æ´å¯Ÿæ‘˜è¦ + ä¸€æ®µ 120 å­—çµè«–\n",
        "API Key å¯åœ¨åŸ·è¡Œæ™‚å‹•æ…‹è¼¸å…¥ï¼Œä¿è­·å®‰å…¨æ€§\n",
        "\n",
        "## 4. Gradio ä»‹é¢\n",
        "åˆ†é  1ï¼šçˆ¬èŸ²èˆ‡è³‡æ–™é¡¯ç¤ºï¼Œé¡¯ç¤ºæŠ“å–çš„æ–‡ç« è³‡æ–™ï¼Œå¯è¨­å®šèµ·å§‹é èˆ‡æŠ“å–é æ•¸\n",
        "åˆ†é  2ï¼šç†±é–€è©çµ±è¨ˆï¼Œé¸æ“‡å‰ N åç†±é–€è©ï¼Œé¡¯ç¤º TF-IDF çµ±è¨ˆçµæœ\n",
        "åˆ†é  3ï¼šAI æ´å¯Ÿèˆ‡çµè«–ï¼Œè¼¸å…¥ API Key ä¸¦ç”Ÿæˆåˆ†ææ‘˜è¦èˆ‡çµè«–ï¼Œä¸€éµæ“ä½œï¼Œç›´è¦ºå¼ä»‹é¢ï¼Œä½¿ç”¨è€…å‹å¥½\n",
        "\n",
        "### è©¦ç®—è¡¨é€£çµ:https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit?gid=742427183#gid=742427183"
      ],
      "metadata": {
        "id": "BEBtbDWs0FEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æœ€çµ‚ç¨‹å¼ç¢¼"
      ],
      "metadata": {
        "id": "IRKqkijSz_Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gspread google-auth google-generativeai gradio jieba scikit-learn beautifulsoup4 requests\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¾ Google Sheet æˆæ¬Š\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = 'çˆ¬èŸ²è³‡æ–™'\n",
        "STAT_SHEET_NAME = 'é—œéµè©çµ±è¨ˆ'\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¹ åœç”¨è©\n",
        "# ============================================================\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ•·ï¸ PTT çˆ¬èŸ²\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"âš ï¸ ç„¡æ³•å–å¾—èµ·å§‹é é ç¢¼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“Š Google Sheet æ“ä½œ\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['æ¨™é¡Œ', 'ä½œè€…', 'æ—¥æœŸ', 'é€£çµ'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['è©å½™', 'å¹³å‡ TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§  TF-IDF åˆ†æ\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['æ¨™é¡Œ']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ¤– Gemini API æ´å¯Ÿç”Ÿæˆ\n",
        "# ============================================================\n",
        "def generate_insights(keywords, user_api_key):\n",
        "    if not user_api_key:\n",
        "        return \"âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„ Gemini API Keyã€‚\"\n",
        "\n",
        "    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "    prompt = (\n",
        "        f\"ä»¥ä¸‹æ˜¯ PTT é›»å½±ç‰ˆç†±é–€é—œéµè©ï¼š{', '.join([w for w,_ in keywords])}\\n\"\n",
        "        f\"è«‹ç”¨ä¸­æ–‡ç”Ÿæˆï¼š\\n\"\n",
        "        f\"1. äº”å¥æ´å¯Ÿæ‘˜è¦ï¼ˆæ¯å¥ä»¥ã€Œâ€¢ã€é–‹é ­ï¼‰\\n\"\n",
        "        f\"2. ä¸€æ®µç´„ 120 å­—çš„çµè«–ã€‚\"\n",
        "    )\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": user_api_key}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data, timeout=60)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['candidates'][0]['content']['parts'][0]['text']\n",
        "        else:\n",
        "            return f\"âŒ API éŒ¯èª¤: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ API å‘¼å«å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# âš™ï¸ Gradio å¤šåˆ†é ä»‹é¢ï¼ˆé™åˆ¶çˆ¬èŸ²é æ•¸ï¼‰\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ¬ PTT é›»å½±ç‰ˆ é—œéµè©åˆ†æç³»çµ± (å¤šåˆ†é ä»‹é¢)\")\n",
        "\n",
        "    with gr.Tab(\"çˆ¬èŸ²çµæœ\"):\n",
        "        start_url_input = gr.Textbox(label=\"PTT èµ·å§‹é ç¶²å€\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "        page_slider = gr.Slider(1, 5, value=1, step=1, label=\"çˆ¬å–é æ•¸ï¼ˆå»ºè­° 1ï½3 é ï¼‰\")\n",
        "        run_button = gr.Button(\"ğŸš€ åŸ·è¡Œçˆ¬èŸ²\")\n",
        "        articles_output = gr.Dataframe(headers=[\"æ¨™é¡Œ\", \"ä½œè€…\", \"æ—¥æœŸ\", \"é€£çµ\"], label=\"çˆ¬èŸ²çµæœ\")\n",
        "\n",
        "        def run_crawler(start_url, pages):\n",
        "            gr.Info(f\"é–‹å§‹çˆ¬å– {pages} é è³‡æ–™ï¼Œè«‹ç¨å€™...\")\n",
        "            articles = fetch_ptt_articles(start_url, pages=pages)\n",
        "            if not articles:\n",
        "                return []\n",
        "            write_articles_to_sheet(articles)\n",
        "            data = [[a['title'], a['author'], a['date'], a['href']] for a in articles]\n",
        "            gr.Info(f\"âœ… æˆåŠŸçˆ¬å– {len(data)} ç­†æ–‡ç« ï¼\")\n",
        "            return data\n",
        "\n",
        "        run_button.click(run_crawler, inputs=[start_url_input, page_slider], outputs=articles_output)\n",
        "\n",
        "    with gr.Tab(\"ç†±é–€è©åˆ†æ\"):\n",
        "        top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"ç†±é–€è©å‰ N å\")\n",
        "        run_tfidf_button = gr.Button(\"ğŸ“Š åŸ·è¡Œåˆ†æ\")\n",
        "        keywords_output = gr.Dataframe(headers=[\"è©å½™\", \"å¹³å‡ TF-IDF\"], label=\"TF-IDF çµæœ\")\n",
        "\n",
        "        def run_tfidf(top_n):\n",
        "            gr.Info(\"ğŸ“ˆ æ­£åœ¨é€²è¡Œ TF-IDF åˆ†æ...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"âš ï¸ å°šæœªæœ‰çˆ¬èŸ²è³‡æ–™ï¼Œè«‹å…ˆåˆ°ç¬¬ä¸€é åŸ·è¡Œçˆ¬èŸ²ï¼\")\n",
        "                return []\n",
        "            top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "            write_keywords_to_sheet(top_keywords)\n",
        "            gr.Info(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "            return top_keywords\n",
        "\n",
        "        run_tfidf_button.click(run_tfidf, inputs=top_n_input, outputs=keywords_output)\n",
        "\n",
        "    with gr.Tab(\"AI æ´å¯Ÿæ‘˜è¦\"):\n",
        "        api_key_input = gr.Textbox(label=\"ğŸ”‘ è«‹è¼¸å…¥ä½ çš„ Gemini API Key\", type=\"password\", placeholder=\"AIza æˆ– g- é–‹é ­çš„é‡‘é‘°\")\n",
        "        run_ai_button = gr.Button(\"âœ¨ ç”Ÿæˆæ‘˜è¦\")\n",
        "        ai_output = gr.Textbox(label=\"AI æ´å¯Ÿæ‘˜è¦ + çµè«–\", lines=12)\n",
        "\n",
        "        def run_ai(api_key):\n",
        "            gr.Info(\"ğŸ¤– æ­£åœ¨è«‹æ±‚ Gemini API...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"âš ï¸ å°šæœªæœ‰çˆ¬èŸ²è³‡æ–™ï¼Œè«‹å…ˆåˆ°ç¬¬ä¸€é åŸ·è¡Œçˆ¬èŸ²ï¼\")\n",
        "                return \"âš ï¸ å°šç„¡è³‡æ–™\"\n",
        "            top_keywords = get_top_keywords(records, top_n=10)\n",
        "            insights = generate_insights(top_keywords, api_key)\n",
        "            return insights\n",
        "\n",
        "        run_ai_button.click(run_ai, inputs=api_key_input, outputs=ai_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "WKCn0sqdz4_7",
        "outputId": "50503c11-e4ae-4945-8c99-f6119722162f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a096c38c2fd1acbd3e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a096c38c2fd1acbd3e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ­·ç¨‹è¨˜éŒ„"
      ],
      "metadata": {
        "id": "rFNjM0PFz6O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6m1arRWmGMP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_data = []"
      ],
      "metadata": {
        "id": "thL1I-Qlmrx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}"
      ],
      "metadata": {
        "id": "3XFrT8l1nfld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_previous_page_url(soup):\n",
        "    \"\"\"ç²å–ä¸Šä¸€é  (æ›´æ–°ã€æ›´èˆŠçš„æ–‡ç« ) çš„é€£çµ\"\"\"\n",
        "    # PTT çš„ã€Œä¸Šä¸€é ã€æŒ‰éˆ• HTML çµæ§‹ï¼šdiv class=\"btn-group btn-group-paging\"\n",
        "    paging_div = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if paging_div:\n",
        "        # PTT é é¢æŒ‰éˆ•é †åºï¼šæœ€èˆŠ (0), ä¸Šé  (1), ä¸‹é  (2), æœ€æ–° (3)\n",
        "        # æˆ‘å€‘è¦æ‰¾çš„æ˜¯ã€Œä¸Šä¸€é ã€ (å³æ›´èˆŠçš„æ–‡ç« ) çš„é€£çµï¼Œç´¢å¼•ç‚º 1\n",
        "        prev_button = paging_div.find_all('a')[1]\n",
        "\n",
        "        # æª¢æŸ¥é€£çµæ˜¯å¦æœ‰æ•ˆ (å¦‚æœå·²ç¶“æ˜¯ç¬¬ä¸€é ï¼Œé€£çµæœƒæ˜¯ '#' æˆ–æ²’æœ‰ href)\n",
        "        if 'href' in prev_button.attrs:\n",
        "            return \"https://www.ptt.cc\" + prev_button['href']\n",
        "    return None"
      ],
      "metadata": {
        "id": "48nV4nTVpqhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responseIndex = requests.get(\"https://www.ptt.cc/bbs/movie/index.html\", headers=headers, timeout=5)\n",
        "html_contentIndex = responseIndex.text\n",
        "soupIndex = BeautifulSoup(html_contentIndex, 'html.parser')"
      ],
      "metadata": {
        "id": "jAxIg_mQrxc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_url = get_previous_page_url(soupIndex)"
      ],
      "metadata": {
        "id": "CeLNTFV_puZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n_hTS4QUp3En",
        "outputId": "1ba32296-4321-490f-e4f8-25bd3cce9a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.ptt.cc/bbs/movie/index10818.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_index_split(url):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨å­—ä¸²åˆ†å‰²æ–¹æ³•è§£æé ç¢¼ã€‚\n",
        "\n",
        "    é‚è¼¯ï¼š\n",
        "    1. ä»¥ 'index' åˆ†å‰²ç¶²å€ï¼š['...', '10808.html']\n",
        "    2. å–ç¬¬äºŒå€‹å…ƒç´  ('10808.html')\n",
        "    3. ä»¥ '.html' åˆ†å‰²ï¼š['10808', '']\n",
        "    4. å–ç¬¬ä¸€å€‹å…ƒç´  ('10808')\n",
        "    5. è½‰æ›ç‚ºæ•´æ•¸\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # ç¢ºä¿ç¶²å€ä¸­åŒ…å« 'index' å’Œ '.html'\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except IndexError:\n",
        "        print(\"éŒ¯èª¤: ç¶²å€çµæ§‹ä¸ç¬¦åˆé æœŸ (ç¼ºå°‘ 'index' æˆ– '.html')\")\n",
        "        return None\n",
        "    except ValueError:\n",
        "        print(\"éŒ¯èª¤: æå–åˆ°çš„å…§å®¹ç„¡æ³•è½‰æ›ç‚ºæ•¸å­—\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wsS1sTiRqiVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æŒ‡å®šçš„èµ·å§‹é ç¢¼\n",
        "START_INDEX = extract_index_split(current_url)\n",
        "# æƒ³è¦å–å¾—çš„é æ•¸\n",
        "PAGES_TO_FETCH = 10\n",
        "\n",
        "# PTT åŸºç¤ç¶²å€\n",
        "BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "\n",
        "# è¨ˆç®—è¿´åœˆçš„çµæŸé» (ä¾‹å¦‚: 10808 - 10 + 1 = 10799)\n",
        "# range(start, stop, step) çš„ stop æ˜¯ä¸åŒ…å«çš„ï¼Œæ‰€ä»¥æˆ‘å€‘è¨­ç‚º START_INDEX - PAGES_TO_FETCH\n",
        "stop_index = START_INDEX - PAGES_TO_FETCH\n",
        "\n",
        "print(f\"--- æ­£åœ¨ç”Ÿæˆå¾ {START_INDEX} åˆ° {stop_index + 1} çš„ {PAGES_TO_FETCH} å€‹ç¶²å€ ---\")\n",
        "\n",
        "# ä½¿ç”¨ range è¿´åœˆï¼Œå¾ START_INDEX éæ¸›åˆ° stop_index\n",
        "for index in range(START_INDEX, stop_index, -1):\n",
        "    # çµ„åˆå®Œæ•´çš„ URL\n",
        "    url = f\"{BASE_URL}{index}.html\"\n",
        "    print(url)\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    article_list = soup.find_all('div', class_='r-ent')\n",
        "    for article in article_list:\n",
        "        # æ¨™é¡Œ (Title) å’Œ é€£çµ (Href) è³‡è¨Šé€šå¸¸åœ¨ div class=\"title\" å…§\n",
        "        title_tag = article.find('div', class_='title').find('a')\n",
        "\n",
        "        # æ’é™¤è¢«åˆªé™¤æˆ–ä¸å¯å­˜å–(æ¨™é¡Œç‚º - )çš„æ–‡ç« \n",
        "        if title_tag:\n",
        "            title = title_tag.text.strip()\n",
        "            href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "        else:\n",
        "            # è™•ç†è¢«åˆªé™¤çš„æ–‡ç«  (é€šå¸¸æ¨™é¡Œæœƒæ˜¯ '-')\n",
        "            title = article.find('div', class_='title').text.strip()\n",
        "            href = \"N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)\"\n",
        "\n",
        "        # ä½œè€… (Author) è³‡è¨Šåœ¨ div class=\"author\" å…§\n",
        "        author = article.find('div', class_='author').text.strip()\n",
        "\n",
        "        # æ—¥æœŸ (Date) è³‡è¨Šåœ¨ div class=\"date\" å…§\n",
        "        date = article.find('div', class_='date').text.strip()\n",
        "\n",
        "        # å„²å­˜è³‡æ–™\n",
        "        articles_data.append({\n",
        "            'title': title,\n",
        "            'date': date,\n",
        "            'author': author,\n",
        "            'href': href\n",
        "        })\n",
        "\n",
        "        # é¡å¤–è¦æ±‚ï¼šå¦‚æœæ¨™é¡Œæ˜¯æŒ‡å®šæ¨™é¡Œï¼Œå°å‡ºå…¶å°æ‡‰çš„ href\n",
        "        # å‡è¨­æˆ‘å€‘æŒ‡å®šè¦ç‰¹åˆ¥é—œæ³¨æ¨™é¡ŒåŒ…å« \"æ–°è\" çš„æ–‡ç« \n",
        "        # if 'æ–°è' in title:\n",
        "        #     print(f\"[ç‰¹åˆ¥é—œæ³¨] æ¨™é¡Œï¼š{title} | é€£çµï¼š{href}\")\n",
        "    # è¨»é‡‹: åœ¨å¯¦éš›çš„çˆ¬èŸ²ç¨‹å¼ä¸­ï¼Œæ‚¨æœƒå°‡é€™å€‹ url å‚³éçµ¦ requests.get() å‡½å¼ä¾†ç²å–å…§å®¹\n",
        "    # ä¾‹å¦‚: html_content = requests.get(url, headers=headers, cookies=cookies).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61-di9Q2rBul",
        "outputId": "2feb41a6-a3e2-4df9-ecf7-57e32cbb6ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- æ­£åœ¨ç”Ÿæˆå¾ 10818 åˆ° 10809 çš„ 10 å€‹ç¶²å€ ---\n",
            "https://www.ptt.cc/bbs/movie/index10818.html\n",
            "https://www.ptt.cc/bbs/movie/index10817.html\n",
            "https://www.ptt.cc/bbs/movie/index10816.html\n",
            "https://www.ptt.cc/bbs/movie/index10815.html\n",
            "https://www.ptt.cc/bbs/movie/index10814.html\n",
            "https://www.ptt.cc/bbs/movie/index10813.html\n",
            "https://www.ptt.cc/bbs/movie/index10812.html\n",
            "https://www.ptt.cc/bbs/movie/index10811.html\n",
            "https://www.ptt.cc/bbs/movie/index10810.html\n",
            "https://www.ptt.cc/bbs/movie/index10809.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_data"
      ],
      "metadata": {
        "id": "I4REQvLpwHwE",
        "outputId": "64c9ce1d-8474-4717-e1c6-7fc493938338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': '[å•ç‰‡] ä¸€éƒ¨é›»å½±é–‹é ­æœ‰ç´™éˆ”ä¸Šçš„äººé ­è¬›è©±',\n",
              "  'date': '10/24',\n",
              "  'author': 'wch1995',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761261468.A.9C4.html'},\n",
              " {'title': '[æƒ…å ±] éˆé‹¸äººåŠ‡å ´ç‰ˆè•¾æ½”ç¯‡ çˆ›ç•ªèŒ„100',\n",
              "  'date': '10/24',\n",
              "  'author': 'vestal',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761270564.A.7B9.html'},\n",
              " {'title': '[è¨è«–] å‘¨æ˜Ÿé¦³ç‚ºä½•é€™éº¼æ¬£è³ç¾…å¿—ç¥¥ï¼Ÿ',\n",
              "  'date': '10/24',\n",
              "  'author': 'DiCaprio',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761283533.A.798.html'},\n",
              " {'title': '[è¨è«–] åº·æ–¯å¦æ±€:é©…é­”ç¥æ¢12/05é‡è¿”å¤§éŠ€å¹•',\n",
              "  'date': '10/24',\n",
              "  'author': 'smilekrtc',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761283695.A.0CA.html'},\n",
              " {'title': 'Re: [è¨è«–] å¤§å®¶æœ‰å“ªäº›å¿ƒä¸­éå¸¸å–œæ­¡çš„é›»å½±ä¸»é¡Œæ›²ï¼Ÿ',\n",
              "  'date': '10/24',\n",
              "  'author': 'Allen0820',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761286588.A.1E9.html'},\n",
              " {'title': '[  æœ‰é›·] å¤§å©¢å’’å¥½çœ‹',\n",
              "  'date': '10/24',\n",
              "  'author': 'ej200078914',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761289653.A.6FA.html'},\n",
              " {'title': '[å¥½é›·] éˆé‹¸äººè•¾æ½”ç¯‡-å¤§å·¨è›‹ç§€æ³°ULTRA 4DX',\n",
              "  'date': '10/24',\n",
              "  'author': 'ljw155299',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761290069.A.609.html'},\n",
              " {'title': '[æ–°è] ã€Šçµé­”å¥³åœ˜ã€‹æ­Œæ‰‹EJAEç°½ç¶“ç´€ç´„ èˆ‡å²å˜‰è•¾åŒ',\n",
              "  'date': '10/24',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761293654.A.257.html'},\n",
              " {'title': '(æœ¬æ–‡å·²è¢«åˆªé™¤) [godofsex]',\n",
              "  'date': '10/24',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)'},\n",
              " {'title': '[è² é›·] ç‚¸å½ˆå±‹    æ¬¸ä¸æ˜¯....å°±é€™æ¨£!?',\n",
              "  'date': '10/24',\n",
              "  'author': 'sola2610',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761300583.A.5FC.html'},\n",
              " {'title': 'Re: [è¨è«–] å‘¨æ˜Ÿé¦³ç‚ºä½•é€™éº¼æ¬£è³ç¾…å¿—ç¥¥ï¼Ÿ',\n",
              "  'date': '10/24',\n",
              "  'author': 'mach1210',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761301538.A.176.html'},\n",
              " {'title': '[æ–°è] ã€Šæ˜Ÿéš›å¤§æˆ°ã€‹åå°æ¶æ‹ ä¸åªå²è’‚èŠ¬ç´¢å¾·æŸ',\n",
              "  'date': '10/24',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306055.A.321.html'},\n",
              " {'title': '[ç–‘å•é›·] åœ‹å¯¶ æœ‰æ®µåŠ‡æƒ…ç„¡æ³•ç†è§£',\n",
              "  'date': '10/24',\n",
              "  'author': 'u10400068',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306271.A.D6A.html'},\n",
              " {'title': '[æ–°è] å¼·å°¼æˆ´æ™®é‡è¿”å¥½èŠå¡¢å¤§ç‰‡ ä¸»æ¼”ã€Šå°æ°£è²¡ç¥',\n",
              "  'date': '10/24',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306408.A.E48.html'},\n",
              " {'title': '[LIVE] CINEMAX 22:00 æ—‹è½‰ç“¶å­',\n",
              "  'date': '10/24',\n",
              "  'author': 'ckny',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306986.A.8F9.html'},\n",
              " {'title': '[æƒ…å ±] ç¡è¦ºçš„ç¬¨è›‹é å‘Š-çŸ³é»‘æ­£æ•¸åŸä½œ',\n",
              "  'date': '10/24',\n",
              "  'author': 'takuminauki',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761312028.A.8C8.html'},\n",
              " {'title': '[å¥½é›·] ã€Šé¯¨é­šé¦¬æˆ²åœ˜ã€‹',\n",
              "  'date': '10/24',\n",
              "  'author': 'plurrr',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761315265.A.018.html'},\n",
              " {'title': '[å¥½é›·] æè¡›å¤©ä½¿ï¼Œæ¨è–¦çµ¦æƒ³çœ‹å–œåŠ‡ç‰‡å’ŒåŸºå“¥çš„ç²‰çµ²',\n",
              "  'date': '10/24',\n",
              "  'author': 'Xenomorph',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761316203.A.B1C.html'},\n",
              " {'title': '[å¥½ç„¡é›·] åœ‹å¯¶',\n",
              "  'date': '10/24',\n",
              "  'author': 'Midiya',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761320632.A.BA2.html'},\n",
              " {'title': '[æ–°è] æœªä¾†å…©å¹´ã€Šè™è ä¿ 2ã€‹ã€Šå¾©ä»‡è€…è¯ç›Ÿ5ã€‹å¤§ç‰‡',\n",
              "  'date': '10/24',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761321034.A.CAE.html'},\n",
              " {'title': '[å•ç‰‡] è«‹å•å‡ºç¾éæ—¥å¼ä½›é¾•å ´æ™¯çš„é›»å½±æˆ–å½±é›†??',\n",
              "  'date': '10/23',\n",
              "  'author': 'edwin11017',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761208319.A.047.html'},\n",
              " {'title': 'Re: [è¨è«–] è¶Šç„ç‰‡éƒ½å”¬çˆ›å§ï¼Ÿ',\n",
              "  'date': '10/23',\n",
              "  'author': 'firefoxriko',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761208739.A.F3D.html'},\n",
              " {'title': 'Re: [æ–°è] è©¹å§†æ–¯å²¡æ©è­‰å¯¦DCUä¸ä»¥é”å…‹è³½å¾·ç‚ºåæ´¾ï¼',\n",
              "  'date': '10/23',\n",
              "  'author': 'MoSalah',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761209606.A.79E.html'},\n",
              " {'title': '[å½±è©•] å‡¶é™å–œè¨Š',\n",
              "  'date': '10/23',\n",
              "  'author': 'godgod777',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761210089.A.A76.html'},\n",
              " {'title': '[æ–°è] åœ‹ç‰‡ç¥¨æˆ¿é”7.58å„„ æ–‡åŒ–éƒ¨å†æ¨ã€Œå¤§èˆªæµ·è¨ˆç•«',\n",
              "  'date': '10/23',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761210589.A.87C.html'},\n",
              " {'title': '[æ–°è] ã€Šç©å‘½é—œé ­11ã€‹é ç®—éé«˜ é¦®è¿ªç´¢æ‰¾åˆ°è§£æ–¹',\n",
              "  'date': '10/23',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761210953.A.A51.html'},\n",
              " {'title': '[æ–°è] å‚³è¯ç´å…„å¼Ÿæ¢ç´¢å°‡è¢«å‡ºå”® è©¹å§†æ–¯å²¡æ©ã€Œç–‘',\n",
              "  'date': '10/23',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761215098.A.979.html'},\n",
              " {'title': '[æ–°è] ã€Œå¤œé­”ä¿ ã€å¦èªå‡ºæ¼”ã€Šèœ˜è››äººï¼šé‡ç”Ÿæ—¥ã€‹',\n",
              "  'date': '10/23',\n",
              "  'author': 'zkow',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761222315.A.931.html'},\n",
              " {'title': '[å¥½ç„¡é›·] åœ‹å¯¶',\n",
              "  'date': '10/23',\n",
              "  'author': 'yu1164',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761225395.A.F38.html'},\n",
              " {'title': '[æ–°è] å…¥ä¼è»ŠéŠ€å„ªå¦é¡å‡ºå¸­ã€æ”¾é£›æ—…è¡Œåœ˜ã€‘è¨˜è€…æœƒ',\n",
              "  'date': '10/23',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761227565.A.223.html'},\n",
              " {'title': '[å¥½ç„¡é›·]åœ‹å¯¶-å‚³çµ±ã€åè²ã€äººæ€§èˆ‡è—è¡“',\n",
              "  'date': '10/23',\n",
              "  'author': 'peterpan910',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761228136.A.5F9.html'},\n",
              " {'title': '[è¨è«–] çœ‹é›»å½±æ™‚,æ‰‹æ©Ÿé—œæˆéœéŸ³æœ‰å¾ˆå›°é›£å—==?',\n",
              "  'date': '10/23',\n",
              "  'author': 'MeiHS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761228984.A.359.html'},\n",
              " {'title': '[æƒ…å ±] å…‹é‡Œæ–¯æ¼¢æ–¯æ²ƒæœ€æ–°å‹•ä½œæ‡¸ç–‘ç‰‡ã€ŠçŠ¯ç½ª101ã€‹',\n",
              "  'date': '10/23',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234206.A.FFD.html'},\n",
              " {'title': '[è¨è«–] æ•å¡å‡±è‰ã€Šé¦™æª³æƒ…ç·£ã€‹é å‘Š',\n",
              "  'date': '10/23',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234475.A.BC2.html'},\n",
              " {'title': '[æ–°è] ã€Šé˜¿å‡¡é”ã€‹ä¸»é¡Œæ›²éº¥è‰å¸Œæ‹‰ç»å”±ï¼ç¬¬ä¸‰é›†',\n",
              "  'date': '10/23',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234522.A.662.html'},\n",
              " {'title': '[å¥½é›·] ã€Šç››å¤å¿ƒå‹•ã€‹åŒå¿—çš„ç¾å¥½çƒæ‰˜é‚¦',\n",
              "  'date': '10/23',\n",
              "  'author': 'godzillahome',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234531.A.848.html'},\n",
              " {'title': '[æ–°è] æ¢…çˆ¾å‰å‹ƒéœã€Šå—é›£è¨˜2ã€‹èºå‡å„„è¬è¶…ç´šå¤§ç‰‡ï¼',\n",
              "  'date': '10/23',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234592.A.BE9.html'},\n",
              " {'title': '[æ™®å¥½é›·]åœ‹å¯¶',\n",
              "  'date': '10/23',\n",
              "  'author': 'nissyyoyo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761235084.A.817.html'},\n",
              " {'title': '[æ–°è] ç±³å®¶å¤§æˆ°æ©Ÿå™¨äººæœ‰çºŒé›† ç‰‡åæš—ç¤ºå®¶æ—åç›®',\n",
              "  'date': '10/23',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761235119.A.2DD.html'},\n",
              " {'title': '[è² é›·] é•·ç”Ÿè¡€æˆ°ï¼Œé å‘Šæ„Ÿè¦ºä¸éŒ¯æ­£ç‰‡å°å¤±æœ›',\n",
              "  'date': '10/24',\n",
              "  'author': 'WEight22',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761236577.A.440.html'},\n",
              " {'title': '[ç„¡é›·] å‰µï¼šæˆ°ç¥ ç­‰é€™éº¼å¤šå¹´ä¸æ˜¯ç‚ºäº†çœ‹é€™ç¨®XX',\n",
              "  'date': '10/22',\n",
              "  'author': 'clurinzler',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761070334.A.C5F.html'},\n",
              " {'title': '[å•ç‰‡] æ‰¾ä¸€éƒ¨å°ç£æœ¬åœŸå¤šç¯‡çŸ­ç‰‡åˆé›†çˆ¶è¦ªä¸»é¡Œé›»å½±',\n",
              "  'date': '10/22',\n",
              "  'author': 'zxc17893',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761077917.A.7C0.html'},\n",
              " {'title': 'Re: [æ™®å¥½é›·]ç ´åœ°ç„ï¼šåŸ·å¿µæ‰æ˜¯çœŸæ­£çš„åœ°ç„',\n",
              "  'date': '10/22',\n",
              "  'author': 'xakg',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761098309.A.B0C.html'},\n",
              " {'title': '[è¨è«–] è—¤æœ¬æ¨¹17-26æ‹†æˆ2é›†æ˜¯ä¸æ˜¯åœ–åˆ©å½±åŸï¼Ÿï¼Ÿï¼Ÿ',\n",
              "  'date': '10/22',\n",
              "  'author': 'Daboto',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761100280.A.33F.html'},\n",
              " {'title': '[è¨è«–] å‹•ä½œç”·æ˜ŸTom Hopperèˆ‡è‰¾èŠ­å…±è­œè«œå ±ç‰‡',\n",
              "  'date': '10/22',\n",
              "  'author': 'petestar',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761121773.A.185.html'},\n",
              " {'title': '[æ–°è] ä¼Šè‰èç™½æ­æ£®æ‹’æ¼”åƒ…é™ä¸²æµé›»å½± å¼·èª¿è§€çœ¾',\n",
              "  'date': '10/22',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761128031.A.A25.html'},\n",
              " {'title': '[æ–°è] æ—¥æœ¬ç¾è±¡ç´šé›»å½±ç‡’åˆ°å°ç£ã€Šåœ‹å¯¶ã€‹ å°æ¼”',\n",
              "  'date': '10/22',\n",
              "  'author': 'yu1164',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761128794.A.F67.html'},\n",
              " {'title': '[è¨è«–] ç‚ºä½•å¾ˆå¤šèˆŠé›»å½±éƒ½è¦é‡æ˜ ï¼Ÿ',\n",
              "  'date': '10/22',\n",
              "  'author': 'DiCaprio',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761130441.A.B25.html'},\n",
              " {'title': '[æ–°è] ã€èª°æƒ³ç•¶è€å¤§ã€‘å¯«ä¸‹å—éŸ“ç–«å¾Œæœ€å¼·ç¥¨æˆ¿å¥‡è¹Ÿ',\n",
              "  'date': '10/22',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761137970.A.4F3.html'},\n",
              " {'title': '[æ–°è] ã€Œé©šå¥‡éšŠé•·ã€å›æ­¸ï¼Ÿæ¼”å“¡ï¼šæˆ‘ä¸èƒ½èªª',\n",
              "  'date': '10/22',\n",
              "  'author': 'CYKONGG',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761139616.A.1B6.html'},\n",
              " {'title': '[æ–°è] Xæˆ°è­¦å¤–å‚³è®Šç¨®äººç•¶å¹´ç¥¨æˆ¿å£ç¢‘å…¨æ˜¯ç½é›£ï¼',\n",
              "  'date': '10/22',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761139723.A.72C.html'},\n",
              " {'title': '[æ–°è] è©¹å§†æ–¯å²¡æ©è­‰å¯¦DCUä¸ä»¥é”å…‹è³½å¾·ç‚ºåæ´¾ï¼',\n",
              "  'date': '10/22',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761147761.A.920.html'},\n",
              " {'title': '[è¨è«–] ã€Œé¬¼æ»…ä¹‹åˆƒã€æ—¥æœ¬ç¸½ç¥¨æˆ¿é£†ç ´367å„„æ—¥åœ“ï¼',\n",
              "  'date': '10/22',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761147795.A.F95.html'},\n",
              " {'title': '[æ–°è] å²ä¸Šæˆæœ¬æœ€é«˜é›»å½±å† è»æ’è¡Œæ´—ç‰Œï¼ä¾ç¾…ç´€',\n",
              "  'date': '10/22',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761147827.A.5FC.html'},\n",
              " {'title': '[å•ç‰‡] äºŒä¸‰åå¹´å‰çš„å¤–æ˜Ÿæ€ªç‰©ç‰‡',\n",
              "  'date': '10/22',\n",
              "  'author': 'shanger74',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761148659.A.64A.html'},\n",
              " {'title': '[æ–°è] è¯ç´æ¢ç´¢é »é“å°‹æ±‚å‡ºå”® åœ‹éš›åª’é«”å¸‚å ´å°‡å¤§æ´—ç‰Œ',\n",
              "  'date': '10/23',\n",
              "  'author': 'horrorghost',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761151856.A.5ED.html'},\n",
              " {'title': '(æœ¬æ–‡å·²è¢«åˆªé™¤) [zx0158]',\n",
              "  'date': '10/23',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)'},\n",
              " {'title': '[è¨è«–] å¾åœ°å¿ƒç«„å‡º4-6 å¥½çœ‹å—ï¼Ÿ',\n",
              "  'date': '10/23',\n",
              "  'author': 'p8410077',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761181006.A.E0A.html'},\n",
              " {'title': '[å•ç‰‡] è€ç”·äººé…è§’æ•´éƒ¨é›»å½±åªæœ‰ä¸€å¥å°è©',\n",
              "  'date': '10/23',\n",
              "  'author': 'unique751224',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761182634.A.DB4.html'},\n",
              " {'title': '[é›·] å¼’æ„›',\n",
              "  'date': '10/23',\n",
              "  'author': 'indoorsma',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761189461.A.CFD.html'},\n",
              " {'title': '[æ–°è] çœŸäººç‰ˆé¦´é¾é«˜æ‰‹2ä¸‹å€‹æœˆå°±é–‹æ‹ çœŸäººå°å—',\n",
              "  'date': '10/21',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760978028.A.5DD.html'},\n",
              " {'title': '[æ™®é›·]ã€Šä¹–ç‹—ç‹—ã€‹ç•¶ç‹—ç‹—é‡ä¸Šè¶…è‡ªç„¶ææ€–ç¾è±¡',\n",
              "  'date': '10/21',\n",
              "  'author': 'KevinMoleaf',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760978445.A.37E.html'},\n",
              " {'title': '[è² é›·] ç½ªäººçœŸä½ç„¡èŠ',\n",
              "  'date': '10/21',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760980202.A.0C1.html'},\n",
              " {'title': '[æ–°è] å‰µï¼šæˆ°ç¥ç¥¨æˆ¿æ…˜æ·¡è¿ªå£«å°¼ä¼°è™§æ1.3å„„ç¾å…ƒ',\n",
              "  'date': '10/21',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761009363.A.17E.html'},\n",
              " {'title': '[è¨è«–] é˜¿å‡¡é”1æ˜¯å¦éè­½',\n",
              "  'date': '10/21',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761015856.A.796.html'},\n",
              " {'title': '[è¶…å¥½é›·] å¤§åœ°è‹±è±ª',\n",
              "  'date': '10/21',\n",
              "  'author': 'skywalker019',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761018730.A.D38.html'},\n",
              " {'title': '[æ–°è] ç‹å¿ƒå‡Œåˆä½œå¤§å’–å¥³æ˜Ÿï¼ç¾è²å”±é€²ä¸‰å¤§åœ‹éš›å½±',\n",
              "  'date': '10/21',\n",
              "  'author': 'CYKONGG',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761027130.A.360.html'},\n",
              " {'title': 'Re: [è´ˆç¥¨] ã€åªç‚ºä½ éºæ†¾ã€‘æ„Ÿå‹•åŒ—ä¸­å—ç‰¹æ˜ æ¶å…ˆçœ‹',\n",
              "  'date': '10/21',\n",
              "  'author': 'cecilia1220',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761031550.A.47C.html'},\n",
              " {'title': 'Re: [æ–°è] å¥½èŠå¡¢é™·å…¥å¹³åº¸ï¼Ÿé›·åˆ©å²è€ƒç‰¹æ‰¹çˆ›ç‰‡æˆç½',\n",
              "  'date': '10/21',\n",
              "  'author': 'xross',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761038981.A.709.html'},\n",
              " {'title': '[æ–°è] è¶…äººçš„ç¥¨æˆ¿ç²åˆ©æ˜¯é‹¼éµè‹±é›„çš„ä¸‰å€',\n",
              "  'date': '10/21',\n",
              "  'author': 'sonans',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761041712.A.2B6.html'},\n",
              " {'title': '[æ–°è] <è¿·å®®è£¡çš„é­”è¡“å¸«>ç¦å±±é›…æ²»å‘Šç™½å°ç£ç§€é­”è¡“',\n",
              "  'date': '10/21',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761041831.A.75D.html'},\n",
              " {'title': '[è«‹ç›Š] æ‰“ç ´ç¬¬å››é¢ç‰†è·Ÿè§€çœ¾å°è©±',\n",
              "  'date': '10/21',\n",
              "  'author': 'gsp0309099',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761052661.A.B16.html'},\n",
              " {'title': '[è¨è«–] è¶Šç„ç‰‡éƒ½å”¬çˆ›å§ï¼Ÿ',\n",
              "  'date': '10/21',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761054868.A.81D.html'},\n",
              " {'title': 'Re: [è¨è«–] è¶Šç„ç‰‡éƒ½å”¬çˆ›å§ï¼Ÿ',\n",
              "  'date': '10/21',\n",
              "  'author': 'MeiHS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761057211.A.BC4.html'},\n",
              " {'title': '[æƒ…å ±] æœ´è´Šéƒã€Šå¾µäººå•Ÿå¼’ã€‹çˆ›ç•ªèŒ„é–‹ç›¤',\n",
              "  'date': '10/21',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761059310.A.E7B.html'},\n",
              " {'title': '[è¨è«–] ã€Šå±±æ€ªå·¨é­” 2ã€‹æ­£å¼é å‘Š',\n",
              "  'date': '10/21',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061088.A.1F7.html'},\n",
              " {'title': '[æ–°è] ã€Œæµ©å…‹ã€é¦¬å…‹é­¯æ³•æ´›å¦è¨€ç¨ç«‹é›»å½±å› ç‚ºã€Œ',\n",
              "  'date': '10/21',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061126.A.C4B.html'},\n",
              " {'title': '[æ–°è] äºç•¶å´”ä½›æ›¾ç±Œæ‹æ˜Ÿæˆ°ã€Œå‡±ç¾…å¿ã€å¤–å‚³ï¼ç‰‡',\n",
              "  'date': '10/21',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061158.A.CA1.html'},\n",
              " {'title': '[æ–°è] ã€Šå’’è¡“è¿´æˆ°0ã€‹é‡è¿”å¤§éŠ€å¹•å…¨æ–°é™é‡ç‰¹å…¸ç™»å ´',\n",
              "  'date': '10/21',\n",
              "  'author': 'hvariables',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061809.A.DCE.html'},\n",
              " {'title': '[æƒ…å ±] ã€Šä½ ç•™ä¸‹çš„ç—•è·¡ã€‹é¦–æ”¯é å‘Š',\n",
              "  'date': '10/22',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761064901.A.BFE.html'},\n",
              " {'title': '[è«‹ç›Š] ç²‰çµ²å‘ç´€éŒ„ç‰‡ç‚ºä»€éº¼è¦è³£åˆ°550ï¼Ÿ',\n",
              "  'date': '10/20',\n",
              "  'author': 'summer07077',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760951541.A.7AF.html'},\n",
              " {'title': '[å¥½é›·]ã€Šä¹–ç‹—ç‹—ã€‹ï¼Œç‰ çœ‹è¦‹çš„ï¼Œè½è¦‹çš„ï¼Œç¶“æ­·è‘—çš„',\n",
              "  'date': '10/20',\n",
              "  'author': 'a122239',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760951767.A.78A.html'},\n",
              " {'title': '[å¥½é›·]ã€Šè—¤æœ¬æ¨¹ 17-26ã€‹ï¼Œè—¤æœ¬æ¨¹è€å¸«ç­†ä¸‹çš„ä¸–ç•Œ',\n",
              "  'date': '10/20',\n",
              "  'author': 'a122239',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760951877.A.333.html'},\n",
              " {'title': '[æ–°è] æ¼«å¨ç‚ºä½•æ²’ç¨ç«‹è£½ä½œæµ©å…‹é›»å½± é¦¬å…‹é­¯æ³•æ´›è§£',\n",
              "  'date': '10/20',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760953024.A.25D.html'},\n",
              " {'title': '[æ–°è] å¥½èŠå¡¢é™·å…¥å¹³åº¸ï¼Ÿé›·åˆ©å²è€ƒç‰¹æ‰¹çˆ›ç‰‡æˆç½',\n",
              "  'date': '10/20',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760954570.A.A31.html'},\n",
              " {'title': '[å¥½ç„¡é›·] éˆé‹¸äºº é’åŸ”æ–°å…‰Dolby Cinema',\n",
              "  'date': '10/20',\n",
              "  'author': 'ec75413',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760960739.A.112.html'},\n",
              " {'title': '[æ–°è] 7å¤§åå°é½Šèšåˆ†äº«ã€è—¤æœ¬æ¨¹17-26ã€‘å‰µä½œç§˜è¾›',\n",
              "  'date': '10/20',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760961390.A.932.html'},\n",
              " {'title': '[æ–°è] äºé¦¬éœç‚ºã€Š007ã€‹ç³»åˆ—é–‹é ­åŠ ä¸Šå…§å®¹è­¦èª',\n",
              "  'date': '10/20',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760961462.A.E49.html'},\n",
              " {'title': '[è¨è«–] éˆé‹¸äººè•¾æ½”ç¯‡å³å°‡ä¸Šæ˜ SCREENXç‰ˆ',\n",
              "  'date': '10/20',\n",
              "  'author': 'nobady98',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760961929.A.096.html'},\n",
              " {'title': '[æƒ…å ±] æœ´è´Šéƒ å½±å²ç¶“å…¸ã€ŠåŸç½ªçŠ¯ 4Kæ•¸ä½ä¿®å¾©ç‰ˆã€‹',\n",
              "  'date': '10/20',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760964111.A.0C6.html'},\n",
              " {'title': '[å¥½é›·] é¢¨è‘µçš„å¤æ—¥ç‰©èª',\n",
              "  'date': '10/20',\n",
              "  'author': 'backfish',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760964566.A.785.html'},\n",
              " {'title': '[è¨è«–] é¡å€¼æ¼”æŠ€ä¸éŒ¯å»ç´…ä¸èµ·ä¾†çš„æ¼”å“¡',\n",
              "  'date': '10/20',\n",
              "  'author': 'larry0323',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760965801.A.572.html'},\n",
              " {'title': '[æ–°è] æŸ¥å…‹å²å¥ˆå¾·æ›å…‰å–ªé˜æ–°ç…§ç‰‡ï¼ç²‰çµ²ç†±è­°å¸Œæœ›',\n",
              "  'date': '10/20',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760973330.A.82C.html'},\n",
              " {'title': '[å•ç‰‡] é–‹åº—è€é—†å–ªå¶èªè­˜ç¬¬äºŒæ˜¥çš„æ„›æƒ…ç‰‡',\n",
              "  'date': '10/20',\n",
              "  'author': 'markkkkkkkk',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760973346.A.E36.html'},\n",
              " {'title': '[è¨è«–] å‰µï¼šæˆ°ç¥...è¿ªå£«å°¼ä¹Ÿå¤ªæ‚²å“€äº†å§',\n",
              "  'date': '10/20',\n",
              "  'author': 'BlacKlonely',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760974069.A.89A.html'},\n",
              " {'title': 'Re: åˆºæ¿€1995  è‡ªæ¬ºæ¬ºäºº',\n",
              "  'date': '10/20',\n",
              "  'author': 'revanchist',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760974820.A.1B8.html'},\n",
              " {'title': 'ç¾…æµ®å®®ç«Šç›œæ¡ˆçš„æ—¢è¦–æ„Ÿ',\n",
              "  'date': '10/20',\n",
              "  'author': 'brothersun',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975197.A.B76.html'},\n",
              " {'title': '[æ–°è] æ¹¯å§†è‰¾åˆ©æ–¯è‡ªæ›æ›¾è©¦é¡ã€Œé©šå¥‡å…ˆç”Ÿã€ï¼éŒ¯',\n",
              "  'date': '10/20',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975202.A.CEA.html'},\n",
              " {'title': '[è¨è«–] å‹å‹ƒç‹„å°¼æ´›è¡¨ç¤ºä»ç„¶éœ€è¦èˆ‡å·æ™®æˆ°é¬¥ï¼',\n",
              "  'date': '10/20',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975239.A.69B.html'},\n",
              " {'title': '[æ–°è] å²æŸ¯è¥¿æ–¯æŒçºŒå°‹æ‰¾ä¸‹ä¸€å€‹æ•…äº‹',\n",
              "  'date': '10/20',\n",
              "  'author': 'hvariables',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975386.A.203.html'},\n",
              " {'title': '[è¨è«–] å¤§è£‚',\n",
              "  'date': '10/19',\n",
              "  'author': 'jeeplong',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760885070.A.4BF.html'},\n",
              " {'title': '[æ–°è] èˆ’æ·‡ä¸­åœ‹æ–°ç‰‡çªé­æ’¤æª”ï¼é¦–æ—¥ç¥¨æˆ¿åƒ…73è¬å…ƒ',\n",
              "  'date': '10/19',\n",
              "  'author': 'hvariables',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760885446.A.584.html'},\n",
              " {'title': '[æƒ…å ±] 10/19 ç•¶é€±9éƒ¨æ–°ç‰‡é å‘Š+Youtubeè§€çœ‹æ’è¡Œ',\n",
              "  'date': '10/19',\n",
              "  'author': 'bestbamboo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760886992.A.2BB.html'},\n",
              " {'title': '[å¥½é›·] è—¤æœ¬æ¨¹part2 æœ‰è¶£ç„¡èƒƒç—›',\n",
              "  'date': '10/19',\n",
              "  'author': 'jack5u06d93',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760887468.A.B91.html'},\n",
              " {'title': '[å¥½é›·] ç¬¬ä¸€æ»´è¡€äºŒ',\n",
              "  'date': '10/19',\n",
              "  'author': 'LVDior',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760888518.A.185.html'},\n",
              " {'title': '[è¨è«–] è¿·å®®è£¡çš„é­”è¡“å¸«é›»å½±é å‘Š',\n",
              "  'date': '10/19',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760889083.A.E77.html'},\n",
              " {'title': '[æ–°è] ã€Šå²ç‘å…‹5ã€‹åŠ‡æƒ…è¨­å®šæ›å…‰ï¼å²ç‘å…‹ä¸€è¡Œäºº',\n",
              "  'date': '10/19',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760889110.A.010.html'},\n",
              " {'title': '[æ–°è] é¬¼æ»…å…¨çƒç¥¨æˆ¿çªç ´948å„„æ—¥åœ“ï¼2025ç¬¬äº”å',\n",
              "  'date': '10/19',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760889138.A.AE5.html'},\n",
              " {'title': '[è«‹ç›Š] ä¸å¯èƒ½çš„ä»»å‹™ï¼šæœ€çµ‚æ¸…ç®—  ä¸€å€‹å•é¡Œ(æœ‰é›·)',\n",
              "  'date': '10/20',\n",
              "  'author': 'Midiya',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760890108.A.75A.html'},\n",
              " {'title': '[å¥½é›·] ã€Šå¾µäººå•Ÿå¼’ã€‹',\n",
              "  'date': '10/20',\n",
              "  'author': 'plurrr',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760890388.A.077.html'},\n",
              " {'title': 'Re: [è¨è«–] å°ç£é›»å½±é™¢ç‚ºä»€éº¼ä¸èƒ½å¶å–Š',\n",
              "  'date': '10/20',\n",
              "  'author': 'NuCat',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760899297.A.69C.html'},\n",
              " {'title': '[] ï¼»è±ªæ´¨é›·ï¼½æè¡›å¤©ä½¿ï¼Œè±ªæ´¨ç‰‡',\n",
              "  'date': '10/20',\n",
              "  'author': 'iamdiff',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760921493.A.C51.html'},\n",
              " {'title': '[å¥½é›·] é¢¨æ—ç«å±±',\n",
              "  'date': '10/20',\n",
              "  'author': 'ume',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760927383.A.2FC.html'},\n",
              " {'title': '[é–’èŠ] åª½çš„å¤šé‡å®‡å®™ ç¶²é£›æ­£å¸¸ç¿»è­¯ç‰ˆ',\n",
              "  'date': '10/20',\n",
              "  'author': 'winnietslock',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760928774.A.496.html'},\n",
              " {'title': '(æœ¬æ–‡å·²è¢«åˆªé™¤) [ilv1181023]',\n",
              "  'date': '10/20',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)'},\n",
              " {'title': 'åˆºæ¿€1995  è‡ªæ¬ºæ¬ºäºº',\n",
              "  'date': '10/20',\n",
              "  'author': 'revanchist',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760937413.A.4D4.html'},\n",
              " {'title': '[è¨è«–] é¬¼æ»…ä¹‹åˆƒå°ç£ç‹‚é£†8.19å„„ï¼Œæ¦®ç™»å°ç£å½±å²ç¬¬',\n",
              "  'date': '10/20',\n",
              "  'author': 'badmonkey',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760942642.A.FEA.html'},\n",
              " {'title': '[å¥½é›·] å¾µäººå•Ÿå¼’No Other Choice',\n",
              "  'date': '10/20',\n",
              "  'author': 'ueiwei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760943280.A.6D7.html'},\n",
              " {'title': '[é›·] å¥½é›·-å‰µæˆ°ç¥imax',\n",
              "  'date': '10/20',\n",
              "  'author': 'S26',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760948941.A.2E4.html'},\n",
              " {'title': 'è´ˆç¥¨ ä»Šæ™šå¤§å©¢å’’ é›»å½±ç‰¹æ˜ åˆ¸*1',\n",
              "  'date': '10/20',\n",
              "  'author': 'anggunuggna',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760950840.A.37D.html'},\n",
              " {'title': '[æ–°è] ã€Œç™½é›ªå…¬ä¸»ã€ç‘ç§‹é½Šæ ¼å‹’æ¥å¥½èŠå¡¢å¤§ç‰‡ï¼',\n",
              "  'date': '10/18',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760802318.A.713.html'},\n",
              " {'title': '[æ–°è] é¬¼æ»…å¸­æ²éŸ“åœ‹å½±å£‡ï¼éŸ“åª’ï¼šå…¨è¼¸æ—¥æœ¬å‹•ç•«ï¼',\n",
              "  'date': '10/18',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760802355.A.A01.html'},\n",
              " {'title': '[å¥½é›·] æè¡›å¤©ä½¿  çª®äººç”Ÿæ´»å°±æ˜¯è²»ç›¡å…¨åŠ›äº†',\n",
              "  'date': '10/18',\n",
              "  'author': 'callhek',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760803141.A.F8E.html'},\n",
              " {'title': '[å¥½é›·] ä¹–ç‹—ç‹—',\n",
              "  'date': '10/19',\n",
              "  'author': 'wusbetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760804485.A.789.html'},\n",
              " {'title': '[ å¥½ é›·] è—¤æœ¬æ¨¹part1 åŠ‡æƒ…å¤§é›·',\n",
              "  'date': '10/19',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760806566.A.B59.html'},\n",
              " {'title': '[ æ™®è² é›·] é¢¨æ—ç«å±±ï¼šé»‘ç¤¾æœƒè­¦åŒªç‰‡çš„å¾©å¤æƒ…æ‡·',\n",
              "  'date': '10/19',\n",
              "  'author': 'rabinson',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760806962.A.E38.html'},\n",
              " {'title': '[è¨è«–] å°ç£é›»å½±é™¢ç‚ºä»€éº¼ä¸èƒ½å¶å–Š',\n",
              "  'date': '10/19',\n",
              "  'author': 'Fucker5566',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760829534.A.2AF.html'},\n",
              " {'title': '[å¥½é›·] æè¡›å¤©ä½¿',\n",
              "  'date': '10/19',\n",
              "  'author': 'wusbetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760833505.A.3BA.html'},\n",
              " {'title': 'Re: [è¨è«–] å°ç£é›»å½±é™¢ç‚ºä»€éº¼ä¸èƒ½å¶å–Š',\n",
              "  'date': '10/19',\n",
              "  'author': 'a95462015',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760844591.A.49B.html'},\n",
              " {'title': '[å¥½é›·]ä¹–ç‹—ç‹—_ä¸»äººæˆ‘æœƒä¿è­·ä½ ...å³ä½¿é¢å°æ­»äº¡',\n",
              "  'date': '10/19',\n",
              "  'author': 'neilhister',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760853770.A.CC5.html'},\n",
              " {'title': '[å¥½é›·] éˆé‹¸äºº è•¾æ½”ç¯‡',\n",
              "  'date': '10/19',\n",
              "  'author': 'iamflash',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760855788.A.F6A.html'},\n",
              " {'title': '[è¨è«–] é›»å½±é™¢æœ‰è®“äººè®Šå¾—éµå®ˆè¦çŸ©çš„é­”åŠ›å§ï¼Ÿ',\n",
              "  'date': '10/19',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760863343.A.056.html'},\n",
              " {'title': '[è¨è«–] Netflix: å³å®‡æ£®çš„ The killer',\n",
              "  'date': '10/19',\n",
              "  'author': 'pacino',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760863975.A.EBF.html'},\n",
              " {'title': 'Re: [è¨è«–] å°ç£é›»å½±é™¢ç‚ºä»€éº¼ä¸èƒ½å¶å–Š',\n",
              "  'date': '10/19',\n",
              "  'author': 'goetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760864338.A.B04.html'},\n",
              " {'title': '[LIVE] AXN 21:00 æœ«æ—¥é è¨€',\n",
              "  'date': '10/19',\n",
              "  'author': 'ckny',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760866681.A.C0A.html'},\n",
              " {'title': '[è¨è«–] HMO MAXç½ªäººçªç„¶æ²’ä¸­æ–‡å­—å¹•?',\n",
              "  'date': '10/19',\n",
              "  'author': 'awestricken',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760867681.A.D95.html'},\n",
              " {'title': '(æœ¬æ–‡å·²è¢«åˆªé™¤) [larry0323]',\n",
              "  'date': '10/19',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)'},\n",
              " {'title': '[è«‹ç›Š] ç™¾å¹´ä¾†ï¼Œç¶“å…¸é›»å½±æœ€å¤šæ˜¯1970å¹´ä»£å—ï¼Ÿ',\n",
              "  'date': '10/19',\n",
              "  'author': 'nissan168',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760871760.A.C82.html'},\n",
              " {'title': '[æƒ…å ±] ã€ŠåŠ‡å ´ç‰ˆ å’’è¡“è¿´æˆ° æ¾€è°·äº‹è®Šxæ­»æ»…è¿´æ¸¸ã€‹',\n",
              "  'date': '10/19',\n",
              "  'author': 'lo17593ve',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760878943.A.607.html'},\n",
              " {'title': '[æƒ…å ±] podcast:ä¾¯å­è³¢_é¢¨å…’è¸¢è¸è¸©',\n",
              "  'date': '10/19',\n",
              "  'author': 'aton17',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760879949.A.186.html'},\n",
              " {'title': '[è¨è«–] æ±äº¬comic conå·¨æ˜Ÿé›²é›†...',\n",
              "  'date': '10/18',\n",
              "  'author': 'goetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760723092.A.2C3.html'},\n",
              " {'title': '[æ™®é›·] æ³¥å¨ƒå¨ƒï¼ˆå…§æ–‡æœ‰é›·ï¼‰',\n",
              "  'date': '10/18',\n",
              "  'author': 'cc001225',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760730185.A.D7F.html'},\n",
              " {'title': '[æ–°è] ã€Šåœ‹æœ‰å™¨å®˜ã€‹åœ¨éŸ“åœ‹å½±é™¢é¦–æ˜  å¼•è§€çœ¾å…±é³´',\n",
              "  'date': '10/18',\n",
              "  'author': 'pulagu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760741751.A.FA9.html'},\n",
              " {'title': 'Re: [è¨è«–] æœ€é ‚çš„æ„›æƒ…é›»å½±ï¼Ÿ',\n",
              "  'date': '10/18',\n",
              "  'author': 'xross',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760748092.A.42D.html'},\n",
              " {'title': '[è¨è«–] è‡ºç£è§€å½±æ—¥æœ¬åŒ–ï¼Ÿ',\n",
              "  'date': '10/18',\n",
              "  'author': 'DiCaprio',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760750041.A.132.html'},\n",
              " {'title': '[æ–°è] é›»å½±ç”¢æ¥­å›ä¸å»äº†ï¼Ÿ ç¶²å‹è§€å¯Ÿã€Œå¹¾å€‹é¢å‘',\n",
              "  'date': '10/18',\n",
              "  'author': 'sony577',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760753550.A.E62.html'},\n",
              " {'title': '[å¥½é›·] å¹¸ç¦è·¯ä¸Š',\n",
              "  'date': '10/18',\n",
              "  'author': 'waakye',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760764742.A.BF6.html'},\n",
              " {'title': '[  æ™®é›·] ä¹–ç‹—ç‹— ç‚ºä»€éº¼æˆ‘çœ‹ä¸æ‡‚',\n",
              "  'date': '10/18',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760765253.A.0C8.html'},\n",
              " {'title': '(æœ¬æ–‡å·²è¢«åˆªé™¤) [larry0323]',\n",
              "  'date': '10/18',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)'},\n",
              " {'title': '[è² é›·] ä¸–ç•Œå°±æ˜¯é€™æ¨£çµæŸçš„',\n",
              "  'date': '10/18',\n",
              "  'author': 'j022015',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760771186.A.219.html'},\n",
              " {'title': '[å¥½é›·] ã€Šè—¤æœ¬æ¨¹17-26ã€‹ç´”æ„›æ§+å¦¹æ§å¤§ç¦®åŒ…',\n",
              "  'date': '10/18',\n",
              "  'author': 'godzillahome',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760771837.A.2B0.html'},\n",
              " {'title': '[LIVE] HBO 21:00 ç„¡ç·šæ®ºæ©Ÿ',\n",
              "  'date': '10/18',\n",
              "  'author': 'ckny',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760776629.A.934.html'},\n",
              " {'title': 'Re: [  æ™®é›·] ä¹–ç‹—ç‹— ç‚ºä»€éº¼æˆ‘çœ‹ä¸æ‡‚',\n",
              "  'date': '10/18',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760781210.A.59B.html'},\n",
              " {'title': '[æ™®é›·] æè¡›ä»»å‹™ï¼šå¾©ä»‡èŠ­è•¾',\n",
              "  'date': '10/18',\n",
              "  'author': 'darkofpolo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760782032.A.99B.html'},\n",
              " {'title': '[æ™®ç„¡é›·] é—‡é»‘é›»è©±2',\n",
              "  'date': '10/18',\n",
              "  'author': 'setyounger',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760783253.A.9E7.html'},\n",
              " {'title': '[é¸ç‰‡] åœ‹å¯¶é¢¨æš´ or é—‡é»‘é›»è©± or ä¹–ç‹—ç‹—',\n",
              "  'date': '10/18',\n",
              "  'author': 'Daboto',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760786986.A.9DB.html'},\n",
              " {'title': '[è² é›·] ä¸€ç™¾å…¬å°º',\n",
              "  'date': '10/18',\n",
              "  'author': 'larry8550',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760791258.A.895.html'},\n",
              " {'title': 'Fw: [æ™®é›·] ã€Šé¢¨æ—ç«å±±ã€‹ã€Œå‚³èªªã€çš„çµ‚é»ï¼Œæ˜¯é€£æ»¾å¸¶çˆ¬',\n",
              "  'date': '10/18',\n",
              "  'author': 'elvayanzimei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760800558.A.B7B.html'},\n",
              " {'title': '[ç‰‡å–®] æ‡¸ç–‘æ‰¾äººçš„ç‰‡',\n",
              "  'date': '10/18',\n",
              "  'author': 'moneybuy',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760800744.A.379.html'},\n",
              " {'title': '[è¨è«–] å¡”æäºå¨œç‘ªæ–¯æ‹‰å¦®ã€Šé¡«æ‡¼ã€‹é å‘Š',\n",
              "  'date': '10/18',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760802290.A.728.html'},\n",
              " {'title': '[æ–°è] å†åº¦åƒèˆ‡è«¾è˜­é›»å½±çš„æ„Ÿå—ï¼Ÿ è‰¾ç•¥ç‰¹ä½©å‰',\n",
              "  'date': '10/17',\n",
              "  'author': 'mashmabo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760669253.A.12E.html'},\n",
              " {'title': '[è¨è«–] å¤©åŠ«å€’æ•¸2é¦–æ”¯é å‘Š',\n",
              "  'date': '10/17',\n",
              "  'author': 'j31404',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760670398.A.481.html'},\n",
              " {'title': '[æ–°è] Lisaé¦–åº¦æŒ‘æˆ°å¤§éŠ€å¹• å‡ºæ¼”ã€Šé©šå¤©ç‡Ÿæ•‘ï¼šæ³°æˆˆ',\n",
              "  'date': '10/17',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760672064.A.F08.html'},\n",
              " {'title': '[æ–°è] ä¼‘é¤Šç”Ÿæ¯é‡‘å‡±ç‘ æœ‰æ„æ¼”çœŸäººç‰ˆã€Šå‚‘æ£®ä¸€å®¶ã€‹',\n",
              "  'date': '10/17',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760672788.A.58B.html'},\n",
              " {'title': '[æ–°è]æ—¥æœ¬ã€Šéˆé‹¸äººã€‹+ã€Šé¬¼æ»…ä¹‹åˆƒã€‹å¸­æ²éŸ“åœ‹å½±å£‡',\n",
              "  'date': '10/17',\n",
              "  'author': 'toebb',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760673467.A.1A3.html'},\n",
              " {'title': '[è¨è«–] å¤©ç‹å‘¨æ°å€«ã€é ­æ–‡å­—Dã€‘20å‘¨å¹´ 4Kä¿®å¾©ç‰ˆ',\n",
              "  'date': '10/17',\n",
              "  'author': 'Oni028',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760676049.A.4B2.html'},\n",
              " {'title': '[  å¥½é›·] è—¤æœ¬æ¨¹17-26',\n",
              "  'date': '10/17',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760679013.A.D67.html'},\n",
              " {'title': '[æ™®é›·]ã€Šé»‘è–”è–‡ä¹‹é¤¨ã€‹æ„›çš„æ¯€æ»…ã€ç½ªå­½èˆ‡åå™¬',\n",
              "  'date': '10/17',\n",
              "  'author': 'KevinMoleaf',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760679772.A.1E8.html'},\n",
              " {'title': '[å¥½é›·] æ—¥æœ¬æœ‰åœ‹å¯¶ä¸­åœ‹æœ‰æˆ²å°',\n",
              "  'date': '10/17',\n",
              "  'author': 'godgod777',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760683943.A.3F5.html'},\n",
              " {'title': '[å¥½é›·] å¾µäººå•Ÿå¼’No Other Choice',\n",
              "  'date': '10/17',\n",
              "  'author': 'ueiwei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760684400.A.1D5.html'},\n",
              " {'title': '[å¥½é›·] è—¤æœ¬æ¨¹17-26 å¥½é›·',\n",
              "  'date': '10/17',\n",
              "  'author': 'VANDAS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760690640.A.066.html'},\n",
              " {'title': '[æ™®å¥½é›·] æ³¥å¨ƒå¨ƒ',\n",
              "  'date': '10/17',\n",
              "  'author': 'HuangYa',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760691055.A.4F7.html'},\n",
              " {'title': '[ æ™®é›·] é¢¨æ—ç«å±±',\n",
              "  'date': '10/17',\n",
              "  'author': 'AV771118',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760705601.A.8E5.html'},\n",
              " {'title': '[ç„¡é›·] å‰µï¼šæˆ°ç¥ å¤§å·¨è›‹ç§€æ³°ULTRA 4DXåˆé«”é©—',\n",
              "  'date': '10/17',\n",
              "  'author': 'mmm9poo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760713115.A.309.html'},\n",
              " {'title': '[æ™®é›·] æè¡›ä»»å‹™ï¼šå¾©ä»‡èŠ­è•¾ æ»¿æ»¿ACGæ¢—',\n",
              "  'date': '10/17',\n",
              "  'author': 'defenser',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760713395.A.F2B.html'},\n",
              " {'title': '[è¨è«–] é¦¬å…‹è¯æŸæ ¼ã€Šå…¨å®¶é€ƒèµ°ä¸­2ã€‹é å‘Š',\n",
              "  'date': '10/17',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716316.A.08B.html'},\n",
              " {'title': '[æ–°è] å‹å€«æ–¯è²»è¨±æœ‹æƒ³ç•¶ã€ŒXæ•™æˆã€ï¼ä¸æƒ³æ¼”æ˜Ÿéš›',\n",
              "  'date': '10/17',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716349.A.A12.html'},\n",
              " {'title': '[æ–°è] åŸºåŠªæç¶­:åˆ°å¥½èŠå¡¢å°±è¢«è¦æ±‚æ”¹åKCæç¶­ï¼',\n",
              "  'date': '10/17',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716380.A.89E.html'},\n",
              " {'title': '[æ–°è] å¤±æ§çŒ©çŒ©æ€ã€ŠçŒ©ç˜‹è¡€é›¨ã€‹ï¼çˆ›ç•ªèŒ„88ï¼…å¥½è©•ææ€–ç‰‡ é¦–æ›é å‘Š',\n",
              "  'date': '10/17',\n",
              "  'author': 'hihihihehehe',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716506.A.608.html'},\n",
              " {'title': 'Re: [è¨è«–] æœ€é ‚çš„æ„›æƒ…é›»å½±ï¼Ÿ',\n",
              "  'date': '10/18',\n",
              "  'author': 'ivorysoap',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760721115.A.AFB.html'},\n",
              " {'title': '[æ–°è] ã€Šé–ƒé›»ä¿ ã€‹ç¥¨æˆ¿ã€å£ç¢‘çš†è¼¸ å°æ¼”ï¼šæ²’çœ‹é',\n",
              "  'date': '10/16',\n",
              "  'author': 'CYKONGG',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760596833.A.2C4.html'},\n",
              " {'title': '[æ–°è]ã€Šé˜¿å‡¡é”ã€‹å…©é›†è£½ä½œç´€éŒ„ç‰‡ 11æœˆDisney+ä¸Šç·š',\n",
              "  'date': '10/16',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760597567.A.CAC.html'},\n",
              " {'title': '[æ–°è] éŸ“æ˜ŸæŒ¯æ°¸æ¥æ¼”å°éŸ“æ„›æƒ…ç‰‡ èˆ‡ææ²ã€å®‹æŸç·¯ä¸»',\n",
              "  'date': '10/16',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760598386.A.6FB.html'},\n",
              " {'title': '[è¨è«–] å¹´è¼•æ²™è´ŠAsher Angelçš„è¿‘æ³?',\n",
              "  'date': '10/16',\n",
              "  'author': 'pttnowash',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760613123.A.270.html'},\n",
              " {'title': '[è¨è«–] äººå‹èœˆèš£æ€éº¼æ²’çºŒé›†ï¼Ÿ',\n",
              "  'date': '10/16',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760614719.A.478.html'},\n",
              " {'title': '[æ–°è] ã€æ”¾é£›æ—…è¡Œåœ˜ã€‘äº”å¤§å¤¢å¹»å¡å¸å³èˆˆç¬‘åŠ›å…¨é–‹',\n",
              "  'date': '10/16',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760617626.A.5DC.html'},\n",
              " {'title': '[æ–°è] è£´æ–—å¨œã€è¥¿å³¶ç§€ä¿Šå°‡ä¾†å°ä¸Šé‡‘é¦¬å¤§å¸«èª²ï¼é‡',\n",
              "  'date': '10/16',\n",
              "  'author': 'yu1164',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760618844.A.DD6.html'},\n",
              " {'title': '[è½‰éŒ„] é„­æµ©å—å¾ˆåƒæœå¾·å‰å»ç„¡æ³•å¤§ç´…',\n",
              "  'date': '10/16',\n",
              "  'author': 'cjol',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760620082.A.75D.html'},\n",
              " {'title': '[å¥½ç„¡é›·] ä¹–ç‹—ç‹—',\n",
              "  'date': '10/16',\n",
              "  'author': 'wholehearted',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760624988.A.BEF.html'},\n",
              " {'title': '[è¨è«–] æœ€é ‚çš„æ„›æƒ…é›»å½±ï¼Ÿ',\n",
              "  'date': '10/16',\n",
              "  'author': 'c48074',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760625279.A.B77.html'},\n",
              " {'title': '[è¨è«–] MIB2çš„RAP',\n",
              "  'date': '10/16',\n",
              "  'author': 'apeshit5566',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760626937.A.D17.html'},\n",
              " {'title': '[è¨è«–] ç‹„å€«æ­å¸ƒèŠæ©ã€ç‘ç§‹éº¥äºç•¶æ–¯ã€Šæ±‚æ•‘ã€‹é å‘Š',\n",
              "  'date': '10/16',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760627121.A.7DA.html'},\n",
              " {'title': '[å¥½é›·] ç¥é¬¼äº¤é‹’ å½è£ã€å­¤å–®èˆ‡ç”Ÿå‘½çš„æ™æ‰',\n",
              "  'date': '10/16',\n",
              "  'author': 'PiDaiShuei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760627376.A.1BD.html'},\n",
              " {'title': '[æ–°è] æå¥§ç´å¤šã€Šä¸€æˆ°å†æˆ°ã€‹å°‡è™§æè¶…é1å„„ç¾å…ƒï¼',\n",
              "  'date': '10/16',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760627948.A.54C.html'},\n",
              " {'title': '[æ–°è] å·¨çŸ³å¼·æ£®è¢«è«¾è˜­è®šæ¼”æŠ€ï¼ç‚ºä»–ç²å¥§æ–¯å¡æå',\n",
              "  'date': '10/16',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760628758.A.03E.html'},\n",
              " {'title': '[è¨è«–] å“ªäº›ä½ èªç‚ºç¶“å…¸é›»å½±æµ·å ±ä½†ä½ å¾æ²’æƒ³çœ‹æ­£ç‰‡',\n",
              "  'date': '10/16',\n",
              "  'author': 'ivorysoap',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760629002.A.0D3.html'},\n",
              " {'title': '[æ–°è] çœ‹é›»å½±ç„¡æ³•æ»¿è¶³ ä¹¾è„†è‡ªå·±æ‹ä¸€éƒ¨ï¼ã€Šå„éˆ',\n",
              "  'date': '10/17',\n",
              "  'author': 'sony577',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760647434.A.740.html'},\n",
              " {'title': 'Re: [è½‰éŒ„] é„­æµ©å—å¾ˆåƒæœå¾·å‰å»ç„¡æ³•å¤§ç´…',\n",
              "  'date': '10/17',\n",
              "  'author': 'godgod777',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760659814.A.746.html'},\n",
              " {'title': '[è¨è«–] ä»Šå¹´æš‘å‡æª”çš„é›»å½±,ç®—æ˜¯å‹•ç•«å¼·éçœŸäººå—?',\n",
              "  'date': '10/17',\n",
              "  'author': 'MeiHS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760665647.A.8AB.html'},\n",
              " {'title': 'Re: [è«‹ç›Š] å“ªäº›é›»å½±æ”¹è®Šæ‹æ”æ–¹å¼ï¼Ÿ',\n",
              "  'date': '10/17',\n",
              "  'author': 'icrose',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760667017.A.044.html'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = articles_data[1]['title']"
      ],
      "metadata": {
        "id": "Ak6rmgQBpruY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "\n",
        "# å¾…åˆ†è©çš„ä¸­æ–‡å¥å­\n",
        "print(f\"åŸå§‹å¥å­: {sentence}\\n\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- 1. ç²¾ç¢ºæ¨¡å¼ (Default Mode) ---\n",
        "# é€™æ˜¯æœ€å¸¸ç”¨çš„æ¨¡å¼ï¼Œå˜—è©¦å°‡å¥å­æœ€ç²¾ç¢ºåœ°åˆ‡é–‹ï¼Œé©åˆæ–‡æœ¬åˆ†æã€‚\n",
        "print(\"æ¨¡å¼ä¸€ï¼šç²¾ç¢ºæ¨¡å¼ (jieba.cut)\")\n",
        "# jieba.cut è¿”å›çš„æ˜¯ä¸€å€‹è¿­ä»£å™¨ (iterator)\n",
        "seg_list_precise = jieba.cut(sentence, cut_all=False)\n",
        "# ä½¿ç”¨ '/ ' å°‡çµæœä¸²æ¥èµ·ä¾†ï¼Œæ–¹ä¾¿è¼¸å‡º\n",
        "print(f\"åˆ†è©çµæœ: {'/ '.join(seg_list_precise)}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- 2. å…¨æ¨¡å¼ (Full Mode) ---\n",
        "# æœƒæƒæå‡ºå¥å­ä¸­æ‰€æœ‰å¯èƒ½çš„è©èªï¼Œé€Ÿåº¦æœ€å¿«ï¼Œä½†çµæœå¯èƒ½æœ‰å¤§é‡é‡ç–Šã€‚\n",
        "print(\"æ¨¡å¼äºŒï¼šå…¨æ¨¡å¼ (jieba.cut(..., cut_all=True))\")\n",
        "seg_list_all = jieba.cut(sentence, cut_all=True)\n",
        "print(f\"åˆ†è©çµæœ: {'/ '.join(seg_list_all)}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- 3. æœå°‹å¼•æ“æ¨¡å¼ (Search Engine Mode) ---\n",
        "# åœ¨ç²¾ç¢ºæ¨¡å¼çš„åŸºç¤ä¸Šï¼Œå°é•·è©å†æ¬¡é€²è¡Œç´°åˆ†ï¼Œé©åˆç”¨æ–¼æœå°‹å¼•æ“å»ºç«‹ç´¢å¼•ã€‚\n",
        "print(\"æ¨¡å¼ä¸‰ï¼šæœå°‹å¼•æ“æ¨¡å¼ (jieba.cut_for_search)\")\n",
        "seg_list_search = jieba.cut_for_search(sentence)\n",
        "print(f\"åˆ†è©çµæœ: {'/ '.join(seg_list_search)}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- 4. è©æ€§æ¨™è¨» (Optional: Add Part-of-Speech Tagging) ---\n",
        "# jieba.posseg å¯ä»¥åœ¨åˆ†è©çš„åŒæ™‚æ¨™è¨»è©æ€§ (ä¾‹å¦‚ n: åè©, v: å‹•è©)\n",
        "import jieba.posseg as pseg\n",
        "print(\"æ¨¡å¼å››ï¼šåˆ†è©èˆ‡è©æ€§æ¨™è¨» (jieba.posseg)\")\n",
        "words = pseg.cut(sentence)\n",
        "result = []\n",
        "for word, flag in words:\n",
        "    result.append(f\"{word}/{flag}\")\n",
        "\n",
        "print(f\"åˆ†è©çµæœ: {' '.join(result)}\")\n",
        "print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHTyszE3tcgw",
        "outputId": "75ed9089-f707-4d9f-ba9d-f2e08fa92261"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "åŸå§‹å¥å­: [æƒ…å ±] éˆé‹¸äººåŠ‡å ´ç‰ˆè•¾æ½”ç¯‡ çˆ›ç•ªèŒ„100\n",
            "\n",
            "----------------------------------------\n",
            "æ¨¡å¼ä¸€ï¼šç²¾ç¢ºæ¨¡å¼ (jieba.cut)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.541 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.541 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:16: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip_detail = re.compile(\"([\\.0-9]+|[a-zA-Z0-9]+)\")\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_internal = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._]+)\")\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:18: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_internal = re.compile(\"(\\r\\n|\\s)\")\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:21: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_num = re.compile(\"[\\.0-9]+\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "åˆ†è©çµæœ: [/ æƒ…å ±/ ]/  / éˆé‹¸äºº/ åŠ‡å ´/ ç‰ˆè•¾æ½”/ ç¯‡/  / çˆ›/ ç•ªèŒ„/ 100\n",
            "----------------------------------------\n",
            "æ¨¡å¼äºŒï¼šå…¨æ¨¡å¼ (jieba.cut(..., cut_all=True))\n",
            "åˆ†è©çµæœ: [/ æƒ…/ å ±/ ]/  / / éˆ/ é‹¸/ äºº/ åŠ‡/ å ´/ ç‰ˆ/ è•¾/ æ½”/ ç¯‡/ /  / / çˆ›/ ç•ªèŒ„/ 100\n",
            "----------------------------------------\n",
            "æ¨¡å¼ä¸‰ï¼šæœå°‹å¼•æ“æ¨¡å¼ (jieba.cut_for_search)\n",
            "åˆ†è©çµæœ: [/ æƒ…å ±/ ]/  / éˆé‹¸äºº/ åŠ‡å ´/ ç‰ˆè•¾æ½”/ ç¯‡/  / çˆ›/ ç•ªèŒ„/ 100\n",
            "----------------------------------------\n",
            "æ¨¡å¼å››ï¼šåˆ†è©èˆ‡è©æ€§æ¨™è¨» (jieba.posseg)\n",
            "åˆ†è©çµæœ: [/x æƒ…å ±/n ]/x  /x éˆé‹¸äºº/n åŠ‡å ´/n ç‰ˆè•¾æ½”ç¯‡/n  /x çˆ›/zg ç•ªèŒ„/n 100/m\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# 1. åˆå§‹åŒ–ä¸€å€‹ Counter ç‰©ä»¶ä¾†è¨˜éŒ„æ‰€æœ‰å–®è©çš„é »ç‡\n",
        "word_counts = Counter()\n",
        "\n",
        "# 2. è¨­å®šä¸€å€‹ç¯„åœï¼Œå¾ç´¢å¼• 1 åˆ° 10 (åŒ…å«)\n",
        "# åœ¨ Python çš„ range ä¸­ï¼Œrange(start, stop) æ˜¯å¾ start åˆ° stop-1\n",
        "for i in range(1, 11):\n",
        "    # ç¢ºä¿ç´¢å¼• i å­˜åœ¨ï¼Œé¿å…éŒ¯èª¤\n",
        "    if i < len(articles_data) and 'title' in articles_data[i]:\n",
        "        # å–å‡ºæ¨™é¡Œå…§å®¹\n",
        "        title_text = articles_data[i]['title']\n",
        "\n",
        "        # --- æ–‡æœ¬æ¸…ç†æ­¥é©Ÿ (é‡è¦) ---\n",
        "        # æ¸…é™¤æ¨™é»ç¬¦è™Ÿã€ç©ºæ ¼ã€æ›è¡Œç¬¦ç­‰éä¸­æ–‡å­—ç¬¦\n",
        "        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡å­—æ¯ã€æ•¸å­—\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text) # ç§»é™¤å¤§éƒ¨åˆ†æ¨™é»ç¬¦è™Ÿ\n",
        "\n",
        "        # é€²è¡Œçµå·´åˆ†è© (ä½¿ç”¨ç²¾ç¢ºæ¨¡å¼ jieba.cut)\n",
        "        # cut() è¿”å›çš„æ˜¯ä¸€å€‹ generatorï¼Œé€šå¸¸æœƒè½‰æˆ list\n",
        "        # æˆ–ç›´æ¥åœ¨è¿´åœˆä¸­ä½¿ç”¨ï¼Œé€™è£¡æˆ‘å€‘ç›´æ¥ç”¨ä¾†æ›´æ–° Counter\n",
        "        words = jieba.cut(cleaned_text, cut_all=False)\n",
        "\n",
        "        # å°‡åˆ†è©çµæœæ›´æ–°åˆ° word_counts\n",
        "        # Counter çš„ update() æ–¹æ³•å¯ä»¥ç›´æ¥æ¥æ”¶ä¸€å€‹å¯ç–Šä»£å°è±¡ï¼ˆå¦‚ wordsï¼‰\n",
        "        word_counts.update(words)\n",
        "\n",
        "# 3. æ¸…ç†åˆ†è©çµæœï¼Œç§»é™¤ç©ºæ ¼ã€å–®å€‹å­—æ¯ç­‰å¸¸è¦‹é›œè¨Š\n",
        "# å»ºç«‹ä¸€å€‹æ–°çš„ Counterï¼ŒåªåŒ…å«é•·åº¦å¤§æ–¼ 1 çš„è©ï¼Œæˆ–æ‚¨èªç‚ºæœ‰æ„ç¾©çš„è©\n",
        "final_word_counts = Counter()\n",
        "for word, count in word_counts.items():\n",
        "    # ç§»é™¤ç©ºå­—ç¬¦ä¸²ã€ç©ºæ ¼ã€æ›è¡Œç¬¦\n",
        "    if word.strip() and len(word.strip()) > 1:\n",
        "        final_word_counts[word] = count\n",
        "\n",
        "# 4. è¼¸å‡ºè©é »çµæœ (ä¾‹å¦‚ï¼Œå‰ 10 å€‹é«˜é »è©)\n",
        "print(\"--- è©é »çµ±è¨ˆçµæœ (å‰ 10 å) ---\")\n",
        "for word, count in final_word_counts.most_common(10):\n",
        "    print(f\"'{word}': {count} æ¬¡\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XnGLvKzt_l6",
        "outputId": "22ac3410-8a27-4eeb-f302-e65148290e86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- è©é »çµ±è¨ˆçµæœ (å‰ 10 å) ---\n",
            "'è¨è«–': 4 æ¬¡\n",
            "'å‘¨æ˜Ÿé¦³': 2 æ¬¡\n",
            "'ç‚ºä½•': 2 æ¬¡\n",
            "'é€™éº¼': 2 æ¬¡\n",
            "'æ¬£è³ç¾…å¿—ç¥¥': 2 æ¬¡\n",
            "'Re': 2 æ¬¡\n",
            "'æƒ…å ±': 1 æ¬¡\n",
            "'éˆé‹¸äºº': 1 æ¬¡\n",
            "'åŠ‡å ´': 1 æ¬¡\n",
            "'ç‰ˆè•¾æ½”': 1 æ¬¡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "\n",
        "# è¨­ç½®ä¸€å€‹ç°¡å–®çš„åœç”¨è©åˆ—è¡¨ï¼ˆStop Wordsï¼‰\n",
        "# é€™äº›è©é€šå¸¸é »ç‡å¾ˆé«˜ï¼Œä½†å°æ–‡ç« ä¸»é¡Œè²¢ç»å°\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])"
      ],
      "metadata": {
        "id": "x0sb-cTEvqaj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_list = []\n",
        "\n",
        "# å¾ç´¢å¼• 1 åˆ° 10 (åŒ…å«)\n",
        "for i in range(1, 11):\n",
        "    if i < len(articles_data) and 'title' in articles_data[i]:\n",
        "        title_text = articles_data[i]['title']\n",
        "\n",
        "        # æ–‡æœ¬æ¸…ç†ï¼šç§»é™¤æ¨™é»ç¬¦è™Ÿå’Œéè©èªå­—ç¬¦\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text)\n",
        "\n",
        "        # é€²è¡Œçµå·´åˆ†è©\n",
        "        # lcut() ç›´æ¥è¿”å›ä¸€å€‹åˆ—è¡¨\n",
        "        words = jieba.lcut(cleaned_text, cut_all=False)\n",
        "\n",
        "        # éæ¿¾åœç”¨è©å’Œå–®å€‹ç©ºç™½è©ï¼Œä¸¦ç”¨ç©ºæ ¼é‡æ–°é€£æ¥æˆä¸€å€‹å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿ TfidfVectorizer è™•ç†\n",
        "        filtered_words = [\n",
        "            word.strip()\n",
        "            for word in words\n",
        "            if word.strip() and len(word.strip()) > 1 and word.strip() not in stopwords\n",
        "        ]\n",
        "\n",
        "        # TfidfVectorizer éœ€è¦çš„æ˜¯å­—ä¸²å½¢å¼çš„æ–‡æª”\n",
        "        document = \" \".join(filtered_words)\n",
        "        document_list.append(document)\n",
        "\n",
        "# document_list ç¾åœ¨æ˜¯ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯ç¶“éè™•ç†çš„æ¨™é¡Œå­—ä¸²\n",
        "# print(document_list)"
      ],
      "metadata": {
        "id": "JSuthgyMvxEk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. åˆå§‹åŒ– TfidfVectorizer\n",
        "# TfidfVectorizer æœƒè™•ç†ï¼š\n",
        "#    a. å°‡æ–‡æª”è½‰æ›ç‚ºè©é »çŸ©é™£ (CountVectorizer çš„å·¥ä½œ)\n",
        "#    b. è¨ˆç®— TF-IDF æ¬Šé‡ (TfidfTransformer çš„å·¥ä½œ)\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 2. é€²è¡Œæ“¬åˆå’Œè½‰æ› (Fit and Transform)\n",
        "# tfidf_matrix æ˜¯ä¸€å€‹ç¨€ç–çŸ©é™£ (sparse matrix)ï¼ŒåŒ…å«æ‰€æœ‰æ–‡æª”çš„ TF-IDF æ¬Šé‡\n",
        "tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "\n",
        "# 3. ç²å–æ‰€æœ‰è©å½™ (ç‰¹å¾µåç¨±)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# 4. å°‡ç¨€ç–çŸ©é™£è½‰æ›ç‚º NumPy é™£åˆ—ï¼Œæ–¹ä¾¿æŸ¥çœ‹æ¬Šé‡\n",
        "tfidf_array = tfidf_matrix.toarray()"
      ],
      "metadata": {
        "id": "c0z9BSeXv31l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# å‰µå»ºä¸€å€‹å­—å…¸ä¾†å­˜å„²æ¯å€‹è©å½™åŠå…¶åœ¨æ‰€æœ‰æ–‡æª”ä¸­çš„ TF-IDF å¹³å‡æ¬Šé‡\n",
        "avg_tfidf_scores = defaultdict(float)\n",
        "\n",
        "# éæ­·æ‰€æœ‰æ–‡æª”çš„æ¬Šé‡\n",
        "for doc_weights in tfidf_array:\n",
        "    # éæ­·å–®ç¯‡æ–‡æª”ä¸­çš„æ‰€æœ‰è©å½™åŠå…¶æ¬Šé‡\n",
        "    for i, weight in enumerate(doc_weights):\n",
        "        word = feature_names[i]\n",
        "        avg_tfidf_scores[word] += weight\n",
        "\n",
        "# è¨ˆç®—å¹³å‡å€¼\n",
        "num_documents = len(document_list)\n",
        "for word in avg_tfidf_scores:\n",
        "    avg_tfidf_scores[word] /= num_documents\n",
        "\n",
        "# æŒ‰æ¬Šé‡é™åºæ’åˆ—\n",
        "sorted_avg_tfidf = sorted(avg_tfidf_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "print(\"--- æ•´å€‹æ–‡æª”é›†åˆä¸­è©å½™çš„ TF-IDF å¹³å‡æ¬Šé‡ (å‰ 10 å) ---\")\n",
        "for word, avg_weight in sorted_avg_tfidf[:10]:\n",
        "    print(f\"'{word}': {avg_weight:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk5-TJrhv5lq",
        "outputId": "3faa9f49-0b35-4e71-b7f2-9374a9e78589"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- æ•´å€‹æ–‡æª”é›†åˆä¸­è©å½™çš„ TF-IDF å¹³å‡æ¬Šé‡ (å‰ 10 å) ---\n",
            "'å‘¨æ˜Ÿé¦³': 0.0947\n",
            "'æ¬£è³ç¾…å¿—ç¥¥': 0.0947\n",
            "'ç‚ºä½•': 0.0947\n",
            "'é€™éº¼': 0.0947\n",
            "'re': 0.0753\n",
            "'godofsex': 0.0577\n",
            "'åˆªé™¤': 0.0577\n",
            "'å¤§å©¢': 0.0577\n",
            "'å¥½çœ‹': 0.0577\n",
            "'æœ‰é›·': 0.0577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "# å¥—ä»¶\n",
        "# ------------------------\n",
        "!pip install --quiet gspread google-auth openai gradio jieba scikit-learn\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# å‡è¨­ä½ çš„ Gemini API Key å« gemini_xxx\n",
        "os.environ['GEMINI_API_KEY'] = \"gemini\"\n",
        "\n",
        "# ------------------------\n",
        "# Google Sheet OAuth æˆæ¬Šï¼ˆColabï¼‰\n",
        "# ------------------------\n",
        "auth.authenticate_user()  # Colab æˆæ¬Š\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = 'çˆ¬èŸ²è³‡æ–™'\n",
        "STAT_SHEET_NAME = 'é—œéµè©çµ±è¨ˆ'\n",
        "\n",
        "# ------------------------\n",
        "# åœç”¨è©\n",
        "# ------------------------\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "# ------------------------\n",
        "# PTT çˆ¬èŸ²\n",
        "# ------------------------\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # æ‰¾ä¸Šä¸€é é€£çµ\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']  # ä¸Šä¸€é \n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            last_index = int(match.group(1)) + 1  # æœ€æ–°é  = ä¸Šä¸€é +1\n",
        "            return last_index\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"ç„¡æ³•å–å¾—èµ·å§‹é é ç¢¼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ------------------------\n",
        "# Sheet å­˜å–\n",
        "# ------------------------\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['æ¨™é¡Œ', 'ä½œè€…', 'æ—¥æœŸ', 'é€£çµ'])\n",
        "    for article in articles_data:\n",
        "        worksheet.append_row([article['title'], article['author'], article['date'], article['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        records = worksheet.get_all_records()\n",
        "        return records\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['è©å½™', 'å¹³å‡ TF-IDF'])\n",
        "    for word, weight in keywords:\n",
        "        worksheet.append_row([word, weight])\n",
        "\n",
        "# ------------------------\n",
        "# TF-IDF é—œéµè©åˆ†æ\n",
        "# ------------------------\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for record in records:\n",
        "        title_text = record['æ¨™é¡Œ']\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text)\n",
        "        words = jieba.lcut(cleaned_text, cut_all=False)\n",
        "        filtered_words = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered_words))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_tfidf_scores = defaultdict(float)\n",
        "    for doc_weights in tfidf_array:\n",
        "        for i, weight in enumerate(doc_weights):\n",
        "            avg_tfidf_scores[feature_names[i]] += weight\n",
        "    num_documents = len(document_list)\n",
        "    for word in avg_tfidf_scores:\n",
        "        avg_tfidf_scores[word] /= num_documents\n",
        "    sorted_avg_tfidf = sorted(avg_tfidf_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    return sorted_avg_tfidf[:top_n]\n",
        "\n",
        "# ------------------------\n",
        "# Gemini API æ´å¯Ÿç”Ÿæˆ\n",
        "# ------------------------\n",
        "def generate_insights(keywords):\n",
        "    try:\n",
        "        openai.api_key = os.environ.get('GEMINI_API_KEY')\n",
        "        prompt = f\"ä»¥ä¸‹æ˜¯æ–‡ç« ç†±é–€é—œéµè©ï¼š{', '.join([w for w,_ in keywords])}\\n\" \\\n",
        "                 f\"è«‹ç”Ÿæˆ 5 å¥æ´å¯Ÿæ‘˜è¦ + ä¸€æ®µ 120 å­—çµè«–ã€‚\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gemini-1.5\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"API å‘¼å«å¤±æ•—: {e}\"\n",
        "\n",
        "# ------------------------\n",
        "# Gradio ä¸»ç¨‹å¼\n",
        "# ------------------------\n",
        "def run_all(start_url=\"https://www.ptt.cc/bbs/movie/index.html\", top_n=10):\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    records = read_articles_from_sheet()\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    insights = generate_insights(top_keywords)\n",
        "\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ------------------------\n",
        "# Gradio ä»‹é¢\n",
        "# ------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## PTT é›»å½±ç‰ˆæ–‡ç« é—œéµè©åˆ†æ + æ´å¯Ÿç”Ÿæˆ (OAuth)\")\n",
        "    start_url_input = gr.Textbox(label=\"èµ·å§‹é ç¶²å€\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"ç†±é–€è©å‰ N å\")\n",
        "    run_button = gr.Button(\"åŸ·è¡Œ\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"è©å½™\", \"å¹³å‡ TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"æ´å¯Ÿæ‘˜è¦ + çµè«–\")\n",
        "\n",
        "    run_button.click(\n",
        "        run_all,\n",
        "        inputs=[start_url_input, top_n_input],\n",
        "        outputs=[keywords_output, insights_output]\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Pw239AxvfCdm",
        "outputId": "badead46-765d-4856-e895-26beb47fd63e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aaeb1d4d94d8094beb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aaeb1d4d94d8094beb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å…ˆå¯«å…¥çˆ¬èŸ²æŠ“åˆ°çš„æ–‡ç« \n",
        "write_articles_to_sheet(articles)\n",
        "\n",
        "# å†è®€å–å‰›å¯«å…¥çš„è³‡æ–™\n",
        "records = read_articles_from_sheet()\n",
        "print(f\"Sheet è®€å–è³‡æ–™ç­†æ•¸: {len(records)}\")\n",
        "for r in records[:5]:  # å°å‰5ç­†ç¢ºèª\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xRXKehFz6co",
        "outputId": "6f8ba296-7f70-4c04-ec6b-bfc795d76647"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet è®€å–è³‡æ–™ç­†æ•¸: 10\n",
            "{'æ¨™é¡Œ': '[æ–°è] ã€Œå°è¾£æ¤’ã€æº–å‚™å›æ­¸æ¼«å¨ï¼è‘›å¦®çµ²æ´¾ç‰¹æ´›', 'ä½œè€…': 'abiann', 'æ—¥æœŸ': '10/24', 'é€£çµ': 'https://www.ptt.cc/bbs/movie/M.1761321124.A.BBB.html'}\n",
            "{'æ¨™é¡Œ': '[è¨è«–] éˆé‹¸äºº åŒ—ç¾æå‰å ´ 340è¬', 'ä½œè€…': 'razzL1225', 'æ—¥æœŸ': '10/25', 'é€£çµ': 'https://www.ptt.cc/bbs/movie/M.1761321611.A.DD3.html'}\n",
            "{'æ¨™é¡Œ': '[æ™®å¥½é›·] é ­æ–‡å­—D 20é€±å¹´ 4Kä¿®å¾©ç‰ˆ', 'ä½œè€…': 'yulbin98', 'æ—¥æœŸ': '10/25', 'é€£çµ': 'https://www.ptt.cc/bbs/movie/M.1761323729.A.67A.html'}\n",
            "{'æ¨™é¡Œ': '[æ–°è] é›»å½±è³ éŒ¢ä»–é‚„æ˜¯è³º æå¥§ç´å¤šã€Šä¸€æˆ°å†æˆ°ã€‹', 'ä½œè€…': 'godofsex', 'æ—¥æœŸ': '10/25', 'é€£çµ': 'https://www.ptt.cc/bbs/movie/M.1761325800.A.291.html'}\n",
            "{'æ¨™é¡Œ': '[å¥½é›·] æ‹¿å¡é‡Œçš„ç¾éº—å‚³èªª', 'ä½œè€…': 'steelgate', 'æ—¥æœŸ': '10/25', 'é€£çµ': 'https://www.ptt.cc/bbs/movie/M.1761326678.A.10C.html'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¾ Sheet è®€å‡ºçš„ records\n",
        "top_keywords = get_top_keywords(records, top_n=5)\n",
        "print(\"å‰ 5 ç†±é–€é—œéµè©:\")\n",
        "for word, score in top_keywords:\n",
        "    print(word, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJjRAknI1-2J",
        "outputId": "0b0b02ac-31d0-4e81-bad3-fd9e0ebcca3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å‰ 5 ç†±é–€é—œéµè©:\n",
            "å…¬å‘Š 0.11376588207522505\n",
            "340 0.09309790139542415\n",
            "åŒ—ç¾ 0.09309790139542415\n",
            "æå‰ 0.09309790139542415\n",
            "éˆé‹¸äºº 0.09309790139542415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "# å¥—ä»¶å®‰è£\n",
        "# ------------------------\n",
        "!pip install --quiet gspread google-auth openai gradio jieba scikit-learn\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# ç›´æ¥å¾ç’°å¢ƒè®Šæ•¸è®€å–\n",
        "openai.api_key = os.environ.get('gemini')\n",
        "\n",
        "# ------------------------\n",
        "# Google Sheet OAuth æˆæ¬Šï¼ˆColabï¼‰\n",
        "# ------------------------\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = 'çˆ¬èŸ²è³‡æ–™'\n",
        "STAT_SHEET_NAME = 'é—œéµè©çµ±è¨ˆ'\n",
        "\n",
        "# ------------------------\n",
        "# åœç”¨è©\n",
        "# ------------------------\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "# ------------------------\n",
        "# PTT çˆ¬èŸ²\n",
        "# ------------------------\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']  # ä¸Šä¸€é \n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1  # æœ€æ–°é  = ä¸Šä¸€é +1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"ç„¡æ³•å–å¾—èµ·å§‹é é ç¢¼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A (å·²åˆªé™¤æˆ–ä¸å¯å­˜å–)\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ------------------------\n",
        "# Sheet å­˜å–\n",
        "# ------------------------\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['æ¨™é¡Œ', 'ä½œè€…', 'æ—¥æœŸ', 'é€£çµ'])\n",
        "    values = [[a['title'], a['author'], a['date'], a['href']] for a in articles_data]\n",
        "    worksheet.append_rows(values)\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['è©å½™', 'å¹³å‡ TF-IDF'])\n",
        "    values = [[w, score] for w, score in keywords]\n",
        "    worksheet.append_rows(values)\n",
        "\n",
        "# ------------------------\n",
        "# TF-IDF é—œéµè©åˆ†æ\n",
        "# ------------------------\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for record in records:\n",
        "        title_text = record['æ¨™é¡Œ']\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text)\n",
        "        words = jieba.lcut(cleaned_text, cut_all=False)\n",
        "        filtered_words = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered_words))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_tfidf_scores = defaultdict(float)\n",
        "    for doc_weights in tfidf_array:\n",
        "        for i, weight in enumerate(doc_weights):\n",
        "            avg_tfidf_scores[feature_names[i]] += weight\n",
        "    num_documents = len(document_list)\n",
        "    for word in avg_tfidf_scores:\n",
        "        avg_tfidf_scores[word] /= num_documents\n",
        "    sorted_avg_tfidf = sorted(avg_tfidf_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    return sorted_avg_tfidf[:top_n]\n",
        "\n",
        "# ------------------------\n",
        "# Gemini API æ´å¯Ÿç”Ÿæˆ (OpenAI >=1.0)\n",
        "# ------------------------\n",
        "def generate_insights(keywords):\n",
        "    try:\n",
        "        openai.api_key = os.environ.get('gemini')  # å¾ Colab Secrets è®€å–\n",
        "        prompt = f\"ä»¥ä¸‹æ˜¯æ–‡ç« ç†±é–€é—œéµè©ï¼š{', '.join([w for w,_ in keywords])}\\n\" \\\n",
        "                 f\"è«‹ç”Ÿæˆ 5 å¥æ´å¯Ÿæ‘˜è¦ + ä¸€æ®µ 120 å­—çµè«–ã€‚\"\n",
        "\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gemini-1.5\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"API å‘¼å«å¤±æ•—: {e}\"\n",
        "\n",
        "# ------------------------\n",
        "# ä¸»ç¨‹å¼\n",
        "# ------------------------\n",
        "def run_all(start_url=\"https://www.ptt.cc/bbs/movie/index.html\", top_n=10):\n",
        "    print(\"æŠ“å–æ–‡ç« ...\")\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    print(f\"æŠ“å–å®Œæˆ: {len(articles)} ç¯‡æ–‡ç« \")\n",
        "\n",
        "    print(\"å¯«å…¥ Sheet...\")\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    print(\"è®€å– Sheet...\")\n",
        "    records = read_articles_from_sheet()\n",
        "\n",
        "    print(\"TF-IDF åˆ†æç†±é–€è©...\")\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    print(\"å‘¼å« Gemini API ç”Ÿæˆæ´å¯Ÿ...\")\n",
        "    insights = generate_insights(top_keywords)\n",
        "    print(\"å®Œæˆ âœ…\")\n",
        "\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ------------------------\n",
        "# Gradio ä»‹é¢\n",
        "# ------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## PTT é›»å½±ç‰ˆæ–‡ç« é—œéµè©åˆ†æ + æ´å¯Ÿç”Ÿæˆ (OAuth)\")\n",
        "    start_url_input = gr.Textbox(label=\"èµ·å§‹é ç¶²å€\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"ç†±é–€è©å‰ N å\")\n",
        "    run_button = gr.Button(\"åŸ·è¡Œ\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"è©å½™\", \"å¹³å‡ TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"æ´å¯Ÿæ‘˜è¦ + çµè«–\", lines=10)  # å¤šè¡Œæ–‡å­—\n",
        "\n",
        "    run_button.click(\n",
        "        run_all,\n",
        "        inputs=[start_url_input, top_n_input],\n",
        "        outputs=[keywords_output, insights_output]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "NnyE2ohC38f6",
        "outputId": "87164cf7-72eb-464f-d80a-bb4b9da7803a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://638a112a44e786f76c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://638a112a44e786f76c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gspread google-auth google-generativeai gradio jieba scikit-learn beautifulsoup4 requests"
      ],
      "metadata": {
        "id": "3Hoem4cld1R1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ”‘ Gemini API è¨­å®š\n",
        "# ============================================================\n",
        "# âš ï¸ ä½ è¦å…ˆåœ¨ Colab å·¦å´é¸å–®ã€Œâš™ï¸è¨­å®š â†’ Secretsã€ä¸­å»ºç«‹ key åç¨±ï¼šgemini\n",
        "genai.configure(api_key=os.environ.get(\"gemini\"))\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¾ Google Sheet OAuth æˆæ¬Šï¼ˆColabï¼‰\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ä½ çš„è©¦ç®—è¡¨ç¶²å€\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "\n",
        "RAW_SHEET_NAME = 'çˆ¬èŸ²è³‡æ–™'\n",
        "STAT_SHEET_NAME = 'é—œéµè©çµ±è¨ˆ'\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¹ åœç”¨è©\n",
        "# ============================================================\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ•·ï¸ PTT çˆ¬èŸ²\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"âš ï¸ ç„¡æ³•å–å¾—èµ·å§‹é é ç¢¼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“Š Google Sheet æ“ä½œ\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['æ¨™é¡Œ', 'ä½œè€…', 'æ—¥æœŸ', 'é€£çµ'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['è©å½™', 'å¹³å‡ TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§  TF-IDF é—œéµè©åˆ†æ\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['æ¨™é¡Œ']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# âœ¨ Gemini æ´å¯Ÿç”Ÿæˆ\n",
        "# ============================================================\n",
        "def generate_insights(keywords):\n",
        "    try:\n",
        "        prompt = (\n",
        "            f\"ä»¥ä¸‹æ˜¯ PTT é›»å½±ç‰ˆç†±é–€é—œéµè©ï¼š{', '.join([w for w,_ in keywords])}\\n\"\n",
        "            f\"è«‹ç”¨ä¸­æ–‡ç”Ÿæˆï¼š\\n\"\n",
        "            f\"1. äº”å¥æ´å¯Ÿæ‘˜è¦ï¼ˆæ¯å¥ä»¥ã€Œâ€¢ã€é–‹é ­ï¼‰\\n\"\n",
        "            f\"2. ä¸€æ®µç´„ 120 å­—çš„çµè«–ã€‚\"\n",
        "        )\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"âŒ API å‘¼å«å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# âš™ï¸ ä¸»æµç¨‹\n",
        "# ============================================================\n",
        "def run_all(start_url=\"https://www.ptt.cc/bbs/movie/index.html\", top_n=10):\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    records = read_articles_from_sheet()\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    insights = generate_insights(top_keywords)\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ¨ Gradio ä»‹é¢\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ¬ PTT é›»å½±ç‰ˆ é—œéµè©åˆ†æ + Gemini æ´å¯Ÿæ‘˜è¦\")\n",
        "    start_url_input = gr.Textbox(label=\"èµ·å§‹é ç¶²å€\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"ç†±é–€è©å‰ N å\")\n",
        "    run_button = gr.Button(\"åŸ·è¡Œåˆ†æ\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"è©å½™\", \"å¹³å‡ TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"æ´å¯Ÿæ‘˜è¦ + çµè«–\", lines=10)  # âœ… å¤šè¡Œé¡¯ç¤º\n",
        "    run_button.click(run_all, inputs=[start_url_input, top_n_input], outputs=[keywords_output, insights_output])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "kGQusFP7euUT",
        "outputId": "46799afd-3902-42db-dc8c-eada32569b39"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://286fcf5a2c4dcf5b23.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://286fcf5a2c4dcf5b23.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¾ Google Sheet OAuth æˆæ¬Šï¼ˆColabï¼‰\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = 'çˆ¬èŸ²è³‡æ–™'\n",
        "STAT_SHEET_NAME = 'é—œéµè©çµ±è¨ˆ'\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¹ åœç”¨è©\n",
        "# ============================================================\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ•·ï¸ PTT çˆ¬èŸ²\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"âš ï¸ ç„¡æ³•å–å¾—èµ·å§‹é é ç¢¼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“Š Google Sheet æ“ä½œ\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['æ¨™é¡Œ', 'ä½œè€…', 'æ—¥æœŸ', 'é€£çµ'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['è©å½™', 'å¹³å‡ TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§  TF-IDF é—œéµè©åˆ†æ\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['æ¨™é¡Œ']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# âœ¨ Gemini æ´å¯Ÿç”Ÿæˆï¼ˆåŸ·è¡Œæ™‚è¼¸å…¥ API Keyï¼‰\n",
        "# ============================================================\n",
        "def generate_insights(keywords, user_api_key):\n",
        "    if not user_api_key:\n",
        "        return \"âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„ Gemini API Keyã€‚\"\n",
        "\n",
        "    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent\"\n",
        "    prompt = (\n",
        "        f\"ä»¥ä¸‹æ˜¯ PTT é›»å½±ç‰ˆç†±é–€é—œéµè©ï¼š{', '.join([w for w,_ in keywords])}\\n\"\n",
        "        f\"è«‹ç”¨ä¸­æ–‡ç”Ÿæˆï¼š\\n\"\n",
        "        f\"1. äº”å¥æ´å¯Ÿæ‘˜è¦ï¼ˆæ¯å¥ä»¥ã€Œâ€¢ã€é–‹é ­ï¼‰\\n\"\n",
        "        f\"2. ä¸€æ®µç´„ 120 å­—çš„çµè«–ã€‚\"\n",
        "    )\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": user_api_key}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data, timeout=60)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['candidates'][0]['content']['parts'][0]['text']\n",
        "        else:\n",
        "            return f\"âŒ API éŒ¯èª¤: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ API å‘¼å«å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# âš™ï¸ ä¸»æµç¨‹\n",
        "# ============================================================\n",
        "def run_all(start_url, top_n, api_key):\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    records = read_articles_from_sheet()\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    insights = generate_insights(top_keywords, api_key)\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ¨ Gradio ä»‹é¢\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ¬ PTT é›»å½±ç‰ˆ é—œéµè©åˆ†æ + Gemini æ´å¯Ÿæ‘˜è¦ (API Key è¼¸å…¥ç‰ˆ)\")\n",
        "    api_key_input = gr.Textbox(label=\"ğŸ”‘ è«‹è¼¸å…¥ä½ çš„ Gemini API Key\", type=\"password\", placeholder=\"AIza æˆ– g- é–‹é ­çš„é‡‘é‘°\")\n",
        "    start_url_input = gr.Textbox(label=\"èµ·å§‹é ç¶²å€\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"ç†±é–€è©å‰ N å\")\n",
        "    run_button = gr.Button(\"ğŸš€ åŸ·è¡Œåˆ†æ\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"è©å½™\", \"å¹³å‡ TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"æ´å¯Ÿæ‘˜è¦ + çµè«–\", lines=10)\n",
        "\n",
        "    run_button.click(run_all, inputs=[start_url_input, top_n_input, api_key_input], outputs=[keywords_output, insights_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "8TiBVzEYnX6i",
        "outputId": "b1326e93-5624-4d13-c85b-515fc7f15d7c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://162d7484de2755df24.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://162d7484de2755df24.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¾ Google Sheet æˆæ¬Š\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = 'çˆ¬èŸ²è³‡æ–™'\n",
        "STAT_SHEET_NAME = 'é—œéµè©çµ±è¨ˆ'\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§¹ åœç”¨è©\n",
        "# ============================================================\n",
        "stopwords = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ', 'è¨è«–', 'åˆ†äº«'])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ•·ï¸ PTT çˆ¬èŸ²\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"âš ï¸ ç„¡æ³•å–å¾—èµ·å§‹é é ç¢¼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ“Š Google Sheet æ“ä½œ\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['æ¨™é¡Œ', 'ä½œè€…', 'æ—¥æœŸ', 'é€£çµ'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['è©å½™', 'å¹³å‡ TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ§  TF-IDF åˆ†æ\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['æ¨™é¡Œ']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# ğŸ¤– Gemini API æ´å¯Ÿç”Ÿæˆ\n",
        "# ============================================================\n",
        "def generate_insights(keywords, user_api_key):\n",
        "    if not user_api_key:\n",
        "        return \"âš ï¸ è«‹è¼¸å…¥æœ‰æ•ˆçš„ Gemini API Keyã€‚\"\n",
        "\n",
        "    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "    prompt = (\n",
        "        f\"ä»¥ä¸‹æ˜¯ PTT é›»å½±ç‰ˆç†±é–€é—œéµè©ï¼š{', '.join([w for w,_ in keywords])}\\n\"\n",
        "        f\"è«‹ç”¨ä¸­æ–‡ç”Ÿæˆï¼š\\n\"\n",
        "        f\"1. äº”å¥æ´å¯Ÿæ‘˜è¦ï¼ˆæ¯å¥ä»¥ã€Œâ€¢ã€é–‹é ­ï¼‰\\n\"\n",
        "        f\"2. ä¸€æ®µç´„ 120 å­—çš„çµè«–ã€‚\"\n",
        "    )\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": user_api_key}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data, timeout=60)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['candidates'][0]['content']['parts'][0]['text']\n",
        "        else:\n",
        "            return f\"âŒ API éŒ¯èª¤: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ API å‘¼å«å¤±æ•—ï¼š{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# âš™ï¸ Gradio å¤šåˆ†é ä»‹é¢ï¼ˆé™åˆ¶çˆ¬èŸ²é æ•¸ï¼‰\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ğŸ¬ PTT é›»å½±ç‰ˆ é—œéµè©åˆ†æç³»çµ± (å¤šåˆ†é ä»‹é¢)\")\n",
        "\n",
        "    with gr.Tab(\"ğŸ•·ï¸ çˆ¬èŸ²çµæœ\"):\n",
        "        start_url_input = gr.Textbox(label=\"PTT èµ·å§‹é ç¶²å€\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "        page_slider = gr.Slider(1, 5, value=1, step=1, label=\"çˆ¬å–é æ•¸ï¼ˆå»ºè­° 1ï½3 é ï¼‰\")\n",
        "        run_button = gr.Button(\"ğŸš€ åŸ·è¡Œçˆ¬èŸ²\")\n",
        "        articles_output = gr.Dataframe(headers=[\"æ¨™é¡Œ\", \"ä½œè€…\", \"æ—¥æœŸ\", \"é€£çµ\"], label=\"çˆ¬èŸ²çµæœ\")\n",
        "\n",
        "        def run_crawler(start_url, pages):\n",
        "            gr.Info(f\"é–‹å§‹çˆ¬å– {pages} é è³‡æ–™ï¼Œè«‹ç¨å€™...\")\n",
        "            articles = fetch_ptt_articles(start_url, pages=pages)\n",
        "            if not articles:\n",
        "                return []\n",
        "            write_articles_to_sheet(articles)\n",
        "            data = [[a['title'], a['author'], a['date'], a['href']] for a in articles]\n",
        "            gr.Info(f\"âœ… æˆåŠŸçˆ¬å– {len(data)} ç­†æ–‡ç« ï¼\")\n",
        "            return data\n",
        "\n",
        "        run_button.click(run_crawler, inputs=[start_url_input, page_slider], outputs=articles_output)\n",
        "\n",
        "    with gr.Tab(\"ğŸ”  ç†±é–€è©åˆ†æ\"):\n",
        "        top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"ç†±é–€è©å‰ N å\")\n",
        "        run_tfidf_button = gr.Button(\"ğŸ“Š åŸ·è¡Œåˆ†æ\")\n",
        "        keywords_output = gr.Dataframe(headers=[\"è©å½™\", \"å¹³å‡ TF-IDF\"], label=\"TF-IDF çµæœ\")\n",
        "\n",
        "        def run_tfidf(top_n):\n",
        "            gr.Info(\"ğŸ“ˆ æ­£åœ¨é€²è¡Œ TF-IDF åˆ†æ...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"âš ï¸ å°šæœªæœ‰çˆ¬èŸ²è³‡æ–™ï¼Œè«‹å…ˆåˆ°ç¬¬ä¸€é åŸ·è¡Œçˆ¬èŸ²ï¼\")\n",
        "                return []\n",
        "            top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "            write_keywords_to_sheet(top_keywords)\n",
        "            gr.Info(\"âœ… åˆ†æå®Œæˆï¼\")\n",
        "            return top_keywords\n",
        "\n",
        "        run_tfidf_button.click(run_tfidf, inputs=top_n_input, outputs=keywords_output)\n",
        "\n",
        "    with gr.Tab(\"ğŸ¤– AI æ´å¯Ÿæ‘˜è¦\"):\n",
        "        api_key_input = gr.Textbox(label=\"ğŸ”‘ è«‹è¼¸å…¥ä½ çš„ Gemini API Key\", type=\"password\", placeholder=\"AIza æˆ– g- é–‹é ­çš„é‡‘é‘°\")\n",
        "        run_ai_button = gr.Button(\"âœ¨ ç”Ÿæˆæ‘˜è¦\")\n",
        "        ai_output = gr.Textbox(label=\"AI æ´å¯Ÿæ‘˜è¦ + çµè«–\", lines=12)\n",
        "\n",
        "        def run_ai(api_key):\n",
        "            gr.Info(\"ğŸ¤– æ­£åœ¨è«‹æ±‚ Gemini API...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"âš ï¸ å°šæœªæœ‰çˆ¬èŸ²è³‡æ–™ï¼Œè«‹å…ˆåˆ°ç¬¬ä¸€é åŸ·è¡Œçˆ¬èŸ²ï¼\")\n",
        "                return \"âš ï¸ å°šç„¡è³‡æ–™\"\n",
        "            top_keywords = get_top_keywords(records, top_n=10)\n",
        "            insights = generate_insights(top_keywords, api_key)\n",
        "            return insights\n",
        "\n",
        "        run_ai_button.click(run_ai, inputs=api_key_input, outputs=ai_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "X6oDcllJqB5V",
        "outputId": "85739867-3001-4f6d-f796-0b2e8998b3ba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a76869bbcf46b385c3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a76869bbcf46b385c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}