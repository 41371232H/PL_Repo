{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/41371232H/PL_Repo/blob/main/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HW4\n",
        "## 1. 爬蟲資料收集與存儲\n",
        "抓取 PTT 電影版文章的標題、作者、日期與連結\n",
        "資料自動寫入 Google Sheet（「爬蟲資料」工作表）\n",
        "可設定起始頁與抓取頁數，避免爬取過多資料導致延遲\n",
        "\n",
        "## 2. 詞頻與關鍵詞統計\n",
        "從 Google Sheet 讀取爬取資料\n",
        "使用 jieba 中文分詞\n",
        "計算每個詞的 TF-IDF 平均權重\n",
        "支援停用詞過濾，排除高頻無意義詞\n",
        "前 N 熱門詞結果自動回寫 Google Sheet（「關鍵詞統計」工作表）\n",
        "\n",
        "## 3. AI 洞察生成\n",
        "使用 Google Gemini 模型（如 gemini-2.0-flash）生成分析摘要\n",
        "統一產生 5 句洞察摘要 + 一段 120 字結論\n",
        "API Key 可在執行時動態輸入，保護安全性\n",
        "\n",
        "## 4. Gradio 介面\n",
        "分頁 1：爬蟲與資料顯示，顯示抓取的文章資料，可設定起始頁與抓取頁數\n",
        "分頁 2：熱門詞統計，選擇前 N 名熱門詞，顯示 TF-IDF 統計結果\n",
        "分頁 3：AI 洞察與結論，輸入 API Key 並生成分析摘要與結論，一鍵操作，直覺式介面，使用者友好\n",
        "\n",
        "### 試算表連結:https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit?gid=742427183#gid=742427183"
      ],
      "metadata": {
        "id": "BEBtbDWs0FEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 最終程式碼"
      ],
      "metadata": {
        "id": "IRKqkijSz_Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gspread google-auth google-generativeai gradio jieba scikit-learn beautifulsoup4 requests\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# 🧾 Google Sheet 授權\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = '爬蟲資料'\n",
        "STAT_SHEET_NAME = '關鍵詞統計'\n",
        "\n",
        "# ============================================================\n",
        "# 🧹 停用詞\n",
        "# ============================================================\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])\n",
        "\n",
        "# ============================================================\n",
        "# 🕷️ PTT 爬蟲\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"⚠️ 無法取得起始頁頁碼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# 📊 Google Sheet 操作\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['標題', '作者', '日期', '連結'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['詞彙', '平均 TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# 🧠 TF-IDF 分析\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['標題']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# 🤖 Gemini API 洞察生成\n",
        "# ============================================================\n",
        "def generate_insights(keywords, user_api_key):\n",
        "    if not user_api_key:\n",
        "        return \"⚠️ 請輸入有效的 Gemini API Key。\"\n",
        "\n",
        "    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "    prompt = (\n",
        "        f\"以下是 PTT 電影版熱門關鍵詞：{', '.join([w for w,_ in keywords])}\\n\"\n",
        "        f\"請用中文生成：\\n\"\n",
        "        f\"1. 五句洞察摘要（每句以「•」開頭）\\n\"\n",
        "        f\"2. 一段約 120 字的結論。\"\n",
        "    )\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": user_api_key}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data, timeout=60)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['candidates'][0]['content']['parts'][0]['text']\n",
        "        else:\n",
        "            return f\"❌ API 錯誤: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ API 呼叫失敗：{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# ⚙️ Gradio 多分頁介面（限制爬蟲頁數）\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🎬 PTT 電影版 關鍵詞分析系統 (多分頁介面)\")\n",
        "\n",
        "    with gr.Tab(\"爬蟲結果\"):\n",
        "        start_url_input = gr.Textbox(label=\"PTT 起始頁網址\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "        page_slider = gr.Slider(1, 5, value=1, step=1, label=\"爬取頁數（建議 1～3 頁）\")\n",
        "        run_button = gr.Button(\"🚀 執行爬蟲\")\n",
        "        articles_output = gr.Dataframe(headers=[\"標題\", \"作者\", \"日期\", \"連結\"], label=\"爬蟲結果\")\n",
        "\n",
        "        def run_crawler(start_url, pages):\n",
        "            gr.Info(f\"開始爬取 {pages} 頁資料，請稍候...\")\n",
        "            articles = fetch_ptt_articles(start_url, pages=pages)\n",
        "            if not articles:\n",
        "                return []\n",
        "            write_articles_to_sheet(articles)\n",
        "            data = [[a['title'], a['author'], a['date'], a['href']] for a in articles]\n",
        "            gr.Info(f\"✅ 成功爬取 {len(data)} 筆文章！\")\n",
        "            return data\n",
        "\n",
        "        run_button.click(run_crawler, inputs=[start_url_input, page_slider], outputs=articles_output)\n",
        "\n",
        "    with gr.Tab(\"熱門詞分析\"):\n",
        "        top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"熱門詞前 N 名\")\n",
        "        run_tfidf_button = gr.Button(\"📊 執行分析\")\n",
        "        keywords_output = gr.Dataframe(headers=[\"詞彙\", \"平均 TF-IDF\"], label=\"TF-IDF 結果\")\n",
        "\n",
        "        def run_tfidf(top_n):\n",
        "            gr.Info(\"📈 正在進行 TF-IDF 分析...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"⚠️ 尚未有爬蟲資料，請先到第一頁執行爬蟲！\")\n",
        "                return []\n",
        "            top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "            write_keywords_to_sheet(top_keywords)\n",
        "            gr.Info(\"✅ 分析完成！\")\n",
        "            return top_keywords\n",
        "\n",
        "        run_tfidf_button.click(run_tfidf, inputs=top_n_input, outputs=keywords_output)\n",
        "\n",
        "    with gr.Tab(\"AI 洞察摘要\"):\n",
        "        api_key_input = gr.Textbox(label=\"🔑 請輸入你的 Gemini API Key\", type=\"password\", placeholder=\"AIza 或 g- 開頭的金鑰\")\n",
        "        run_ai_button = gr.Button(\"✨ 生成摘要\")\n",
        "        ai_output = gr.Textbox(label=\"AI 洞察摘要 + 結論\", lines=12)\n",
        "\n",
        "        def run_ai(api_key):\n",
        "            gr.Info(\"🤖 正在請求 Gemini API...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"⚠️ 尚未有爬蟲資料，請先到第一頁執行爬蟲！\")\n",
        "                return \"⚠️ 尚無資料\"\n",
        "            top_keywords = get_top_keywords(records, top_n=10)\n",
        "            insights = generate_insights(top_keywords, api_key)\n",
        "            return insights\n",
        "\n",
        "        run_ai_button.click(run_ai, inputs=api_key_input, outputs=ai_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "WKCn0sqdz4_7",
        "outputId": "50503c11-e4ae-4945-8c99-f6119722162f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a096c38c2fd1acbd3e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a096c38c2fd1acbd3e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 歷程記錄"
      ],
      "metadata": {
        "id": "rFNjM0PFz6O8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6m1arRWmGMP"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_data = []"
      ],
      "metadata": {
        "id": "thL1I-Qlmrx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}"
      ],
      "metadata": {
        "id": "3XFrT8l1nfld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_previous_page_url(soup):\n",
        "    \"\"\"獲取上一頁 (更新、更舊的文章) 的連結\"\"\"\n",
        "    # PTT 的「上一頁」按鈕 HTML 結構：div class=\"btn-group btn-group-paging\"\n",
        "    paging_div = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if paging_div:\n",
        "        # PTT 頁面按鈕順序：最舊 (0), 上頁 (1), 下頁 (2), 最新 (3)\n",
        "        # 我們要找的是「上一頁」 (即更舊的文章) 的連結，索引為 1\n",
        "        prev_button = paging_div.find_all('a')[1]\n",
        "\n",
        "        # 檢查連結是否有效 (如果已經是第一頁，連結會是 '#' 或沒有 href)\n",
        "        if 'href' in prev_button.attrs:\n",
        "            return \"https://www.ptt.cc\" + prev_button['href']\n",
        "    return None"
      ],
      "metadata": {
        "id": "48nV4nTVpqhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responseIndex = requests.get(\"https://www.ptt.cc/bbs/movie/index.html\", headers=headers, timeout=5)\n",
        "html_contentIndex = responseIndex.text\n",
        "soupIndex = BeautifulSoup(html_contentIndex, 'html.parser')"
      ],
      "metadata": {
        "id": "jAxIg_mQrxc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_url = get_previous_page_url(soupIndex)"
      ],
      "metadata": {
        "id": "CeLNTFV_puZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n_hTS4QUp3En",
        "outputId": "1ba32296-4321-490f-e4f8-25bd3cce9a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.ptt.cc/bbs/movie/index10818.html'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_index_split(url):\n",
        "    \"\"\"\n",
        "    使用字串分割方法解析頁碼。\n",
        "\n",
        "    邏輯：\n",
        "    1. 以 'index' 分割網址：['...', '10808.html']\n",
        "    2. 取第二個元素 ('10808.html')\n",
        "    3. 以 '.html' 分割：['10808', '']\n",
        "    4. 取第一個元素 ('10808')\n",
        "    5. 轉換為整數\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 確保網址中包含 'index' 和 '.html'\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except IndexError:\n",
        "        print(\"錯誤: 網址結構不符合預期 (缺少 'index' 或 '.html')\")\n",
        "        return None\n",
        "    except ValueError:\n",
        "        print(\"錯誤: 提取到的內容無法轉換為數字\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "wsS1sTiRqiVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定的起始頁碼\n",
        "START_INDEX = extract_index_split(current_url)\n",
        "# 想要取得的頁數\n",
        "PAGES_TO_FETCH = 10\n",
        "\n",
        "# PTT 基礎網址\n",
        "BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "\n",
        "# 計算迴圈的結束點 (例如: 10808 - 10 + 1 = 10799)\n",
        "# range(start, stop, step) 的 stop 是不包含的，所以我們設為 START_INDEX - PAGES_TO_FETCH\n",
        "stop_index = START_INDEX - PAGES_TO_FETCH\n",
        "\n",
        "print(f\"--- 正在生成從 {START_INDEX} 到 {stop_index + 1} 的 {PAGES_TO_FETCH} 個網址 ---\")\n",
        "\n",
        "# 使用 range 迴圈，從 START_INDEX 遞減到 stop_index\n",
        "for index in range(START_INDEX, stop_index, -1):\n",
        "    # 組合完整的 URL\n",
        "    url = f\"{BASE_URL}{index}.html\"\n",
        "    print(url)\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    article_list = soup.find_all('div', class_='r-ent')\n",
        "    for article in article_list:\n",
        "        # 標題 (Title) 和 連結 (Href) 資訊通常在 div class=\"title\" 內\n",
        "        title_tag = article.find('div', class_='title').find('a')\n",
        "\n",
        "        # 排除被刪除或不可存取(標題為 - )的文章\n",
        "        if title_tag:\n",
        "            title = title_tag.text.strip()\n",
        "            href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "        else:\n",
        "            # 處理被刪除的文章 (通常標題會是 '-')\n",
        "            title = article.find('div', class_='title').text.strip()\n",
        "            href = \"N/A (已刪除或不可存取)\"\n",
        "\n",
        "        # 作者 (Author) 資訊在 div class=\"author\" 內\n",
        "        author = article.find('div', class_='author').text.strip()\n",
        "\n",
        "        # 日期 (Date) 資訊在 div class=\"date\" 內\n",
        "        date = article.find('div', class_='date').text.strip()\n",
        "\n",
        "        # 儲存資料\n",
        "        articles_data.append({\n",
        "            'title': title,\n",
        "            'date': date,\n",
        "            'author': author,\n",
        "            'href': href\n",
        "        })\n",
        "\n",
        "        # 額外要求：如果標題是指定標題，印出其對應的 href\n",
        "        # 假設我們指定要特別關注標題包含 \"新聞\" 的文章\n",
        "        # if '新聞' in title:\n",
        "        #     print(f\"[特別關注] 標題：{title} | 連結：{href}\")\n",
        "    # 註釋: 在實際的爬蟲程式中，您會將這個 url 傳遞給 requests.get() 函式來獲取內容\n",
        "    # 例如: html_content = requests.get(url, headers=headers, cookies=cookies).text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61-di9Q2rBul",
        "outputId": "2feb41a6-a3e2-4df9-ecf7-57e32cbb6ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 正在生成從 10818 到 10809 的 10 個網址 ---\n",
            "https://www.ptt.cc/bbs/movie/index10818.html\n",
            "https://www.ptt.cc/bbs/movie/index10817.html\n",
            "https://www.ptt.cc/bbs/movie/index10816.html\n",
            "https://www.ptt.cc/bbs/movie/index10815.html\n",
            "https://www.ptt.cc/bbs/movie/index10814.html\n",
            "https://www.ptt.cc/bbs/movie/index10813.html\n",
            "https://www.ptt.cc/bbs/movie/index10812.html\n",
            "https://www.ptt.cc/bbs/movie/index10811.html\n",
            "https://www.ptt.cc/bbs/movie/index10810.html\n",
            "https://www.ptt.cc/bbs/movie/index10809.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles_data"
      ],
      "metadata": {
        "id": "I4REQvLpwHwE",
        "outputId": "64c9ce1d-8474-4717-e1c6-7fc493938338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': '[問片] 一部電影開頭有紙鈔上的人頭講話',\n",
              "  'date': '10/24',\n",
              "  'author': 'wch1995',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761261468.A.9C4.html'},\n",
              " {'title': '[情報] 鏈鋸人劇場版蕾潔篇 爛番茄100',\n",
              "  'date': '10/24',\n",
              "  'author': 'vestal',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761270564.A.7B9.html'},\n",
              " {'title': '[討論] 周星馳為何這麼欣賞羅志祥？',\n",
              "  'date': '10/24',\n",
              "  'author': 'DiCaprio',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761283533.A.798.html'},\n",
              " {'title': '[討論] 康斯坦汀:驅魔神探12/05重返大銀幕',\n",
              "  'date': '10/24',\n",
              "  'author': 'smilekrtc',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761283695.A.0CA.html'},\n",
              " {'title': 'Re: [討論] 大家有哪些心中非常喜歡的電影主題曲？',\n",
              "  'date': '10/24',\n",
              "  'author': 'Allen0820',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761286588.A.1E9.html'},\n",
              " {'title': '[  有雷] 大婢咒好看',\n",
              "  'date': '10/24',\n",
              "  'author': 'ej200078914',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761289653.A.6FA.html'},\n",
              " {'title': '[好雷] 鏈鋸人蕾潔篇-大巨蛋秀泰ULTRA 4DX',\n",
              "  'date': '10/24',\n",
              "  'author': 'ljw155299',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761290069.A.609.html'},\n",
              " {'title': '[新聞] 《獵魔女團》歌手EJAE簽經紀約 與史嘉蕾同',\n",
              "  'date': '10/24',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761293654.A.257.html'},\n",
              " {'title': '(本文已被刪除) [godofsex]',\n",
              "  'date': '10/24',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (已刪除或不可存取)'},\n",
              " {'title': '[負雷] 炸彈屋    欸不是....就這樣!?',\n",
              "  'date': '10/24',\n",
              "  'author': 'sola2610',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761300583.A.5FC.html'},\n",
              " {'title': 'Re: [討論] 周星馳為何這麼欣賞羅志祥？',\n",
              "  'date': '10/24',\n",
              "  'author': 'mach1210',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761301538.A.176.html'},\n",
              " {'title': '[新聞] 《星際大戰》名導搶拍 不只史蒂芬索德柏',\n",
              "  'date': '10/24',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306055.A.321.html'},\n",
              " {'title': '[疑問雷] 國寶 有段劇情無法理解',\n",
              "  'date': '10/24',\n",
              "  'author': 'u10400068',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306271.A.D6A.html'},\n",
              " {'title': '[新聞] 強尼戴普重返好萊塢大片 主演《小氣財神',\n",
              "  'date': '10/24',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306408.A.E48.html'},\n",
              " {'title': '[LIVE] CINEMAX 22:00 旋轉瓶子',\n",
              "  'date': '10/24',\n",
              "  'author': 'ckny',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761306986.A.8F9.html'},\n",
              " {'title': '[情報] 睡覺的笨蛋預告-石黑正數原作',\n",
              "  'date': '10/24',\n",
              "  'author': 'takuminauki',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761312028.A.8C8.html'},\n",
              " {'title': '[好雷] 《鯨魚馬戲團》',\n",
              "  'date': '10/24',\n",
              "  'author': 'plurrr',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761315265.A.018.html'},\n",
              " {'title': '[好雷] 捍衛天使，推薦給想看喜劇片和基哥的粉絲',\n",
              "  'date': '10/24',\n",
              "  'author': 'Xenomorph',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761316203.A.B1C.html'},\n",
              " {'title': '[好無雷] 國寶',\n",
              "  'date': '10/24',\n",
              "  'author': 'Midiya',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761320632.A.BA2.html'},\n",
              " {'title': '[新聞] 未來兩年《蝙蝠俠2》《復仇者聯盟5》大片',\n",
              "  'date': '10/24',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761321034.A.CAE.html'},\n",
              " {'title': '[問片] 請問出現過日式佛龕場景的電影或影集??',\n",
              "  'date': '10/23',\n",
              "  'author': 'edwin11017',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761208319.A.047.html'},\n",
              " {'title': 'Re: [討論] 越獄片都唬爛吧？',\n",
              "  'date': '10/23',\n",
              "  'author': 'firefoxriko',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761208739.A.F3D.html'},\n",
              " {'title': 'Re: [新聞] 詹姆斯岡恩證實DCU不以達克賽德為反派！',\n",
              "  'date': '10/23',\n",
              "  'author': 'MoSalah',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761209606.A.79E.html'},\n",
              " {'title': '[影評] 凶降喜訊',\n",
              "  'date': '10/23',\n",
              "  'author': 'godgod777',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761210089.A.A76.html'},\n",
              " {'title': '[新聞] 國片票房達7.58億 文化部再推「大航海計畫',\n",
              "  'date': '10/23',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761210589.A.87C.html'},\n",
              " {'title': '[新聞] 《玩命關頭11》預算過高 馮迪索找到解方',\n",
              "  'date': '10/23',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761210953.A.A51.html'},\n",
              " {'title': '[新聞] 傳華納兄弟探索將被出售 詹姆斯岡恩「疑',\n",
              "  'date': '10/23',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761215098.A.979.html'},\n",
              " {'title': '[新聞] 「夜魔俠」否認出演《蜘蛛人：重生日》',\n",
              "  'date': '10/23',\n",
              "  'author': 'zkow',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761222315.A.931.html'},\n",
              " {'title': '[好無雷] 國寶',\n",
              "  'date': '10/23',\n",
              "  'author': 'yu1164',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761225395.A.F38.html'},\n",
              " {'title': '[新聞] 入伍車銀優另類出席【放飛旅行團】記者會',\n",
              "  'date': '10/23',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761227565.A.223.html'},\n",
              " {'title': '[好無雷]國寶-傳統、名聲、人性與藝術',\n",
              "  'date': '10/23',\n",
              "  'author': 'peterpan910',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761228136.A.5F9.html'},\n",
              " {'title': '[討論] 看電影時,手機關成靜音有很困難嗎==?',\n",
              "  'date': '10/23',\n",
              "  'author': 'MeiHS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761228984.A.359.html'},\n",
              " {'title': '[情報] 克里斯漢斯沃最新動作懸疑片《犯罪101》',\n",
              "  'date': '10/23',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234206.A.FFD.html'},\n",
              " {'title': '[討論] 敏卡凱莉《香檳情緣》預告',\n",
              "  'date': '10/23',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234475.A.BC2.html'},\n",
              " {'title': '[新聞] 《阿凡達》主題曲麥莉希拉獻唱！第三集',\n",
              "  'date': '10/23',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234522.A.662.html'},\n",
              " {'title': '[好雷] 《盛夏心動》同志的美好烏托邦',\n",
              "  'date': '10/23',\n",
              "  'author': 'godzillahome',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234531.A.848.html'},\n",
              " {'title': '[新聞] 梅爾吉勃遜《受難記2》躍升億萬超級大片！',\n",
              "  'date': '10/23',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761234592.A.BE9.html'},\n",
              " {'title': '[普好雷]國寶',\n",
              "  'date': '10/23',\n",
              "  'author': 'nissyyoyo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761235084.A.817.html'},\n",
              " {'title': '[新聞] 米家大戰機器人有續集 片名暗示家族反目',\n",
              "  'date': '10/23',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761235119.A.2DD.html'},\n",
              " {'title': '[負雷] 長生血戰，預告感覺不錯正片小失望',\n",
              "  'date': '10/24',\n",
              "  'author': 'WEight22',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761236577.A.440.html'},\n",
              " {'title': '[無雷] 創：戰神 等這麼多年不是為了看這種XX',\n",
              "  'date': '10/22',\n",
              "  'author': 'clurinzler',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761070334.A.C5F.html'},\n",
              " {'title': '[問片] 找一部台灣本土多篇短片合集父親主題電影',\n",
              "  'date': '10/22',\n",
              "  'author': 'zxc17893',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761077917.A.7C0.html'},\n",
              " {'title': 'Re: [普好雷]破地獄：執念才是真正的地獄',\n",
              "  'date': '10/22',\n",
              "  'author': 'xakg',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761098309.A.B0C.html'},\n",
              " {'title': '[討論] 藤本樹17-26拆成2集是不是圖利影城？？？',\n",
              "  'date': '10/22',\n",
              "  'author': 'Daboto',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761100280.A.33F.html'},\n",
              " {'title': '[討論] 動作男星Tom Hopper與艾芭共譜諜報片',\n",
              "  'date': '10/22',\n",
              "  'author': 'petestar',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761121773.A.185.html'},\n",
              " {'title': '[新聞] 伊莉莎白歐森拒演僅限串流電影 強調觀眾',\n",
              "  'date': '10/22',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761128031.A.A25.html'},\n",
              " {'title': '[新聞] 日本現象級電影燒到台灣《國寶》 導演',\n",
              "  'date': '10/22',\n",
              "  'author': 'yu1164',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761128794.A.F67.html'},\n",
              " {'title': '[討論] 為何很多舊電影都要重映？',\n",
              "  'date': '10/22',\n",
              "  'author': 'DiCaprio',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761130441.A.B25.html'},\n",
              " {'title': '[新聞] 【誰想當老大】寫下南韓疫後最強票房奇蹟',\n",
              "  'date': '10/22',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761137970.A.4F3.html'},\n",
              " {'title': '[新聞] 「驚奇隊長」回歸？演員：我不能說',\n",
              "  'date': '10/22',\n",
              "  'author': 'CYKONGG',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761139616.A.1B6.html'},\n",
              " {'title': '[新聞] X戰警外傳變種人當年票房口碑全是災難！',\n",
              "  'date': '10/22',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761139723.A.72C.html'},\n",
              " {'title': '[新聞] 詹姆斯岡恩證實DCU不以達克賽德為反派！',\n",
              "  'date': '10/22',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761147761.A.920.html'},\n",
              " {'title': '[討論] 「鬼滅之刃」日本總票房飆破367億日圓！',\n",
              "  'date': '10/22',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761147795.A.F95.html'},\n",
              " {'title': '[新聞] 史上成本最高電影冠軍排行洗牌！侏羅紀',\n",
              "  'date': '10/22',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761147827.A.5FC.html'},\n",
              " {'title': '[問片] 二三十年前的外星怪物片',\n",
              "  'date': '10/22',\n",
              "  'author': 'shanger74',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761148659.A.64A.html'},\n",
              " {'title': '[新聞] 華納探索頻道尋求出售 國際媒體市場將大洗牌',\n",
              "  'date': '10/23',\n",
              "  'author': 'horrorghost',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761151856.A.5ED.html'},\n",
              " {'title': '(本文已被刪除) [zx0158]',\n",
              "  'date': '10/23',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (已刪除或不可存取)'},\n",
              " {'title': '[討論] 從地心竄出4-6 好看嗎？',\n",
              "  'date': '10/23',\n",
              "  'author': 'p8410077',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761181006.A.E0A.html'},\n",
              " {'title': '[問片] 老男人配角整部電影只有一句台詞',\n",
              "  'date': '10/23',\n",
              "  'author': 'unique751224',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761182634.A.DB4.html'},\n",
              " {'title': '[雷] 弒愛',\n",
              "  'date': '10/23',\n",
              "  'author': 'indoorsma',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761189461.A.CFD.html'},\n",
              " {'title': '[新聞] 真人版馴龍高手2下個月就開拍 真人小嗝',\n",
              "  'date': '10/21',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760978028.A.5DD.html'},\n",
              " {'title': '[普雷]《乖狗狗》當狗狗遇上超自然恐怖現象',\n",
              "  'date': '10/21',\n",
              "  'author': 'KevinMoleaf',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760978445.A.37E.html'},\n",
              " {'title': '[負雷] 罪人真低無聊',\n",
              "  'date': '10/21',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760980202.A.0C1.html'},\n",
              " {'title': '[新聞] 創：戰神票房慘淡迪士尼估虧損1.3億美元',\n",
              "  'date': '10/21',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761009363.A.17E.html'},\n",
              " {'title': '[討論] 阿凡達1是否過譽',\n",
              "  'date': '10/21',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761015856.A.796.html'},\n",
              " {'title': '[超好雷] 大地英豪',\n",
              "  'date': '10/21',\n",
              "  'author': 'skywalker019',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761018730.A.D38.html'},\n",
              " {'title': '[新聞] 王心凌合作大咖女星！美聲唱進三大國際影',\n",
              "  'date': '10/21',\n",
              "  'author': 'CYKONGG',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761027130.A.360.html'},\n",
              " {'title': 'Re: [贈票] 【只為你遺憾】感動北中南特映搶先看',\n",
              "  'date': '10/21',\n",
              "  'author': 'cecilia1220',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761031550.A.47C.html'},\n",
              " {'title': 'Re: [新聞] 好萊塢陷入平庸？雷利史考特批爛片成災',\n",
              "  'date': '10/21',\n",
              "  'author': 'xross',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761038981.A.709.html'},\n",
              " {'title': '[新聞] 超人的票房獲利是鋼鐵英雄的三倍',\n",
              "  'date': '10/21',\n",
              "  'author': 'sonans',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761041712.A.2B6.html'},\n",
              " {'title': '[新聞] <迷宮裡的魔術師>福山雅治告白台灣秀魔術',\n",
              "  'date': '10/21',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761041831.A.75D.html'},\n",
              " {'title': '[請益] 打破第四面牆跟觀眾對話',\n",
              "  'date': '10/21',\n",
              "  'author': 'gsp0309099',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761052661.A.B16.html'},\n",
              " {'title': '[討論] 越獄片都唬爛吧？',\n",
              "  'date': '10/21',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761054868.A.81D.html'},\n",
              " {'title': 'Re: [討論] 越獄片都唬爛吧？',\n",
              "  'date': '10/21',\n",
              "  'author': 'MeiHS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761057211.A.BC4.html'},\n",
              " {'title': '[情報] 朴贊郁《徵人啟弒》爛番茄開盤',\n",
              "  'date': '10/21',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761059310.A.E7B.html'},\n",
              " {'title': '[討論] 《山怪巨魔 2》正式預告',\n",
              "  'date': '10/21',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061088.A.1F7.html'},\n",
              " {'title': '[新聞] 「浩克」馬克魯法洛坦言獨立電影因為「',\n",
              "  'date': '10/21',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061126.A.C4B.html'},\n",
              " {'title': '[新聞] 亞當崔佛曾籌拍星戰「凱羅忍」外傳！片',\n",
              "  'date': '10/21',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061158.A.CA1.html'},\n",
              " {'title': '[新聞] 《咒術迴戰0》重返大銀幕全新限量特典登場',\n",
              "  'date': '10/21',\n",
              "  'author': 'hvariables',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761061809.A.DCE.html'},\n",
              " {'title': '[情報] 《你留下的痕跡》首支預告',\n",
              "  'date': '10/22',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1761064901.A.BFE.html'},\n",
              " {'title': '[請益] 粉絲向紀錄片為什麼要賣到550？',\n",
              "  'date': '10/20',\n",
              "  'author': 'summer07077',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760951541.A.7AF.html'},\n",
              " {'title': '[好雷]《乖狗狗》，牠看見的，聽見的，經歷著的',\n",
              "  'date': '10/20',\n",
              "  'author': 'a122239',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760951767.A.78A.html'},\n",
              " {'title': '[好雷]《藤本樹 17-26》，藤本樹老師筆下的世界',\n",
              "  'date': '10/20',\n",
              "  'author': 'a122239',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760951877.A.333.html'},\n",
              " {'title': '[新聞] 漫威為何沒獨立製作浩克電影 馬克魯法洛解',\n",
              "  'date': '10/20',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760953024.A.25D.html'},\n",
              " {'title': '[新聞] 好萊塢陷入平庸？雷利史考特批爛片成災',\n",
              "  'date': '10/20',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760954570.A.A31.html'},\n",
              " {'title': '[好無雷] 鏈鋸人 青埔新光Dolby Cinema',\n",
              "  'date': '10/20',\n",
              "  'author': 'ec75413',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760960739.A.112.html'},\n",
              " {'title': '[新聞] 7大名導齊聚分享【藤本樹17-26】創作秘辛',\n",
              "  'date': '10/20',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760961390.A.932.html'},\n",
              " {'title': '[新聞] 亞馬遜為《007》系列開頭加上內容警語',\n",
              "  'date': '10/20',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760961462.A.E49.html'},\n",
              " {'title': '[討論] 鏈鋸人蕾潔篇即將上映SCREENX版',\n",
              "  'date': '10/20',\n",
              "  'author': 'nobady98',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760961929.A.096.html'},\n",
              " {'title': '[情報] 朴贊郁 影史經典《原罪犯 4K數位修復版》',\n",
              "  'date': '10/20',\n",
              "  'author': 'godofsex',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760964111.A.0C6.html'},\n",
              " {'title': '[好雷] 風葵的夏日物語',\n",
              "  'date': '10/20',\n",
              "  'author': 'backfish',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760964566.A.785.html'},\n",
              " {'title': '[討論] 顏值演技不錯卻紅不起來的演員',\n",
              "  'date': '10/20',\n",
              "  'author': 'larry0323',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760965801.A.572.html'},\n",
              " {'title': '[新聞] 查克史奈德曝光喪鐘新照片！粉絲熱議希望',\n",
              "  'date': '10/20',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760973330.A.82C.html'},\n",
              " {'title': '[問片] 開店老闆喪偶認識第二春的愛情片',\n",
              "  'date': '10/20',\n",
              "  'author': 'markkkkkkkk',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760973346.A.E36.html'},\n",
              " {'title': '[討論] 創：戰神...迪士尼也太悲哀了吧',\n",
              "  'date': '10/20',\n",
              "  'author': 'BlacKlonely',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760974069.A.89A.html'},\n",
              " {'title': 'Re: 刺激1995  自欺欺人',\n",
              "  'date': '10/20',\n",
              "  'author': 'revanchist',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760974820.A.1B8.html'},\n",
              " {'title': '羅浮宮竊盜案的既視感',\n",
              "  'date': '10/20',\n",
              "  'author': 'brothersun',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975197.A.B76.html'},\n",
              " {'title': '[新聞] 湯姆艾利斯自曝曾試鏡「驚奇先生」！錯',\n",
              "  'date': '10/20',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975202.A.CEA.html'},\n",
              " {'title': '[討論] 勞勃狄尼洛表示仍然需要與川普戰鬥！',\n",
              "  'date': '10/20',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975239.A.69B.html'},\n",
              " {'title': '[新聞] 史柯西斯持續尋找下一個故事',\n",
              "  'date': '10/20',\n",
              "  'author': 'hvariables',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760975386.A.203.html'},\n",
              " {'title': '[討論] 大裂',\n",
              "  'date': '10/19',\n",
              "  'author': 'jeeplong',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760885070.A.4BF.html'},\n",
              " {'title': '[新聞] 舒淇中國新片突遭撤檔！首日票房僅73萬元',\n",
              "  'date': '10/19',\n",
              "  'author': 'hvariables',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760885446.A.584.html'},\n",
              " {'title': '[情報] 10/19 當週9部新片預告+Youtube觀看排行',\n",
              "  'date': '10/19',\n",
              "  'author': 'bestbamboo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760886992.A.2BB.html'},\n",
              " {'title': '[好雷] 藤本樹part2 有趣無胃痛',\n",
              "  'date': '10/19',\n",
              "  'author': 'jack5u06d93',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760887468.A.B91.html'},\n",
              " {'title': '[好雷] 第一滴血二',\n",
              "  'date': '10/19',\n",
              "  'author': 'LVDior',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760888518.A.185.html'},\n",
              " {'title': '[討論] 迷宮裡的魔術師電影預告',\n",
              "  'date': '10/19',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760889083.A.E77.html'},\n",
              " {'title': '[新聞] 《史瑞克5》劇情設定曝光！史瑞克一行人',\n",
              "  'date': '10/19',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760889110.A.010.html'},\n",
              " {'title': '[新聞] 鬼滅全球票房突破948億日圓！2025第五名',\n",
              "  'date': '10/19',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760889138.A.AE5.html'},\n",
              " {'title': '[請益] 不可能的任務：最終清算  一個問題(有雷)',\n",
              "  'date': '10/20',\n",
              "  'author': 'Midiya',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760890108.A.75A.html'},\n",
              " {'title': '[好雷] 《徵人啟弒》',\n",
              "  'date': '10/20',\n",
              "  'author': 'plurrr',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760890388.A.077.html'},\n",
              " {'title': 'Re: [討論] 台灣電影院為什麼不能吶喊',\n",
              "  'date': '10/20',\n",
              "  'author': 'NuCat',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760899297.A.69C.html'},\n",
              " {'title': '[] ［豪洨雷］捍衛天使，豪洨片',\n",
              "  'date': '10/20',\n",
              "  'author': 'iamdiff',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760921493.A.C51.html'},\n",
              " {'title': '[好雷] 風林火山',\n",
              "  'date': '10/20',\n",
              "  'author': 'ume',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760927383.A.2FC.html'},\n",
              " {'title': '[閒聊] 媽的多重宇宙 網飛正常翻譯版',\n",
              "  'date': '10/20',\n",
              "  'author': 'winnietslock',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760928774.A.496.html'},\n",
              " {'title': '(本文已被刪除) [ilv1181023]',\n",
              "  'date': '10/20',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (已刪除或不可存取)'},\n",
              " {'title': '刺激1995  自欺欺人',\n",
              "  'date': '10/20',\n",
              "  'author': 'revanchist',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760937413.A.4D4.html'},\n",
              " {'title': '[討論] 鬼滅之刃台灣狂飆8.19億，榮登台灣影史第',\n",
              "  'date': '10/20',\n",
              "  'author': 'badmonkey',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760942642.A.FEA.html'},\n",
              " {'title': '[好雷] 徵人啟弒No Other Choice',\n",
              "  'date': '10/20',\n",
              "  'author': 'ueiwei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760943280.A.6D7.html'},\n",
              " {'title': '[雷] 好雷-創戰神imax',\n",
              "  'date': '10/20',\n",
              "  'author': 'S26',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760948941.A.2E4.html'},\n",
              " {'title': '贈票 今晚大婢咒 電影特映券*1',\n",
              "  'date': '10/20',\n",
              "  'author': 'anggunuggna',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760950840.A.37D.html'},\n",
              " {'title': '[新聞] 「白雪公主」瑞秋齊格勒接好萊塢大片！',\n",
              "  'date': '10/18',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760802318.A.713.html'},\n",
              " {'title': '[新聞] 鬼滅席捲韓國影壇！韓媒：全輸日本動畫！',\n",
              "  'date': '10/18',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760802355.A.A01.html'},\n",
              " {'title': '[好雷] 捍衛天使  窮人生活就是費盡全力了',\n",
              "  'date': '10/18',\n",
              "  'author': 'callhek',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760803141.A.F8E.html'},\n",
              " {'title': '[好雷] 乖狗狗',\n",
              "  'date': '10/19',\n",
              "  'author': 'wusbetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760804485.A.789.html'},\n",
              " {'title': '[ 好 雷] 藤本樹part1 劇情大雷',\n",
              "  'date': '10/19',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760806566.A.B59.html'},\n",
              " {'title': '[ 普負雷] 風林火山：黑社會警匪片的復古情懷',\n",
              "  'date': '10/19',\n",
              "  'author': 'rabinson',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760806962.A.E38.html'},\n",
              " {'title': '[討論] 台灣電影院為什麼不能吶喊',\n",
              "  'date': '10/19',\n",
              "  'author': 'Fucker5566',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760829534.A.2AF.html'},\n",
              " {'title': '[好雷] 捍衛天使',\n",
              "  'date': '10/19',\n",
              "  'author': 'wusbetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760833505.A.3BA.html'},\n",
              " {'title': 'Re: [討論] 台灣電影院為什麼不能吶喊',\n",
              "  'date': '10/19',\n",
              "  'author': 'a95462015',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760844591.A.49B.html'},\n",
              " {'title': '[好雷]乖狗狗_主人我會保護你...即使面對死亡',\n",
              "  'date': '10/19',\n",
              "  'author': 'neilhister',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760853770.A.CC5.html'},\n",
              " {'title': '[好雷] 鏈鋸人 蕾潔篇',\n",
              "  'date': '10/19',\n",
              "  'author': 'iamflash',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760855788.A.F6A.html'},\n",
              " {'title': '[討論] 電影院有讓人變得遵守規矩的魔力吧？',\n",
              "  'date': '10/19',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760863343.A.056.html'},\n",
              " {'title': '[討論] Netflix: 吳宇森的 The killer',\n",
              "  'date': '10/19',\n",
              "  'author': 'pacino',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760863975.A.EBF.html'},\n",
              " {'title': 'Re: [討論] 台灣電影院為什麼不能吶喊',\n",
              "  'date': '10/19',\n",
              "  'author': 'goetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760864338.A.B04.html'},\n",
              " {'title': '[LIVE] AXN 21:00 末日預言',\n",
              "  'date': '10/19',\n",
              "  'author': 'ckny',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760866681.A.C0A.html'},\n",
              " {'title': '[討論] HMO MAX罪人突然沒中文字幕?',\n",
              "  'date': '10/19',\n",
              "  'author': 'awestricken',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760867681.A.D95.html'},\n",
              " {'title': '(本文已被刪除) [larry0323]',\n",
              "  'date': '10/19',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (已刪除或不可存取)'},\n",
              " {'title': '[請益] 百年來，經典電影最多是1970年代嗎？',\n",
              "  'date': '10/19',\n",
              "  'author': 'nissan168',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760871760.A.C82.html'},\n",
              " {'title': '[情報] 《劇場版 咒術迴戰 澀谷事變x死滅迴游》',\n",
              "  'date': '10/19',\n",
              "  'author': 'lo17593ve',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760878943.A.607.html'},\n",
              " {'title': '[情報] podcast:侯孝賢_風兒踢踏踩',\n",
              "  'date': '10/19',\n",
              "  'author': 'aton17',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760879949.A.186.html'},\n",
              " {'title': '[討論] 東京comic con巨星雲集...',\n",
              "  'date': '10/18',\n",
              "  'author': 'goetz',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760723092.A.2C3.html'},\n",
              " {'title': '[普雷] 泥娃娃（內文有雷）',\n",
              "  'date': '10/18',\n",
              "  'author': 'cc001225',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760730185.A.D7F.html'},\n",
              " {'title': '[新聞] 《國有器官》在韓國影院首映 引觀眾共鳴',\n",
              "  'date': '10/18',\n",
              "  'author': 'pulagu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760741751.A.FA9.html'},\n",
              " {'title': 'Re: [討論] 最頂的愛情電影？',\n",
              "  'date': '10/18',\n",
              "  'author': 'xross',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760748092.A.42D.html'},\n",
              " {'title': '[討論] 臺灣觀影日本化？',\n",
              "  'date': '10/18',\n",
              "  'author': 'DiCaprio',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760750041.A.132.html'},\n",
              " {'title': '[新聞] 電影產業回不去了？ 網友觀察「幾個面向',\n",
              "  'date': '10/18',\n",
              "  'author': 'sony577',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760753550.A.E62.html'},\n",
              " {'title': '[好雷] 幸福路上',\n",
              "  'date': '10/18',\n",
              "  'author': 'waakye',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760764742.A.BF6.html'},\n",
              " {'title': '[  普雷] 乖狗狗 為什麼我看不懂',\n",
              "  'date': '10/18',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760765253.A.0C8.html'},\n",
              " {'title': '(本文已被刪除) [larry0323]',\n",
              "  'date': '10/18',\n",
              "  'author': '-',\n",
              "  'href': 'N/A (已刪除或不可存取)'},\n",
              " {'title': '[負雷] 世界就是這樣結束的',\n",
              "  'date': '10/18',\n",
              "  'author': 'j022015',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760771186.A.219.html'},\n",
              " {'title': '[好雷] 《藤本樹17-26》純愛控+妹控大禮包',\n",
              "  'date': '10/18',\n",
              "  'author': 'godzillahome',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760771837.A.2B0.html'},\n",
              " {'title': '[LIVE] HBO 21:00 無線殺機',\n",
              "  'date': '10/18',\n",
              "  'author': 'ckny',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760776629.A.934.html'},\n",
              " {'title': 'Re: [  普雷] 乖狗狗 為什麼我看不懂',\n",
              "  'date': '10/18',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760781210.A.59B.html'},\n",
              " {'title': '[普雷] 捍衛任務：復仇芭蕾',\n",
              "  'date': '10/18',\n",
              "  'author': 'darkofpolo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760782032.A.99B.html'},\n",
              " {'title': '[普無雷] 闇黑電話2',\n",
              "  'date': '10/18',\n",
              "  'author': 'setyounger',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760783253.A.9E7.html'},\n",
              " {'title': '[選片] 國寶風暴 or 闇黑電話 or 乖狗狗',\n",
              "  'date': '10/18',\n",
              "  'author': 'Daboto',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760786986.A.9DB.html'},\n",
              " {'title': '[負雷] 一百公尺',\n",
              "  'date': '10/18',\n",
              "  'author': 'larry8550',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760791258.A.895.html'},\n",
              " {'title': 'Fw: [普雷] 《風林火山》「傳說」的終點，是連滾帶爬',\n",
              "  'date': '10/18',\n",
              "  'author': 'elvayanzimei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760800558.A.B7B.html'},\n",
              " {'title': '[片單] 懸疑找人的片',\n",
              "  'date': '10/18',\n",
              "  'author': 'moneybuy',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760800744.A.379.html'},\n",
              " {'title': '[討論] 塔提亞娜瑪斯拉妮《顫懼》預告',\n",
              "  'date': '10/18',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760802290.A.728.html'},\n",
              " {'title': '[新聞] 再度參與諾蘭電影的感受？ 艾略特佩吉',\n",
              "  'date': '10/17',\n",
              "  'author': 'mashmabo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760669253.A.12E.html'},\n",
              " {'title': '[討論] 天劫倒數2首支預告',\n",
              "  'date': '10/17',\n",
              "  'author': 'j31404',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760670398.A.481.html'},\n",
              " {'title': '[新聞] Lisa首度挑戰大銀幕 出演《驚天營救：泰戈',\n",
              "  'date': '10/17',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760672064.A.F08.html'},\n",
              " {'title': '[新聞] 休養生息金凱瑞 有意演真人版《傑森一家》',\n",
              "  'date': '10/17',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760672788.A.58B.html'},\n",
              " {'title': '[新聞]日本《鏈鋸人》+《鬼滅之刃》席捲韓國影壇',\n",
              "  'date': '10/17',\n",
              "  'author': 'toebb',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760673467.A.1A3.html'},\n",
              " {'title': '[討論] 天王周杰倫【頭文字D】20周年 4K修復版',\n",
              "  'date': '10/17',\n",
              "  'author': 'Oni028',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760676049.A.4B2.html'},\n",
              " {'title': '[  好雷] 藤本樹17-26',\n",
              "  'date': '10/17',\n",
              "  'author': 'Liaochiharu',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760679013.A.D67.html'},\n",
              " {'title': '[普雷]《黑薔薇之館》愛的毀滅、罪孽與吞噬',\n",
              "  'date': '10/17',\n",
              "  'author': 'KevinMoleaf',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760679772.A.1E8.html'},\n",
              " {'title': '[好雷] 日本有國寶中國有戲台',\n",
              "  'date': '10/17',\n",
              "  'author': 'godgod777',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760683943.A.3F5.html'},\n",
              " {'title': '[好雷] 徵人啟弒No Other Choice',\n",
              "  'date': '10/17',\n",
              "  'author': 'ueiwei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760684400.A.1D5.html'},\n",
              " {'title': '[好雷] 藤本樹17-26 好雷',\n",
              "  'date': '10/17',\n",
              "  'author': 'VANDAS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760690640.A.066.html'},\n",
              " {'title': '[普好雷] 泥娃娃',\n",
              "  'date': '10/17',\n",
              "  'author': 'HuangYa',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760691055.A.4F7.html'},\n",
              " {'title': '[ 普雷] 風林火山',\n",
              "  'date': '10/17',\n",
              "  'author': 'AV771118',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760705601.A.8E5.html'},\n",
              " {'title': '[無雷] 創：戰神 大巨蛋秀泰ULTRA 4DX初體驗',\n",
              "  'date': '10/17',\n",
              "  'author': 'mmm9poo',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760713115.A.309.html'},\n",
              " {'title': '[普雷] 捍衛任務：復仇芭蕾 滿滿ACG梗',\n",
              "  'date': '10/17',\n",
              "  'author': 'defenser',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760713395.A.F2B.html'},\n",
              " {'title': '[討論] 馬克華柏格《全家逃走中2》預告',\n",
              "  'date': '10/17',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716316.A.08B.html'},\n",
              " {'title': '[新聞] 勞倫斯費許朋想當「X教授」！不想演星際',\n",
              "  'date': '10/17',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716349.A.A12.html'},\n",
              " {'title': '[新聞] 基努李維:到好萊塢就被要求改名KC李維！',\n",
              "  'date': '10/17',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716380.A.89E.html'},\n",
              " {'title': '[新聞] 失控猩猩掀《猩瘋血雨》！爛番茄88％好評恐怖片 首曝預告',\n",
              "  'date': '10/17',\n",
              "  'author': 'hihihihehehe',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760716506.A.608.html'},\n",
              " {'title': 'Re: [討論] 最頂的愛情電影？',\n",
              "  'date': '10/18',\n",
              "  'author': 'ivorysoap',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760721115.A.AFB.html'},\n",
              " {'title': '[新聞] 《閃電俠》票房、口碑皆輸 導演：沒看過',\n",
              "  'date': '10/16',\n",
              "  'author': 'CYKONGG',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760596833.A.2C4.html'},\n",
              " {'title': '[新聞]《阿凡達》兩集製作紀錄片 11月Disney+上線',\n",
              "  'date': '10/16',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760597567.A.CAC.html'},\n",
              " {'title': '[新聞] 韓星振永接演台韓愛情片 與李沐、宋柏緯主',\n",
              "  'date': '10/16',\n",
              "  'author': 'Articuno',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760598386.A.6FB.html'},\n",
              " {'title': '[討論] 年輕沙贊Asher Angel的近況?',\n",
              "  'date': '10/16',\n",
              "  'author': 'pttnowash',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760613123.A.270.html'},\n",
              " {'title': '[討論] 人型蜈蚣怎麼沒續集？',\n",
              "  'date': '10/16',\n",
              "  'author': 'ilv1181023',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760614719.A.478.html'},\n",
              " {'title': '[新聞] 【放飛旅行團】五大夢幻卡司即興笑力全開',\n",
              "  'date': '10/16',\n",
              "  'author': 'kkaicd1',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760617626.A.5DC.html'},\n",
              " {'title': '[新聞] 裴斗娜、西島秀俊將來台上金馬大師課！重',\n",
              "  'date': '10/16',\n",
              "  'author': 'yu1164',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760618844.A.DD6.html'},\n",
              " {'title': '[轉錄] 鄭浩南很像杜德偉卻無法大紅',\n",
              "  'date': '10/16',\n",
              "  'author': 'cjol',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760620082.A.75D.html'},\n",
              " {'title': '[好無雷] 乖狗狗',\n",
              "  'date': '10/16',\n",
              "  'author': 'wholehearted',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760624988.A.BEF.html'},\n",
              " {'title': '[討論] 最頂的愛情電影？',\n",
              "  'date': '10/16',\n",
              "  'author': 'c48074',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760625279.A.B77.html'},\n",
              " {'title': '[討論] MIB2的RAP',\n",
              "  'date': '10/16',\n",
              "  'author': 'apeshit5566',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760626937.A.D17.html'},\n",
              " {'title': '[討論] 狄倫歐布萊恩、瑞秋麥亞當斯《求救》預告',\n",
              "  'date': '10/16',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760627121.A.7DA.html'},\n",
              " {'title': '[好雷] 神鬼交鋒 偽裝、孤單與生命的掙扎',\n",
              "  'date': '10/16',\n",
              "  'author': 'PiDaiShuei',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760627376.A.1BD.html'},\n",
              " {'title': '[新聞] 李奧納多《一戰再戰》將虧損超過1億美元！',\n",
              "  'date': '10/16',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760627948.A.54C.html'},\n",
              " {'title': '[新聞] 巨石強森被諾蘭讚演技！為他獲奧斯卡提名',\n",
              "  'date': '10/16',\n",
              "  'author': 'abiann',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760628758.A.03E.html'},\n",
              " {'title': '[討論] 哪些你認為經典電影海報但你從沒想看正片',\n",
              "  'date': '10/16',\n",
              "  'author': 'ivorysoap',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760629002.A.0D3.html'},\n",
              " {'title': '[新聞] 看電影無法滿足 乾脆自己拍一部！《厄靈',\n",
              "  'date': '10/17',\n",
              "  'author': 'sony577',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760647434.A.740.html'},\n",
              " {'title': 'Re: [轉錄] 鄭浩南很像杜德偉卻無法大紅',\n",
              "  'date': '10/17',\n",
              "  'author': 'godgod777',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760659814.A.746.html'},\n",
              " {'title': '[討論] 今年暑假檔的電影,算是動畫強過真人嗎?',\n",
              "  'date': '10/17',\n",
              "  'author': 'MeiHS',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760665647.A.8AB.html'},\n",
              " {'title': 'Re: [請益] 哪些電影改變拍攝方式？',\n",
              "  'date': '10/17',\n",
              "  'author': 'icrose',\n",
              "  'href': 'https://www.ptt.cc/bbs/movie/M.1760667017.A.044.html'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = articles_data[1]['title']"
      ],
      "metadata": {
        "id": "Ak6rmgQBpruY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "\n",
        "# 待分詞的中文句子\n",
        "print(f\"原始句子: {sentence}\\n\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- 1. 精確模式 (Default Mode) ---\n",
        "# 這是最常用的模式，嘗試將句子最精確地切開，適合文本分析。\n",
        "print(\"模式一：精確模式 (jieba.cut)\")\n",
        "# jieba.cut 返回的是一個迭代器 (iterator)\n",
        "seg_list_precise = jieba.cut(sentence, cut_all=False)\n",
        "# 使用 '/ ' 將結果串接起來，方便輸出\n",
        "print(f\"分詞結果: {'/ '.join(seg_list_precise)}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- 2. 全模式 (Full Mode) ---\n",
        "# 會掃描出句子中所有可能的詞語，速度最快，但結果可能有大量重疊。\n",
        "print(\"模式二：全模式 (jieba.cut(..., cut_all=True))\")\n",
        "seg_list_all = jieba.cut(sentence, cut_all=True)\n",
        "print(f\"分詞結果: {'/ '.join(seg_list_all)}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- 3. 搜尋引擎模式 (Search Engine Mode) ---\n",
        "# 在精確模式的基礎上，對長詞再次進行細分，適合用於搜尋引擎建立索引。\n",
        "print(\"模式三：搜尋引擎模式 (jieba.cut_for_search)\")\n",
        "seg_list_search = jieba.cut_for_search(sentence)\n",
        "print(f\"分詞結果: {'/ '.join(seg_list_search)}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "\n",
        "# --- 4. 詞性標註 (Optional: Add Part-of-Speech Tagging) ---\n",
        "# jieba.posseg 可以在分詞的同時標註詞性 (例如 n: 名詞, v: 動詞)\n",
        "import jieba.posseg as pseg\n",
        "print(\"模式四：分詞與詞性標註 (jieba.posseg)\")\n",
        "words = pseg.cut(sentence)\n",
        "result = []\n",
        "for word, flag in words:\n",
        "    result.append(f\"{word}/{flag}\")\n",
        "\n",
        "print(f\"分詞結果: {' '.join(result)}\")\n",
        "print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHTyszE3tcgw",
        "outputId": "75ed9089-f707-4d9f-ba9d-f2e08fa92261"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始句子: [情報] 鏈鋸人劇場版蕾潔篇 爛番茄100\n",
            "\n",
            "----------------------------------------\n",
            "模式一：精確模式 (jieba.cut)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.541 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.541 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:16: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_skip_detail = re.compile(\"([\\.0-9]+|[a-zA-Z0-9]+)\")\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:17: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_han_internal = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._]+)\")\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:18: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  re_skip_internal = re.compile(\"(\\r\\n|\\s)\")\n",
            "/usr/local/lib/python3.12/dist-packages/jieba/posseg/__init__.py:21: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  re_num = re.compile(\"[\\.0-9]+\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分詞結果: [/ 情報/ ]/  / 鏈鋸人/ 劇場/ 版蕾潔/ 篇/  / 爛/ 番茄/ 100\n",
            "----------------------------------------\n",
            "模式二：全模式 (jieba.cut(..., cut_all=True))\n",
            "分詞結果: [/ 情/ 報/ ]/  / / 鏈/ 鋸/ 人/ 劇/ 場/ 版/ 蕾/ 潔/ 篇/ /  / / 爛/ 番茄/ 100\n",
            "----------------------------------------\n",
            "模式三：搜尋引擎模式 (jieba.cut_for_search)\n",
            "分詞結果: [/ 情報/ ]/  / 鏈鋸人/ 劇場/ 版蕾潔/ 篇/  / 爛/ 番茄/ 100\n",
            "----------------------------------------\n",
            "模式四：分詞與詞性標註 (jieba.posseg)\n",
            "分詞結果: [/x 情報/n ]/x  /x 鏈鋸人/n 劇場/n 版蕾潔篇/n  /x 爛/zg 番茄/n 100/m\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# 1. 初始化一個 Counter 物件來記錄所有單詞的頻率\n",
        "word_counts = Counter()\n",
        "\n",
        "# 2. 設定一個範圍，從索引 1 到 10 (包含)\n",
        "# 在 Python 的 range 中，range(start, stop) 是從 start 到 stop-1\n",
        "for i in range(1, 11):\n",
        "    # 確保索引 i 存在，避免錯誤\n",
        "    if i < len(articles_data) and 'title' in articles_data[i]:\n",
        "        # 取出標題內容\n",
        "        title_text = articles_data[i]['title']\n",
        "\n",
        "        # --- 文本清理步驟 (重要) ---\n",
        "        # 清除標點符號、空格、換行符等非中文字符\n",
        "        # 使用正則表達式，保留中文、英文字母、數字\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text) # 移除大部分標點符號\n",
        "\n",
        "        # 進行結巴分詞 (使用精確模式 jieba.cut)\n",
        "        # cut() 返回的是一個 generator，通常會轉成 list\n",
        "        # 或直接在迴圈中使用，這裡我們直接用來更新 Counter\n",
        "        words = jieba.cut(cleaned_text, cut_all=False)\n",
        "\n",
        "        # 將分詞結果更新到 word_counts\n",
        "        # Counter 的 update() 方法可以直接接收一個可疊代對象（如 words）\n",
        "        word_counts.update(words)\n",
        "\n",
        "# 3. 清理分詞結果，移除空格、單個字母等常見雜訊\n",
        "# 建立一個新的 Counter，只包含長度大於 1 的詞，或您認為有意義的詞\n",
        "final_word_counts = Counter()\n",
        "for word, count in word_counts.items():\n",
        "    # 移除空字符串、空格、換行符\n",
        "    if word.strip() and len(word.strip()) > 1:\n",
        "        final_word_counts[word] = count\n",
        "\n",
        "# 4. 輸出詞頻結果 (例如，前 10 個高頻詞)\n",
        "print(\"--- 詞頻統計結果 (前 10 名) ---\")\n",
        "for word, count in final_word_counts.most_common(10):\n",
        "    print(f\"'{word}': {count} 次\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XnGLvKzt_l6",
        "outputId": "22ac3410-8a27-4eeb-f302-e65148290e86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 詞頻統計結果 (前 10 名) ---\n",
            "'討論': 4 次\n",
            "'周星馳': 2 次\n",
            "'為何': 2 次\n",
            "'這麼': 2 次\n",
            "'欣賞羅志祥': 2 次\n",
            "'Re': 2 次\n",
            "'情報': 1 次\n",
            "'鏈鋸人': 1 次\n",
            "'劇場': 1 次\n",
            "'版蕾潔': 1 次\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "\n",
        "# 設置一個簡單的停用詞列表（Stop Words）\n",
        "# 這些詞通常頻率很高，但對文章主題貢獻小\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])"
      ],
      "metadata": {
        "id": "x0sb-cTEvqaj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_list = []\n",
        "\n",
        "# 從索引 1 到 10 (包含)\n",
        "for i in range(1, 11):\n",
        "    if i < len(articles_data) and 'title' in articles_data[i]:\n",
        "        title_text = articles_data[i]['title']\n",
        "\n",
        "        # 文本清理：移除標點符號和非詞語字符\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text)\n",
        "\n",
        "        # 進行結巴分詞\n",
        "        # lcut() 直接返回一個列表\n",
        "        words = jieba.lcut(cleaned_text, cut_all=False)\n",
        "\n",
        "        # 過濾停用詞和單個空白詞，並用空格重新連接成一個字符串，以便 TfidfVectorizer 處理\n",
        "        filtered_words = [\n",
        "            word.strip()\n",
        "            for word in words\n",
        "            if word.strip() and len(word.strip()) > 1 and word.strip() not in stopwords\n",
        "        ]\n",
        "\n",
        "        # TfidfVectorizer 需要的是字串形式的文檔\n",
        "        document = \" \".join(filtered_words)\n",
        "        document_list.append(document)\n",
        "\n",
        "# document_list 現在是一個列表，每個元素是經過處理的標題字串\n",
        "# print(document_list)"
      ],
      "metadata": {
        "id": "JSuthgyMvxEk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 初始化 TfidfVectorizer\n",
        "# TfidfVectorizer 會處理：\n",
        "#    a. 將文檔轉換為詞頻矩陣 (CountVectorizer 的工作)\n",
        "#    b. 計算 TF-IDF 權重 (TfidfTransformer 的工作)\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# 2. 進行擬合和轉換 (Fit and Transform)\n",
        "# tfidf_matrix 是一個稀疏矩陣 (sparse matrix)，包含所有文檔的 TF-IDF 權重\n",
        "tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "\n",
        "# 3. 獲取所有詞彙 (特徵名稱)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# 4. 將稀疏矩陣轉換為 NumPy 陣列，方便查看權重\n",
        "tfidf_array = tfidf_matrix.toarray()"
      ],
      "metadata": {
        "id": "c0z9BSeXv31l"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建一個字典來存儲每個詞彙及其在所有文檔中的 TF-IDF 平均權重\n",
        "avg_tfidf_scores = defaultdict(float)\n",
        "\n",
        "# 遍歷所有文檔的權重\n",
        "for doc_weights in tfidf_array:\n",
        "    # 遍歷單篇文檔中的所有詞彙及其權重\n",
        "    for i, weight in enumerate(doc_weights):\n",
        "        word = feature_names[i]\n",
        "        avg_tfidf_scores[word] += weight\n",
        "\n",
        "# 計算平均值\n",
        "num_documents = len(document_list)\n",
        "for word in avg_tfidf_scores:\n",
        "    avg_tfidf_scores[word] /= num_documents\n",
        "\n",
        "# 按權重降序排列\n",
        "sorted_avg_tfidf = sorted(avg_tfidf_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "print(\"--- 整個文檔集合中詞彙的 TF-IDF 平均權重 (前 10 名) ---\")\n",
        "for word, avg_weight in sorted_avg_tfidf[:10]:\n",
        "    print(f\"'{word}': {avg_weight:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk5-TJrhv5lq",
        "outputId": "3faa9f49-0b35-4e71-b7f2-9374a9e78589"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 整個文檔集合中詞彙的 TF-IDF 平均權重 (前 10 名) ---\n",
            "'周星馳': 0.0947\n",
            "'欣賞羅志祥': 0.0947\n",
            "'為何': 0.0947\n",
            "'這麼': 0.0947\n",
            "'re': 0.0753\n",
            "'godofsex': 0.0577\n",
            "'刪除': 0.0577\n",
            "'大婢': 0.0577\n",
            "'好看': 0.0577\n",
            "'有雷': 0.0577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "# 套件\n",
        "# ------------------------\n",
        "!pip install --quiet gspread google-auth openai gradio jieba scikit-learn\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import openai\n",
        "import os\n",
        "\n",
        "# 假設你的 Gemini API Key 叫 gemini_xxx\n",
        "os.environ['GEMINI_API_KEY'] = \"gemini\"\n",
        "\n",
        "# ------------------------\n",
        "# Google Sheet OAuth 授權（Colab）\n",
        "# ------------------------\n",
        "auth.authenticate_user()  # Colab 授權\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = '爬蟲資料'\n",
        "STAT_SHEET_NAME = '關鍵詞統計'\n",
        "\n",
        "# ------------------------\n",
        "# 停用詞\n",
        "# ------------------------\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])\n",
        "\n",
        "# ------------------------\n",
        "# PTT 爬蟲\n",
        "# ------------------------\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    # 找上一頁連結\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']  # 上一頁\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            last_index = int(match.group(1)) + 1  # 最新頁 = 上一頁+1\n",
        "            return last_index\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"無法取得起始頁頁碼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A (已刪除或不可存取)\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ------------------------\n",
        "# Sheet 存取\n",
        "# ------------------------\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['標題', '作者', '日期', '連結'])\n",
        "    for article in articles_data:\n",
        "        worksheet.append_row([article['title'], article['author'], article['date'], article['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        records = worksheet.get_all_records()\n",
        "        return records\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['詞彙', '平均 TF-IDF'])\n",
        "    for word, weight in keywords:\n",
        "        worksheet.append_row([word, weight])\n",
        "\n",
        "# ------------------------\n",
        "# TF-IDF 關鍵詞分析\n",
        "# ------------------------\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for record in records:\n",
        "        title_text = record['標題']\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text)\n",
        "        words = jieba.lcut(cleaned_text, cut_all=False)\n",
        "        filtered_words = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered_words))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_tfidf_scores = defaultdict(float)\n",
        "    for doc_weights in tfidf_array:\n",
        "        for i, weight in enumerate(doc_weights):\n",
        "            avg_tfidf_scores[feature_names[i]] += weight\n",
        "    num_documents = len(document_list)\n",
        "    for word in avg_tfidf_scores:\n",
        "        avg_tfidf_scores[word] /= num_documents\n",
        "    sorted_avg_tfidf = sorted(avg_tfidf_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    return sorted_avg_tfidf[:top_n]\n",
        "\n",
        "# ------------------------\n",
        "# Gemini API 洞察生成\n",
        "# ------------------------\n",
        "def generate_insights(keywords):\n",
        "    try:\n",
        "        openai.api_key = os.environ.get('GEMINI_API_KEY')\n",
        "        prompt = f\"以下是文章熱門關鍵詞：{', '.join([w for w,_ in keywords])}\\n\" \\\n",
        "                 f\"請生成 5 句洞察摘要 + 一段 120 字結論。\"\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gemini-1.5\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"API 呼叫失敗: {e}\"\n",
        "\n",
        "# ------------------------\n",
        "# Gradio 主程式\n",
        "# ------------------------\n",
        "def run_all(start_url=\"https://www.ptt.cc/bbs/movie/index.html\", top_n=10):\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    records = read_articles_from_sheet()\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    insights = generate_insights(top_keywords)\n",
        "\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ------------------------\n",
        "# Gradio 介面\n",
        "# ------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## PTT 電影版文章關鍵詞分析 + 洞察生成 (OAuth)\")\n",
        "    start_url_input = gr.Textbox(label=\"起始頁網址\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"熱門詞前 N 名\")\n",
        "    run_button = gr.Button(\"執行\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"詞彙\", \"平均 TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"洞察摘要 + 結論\")\n",
        "\n",
        "    run_button.click(\n",
        "        run_all,\n",
        "        inputs=[start_url_input, top_n_input],\n",
        "        outputs=[keywords_output, insights_output]\n",
        "    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "Pw239AxvfCdm",
        "outputId": "badead46-765d-4856-e895-26beb47fd63e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aaeb1d4d94d8094beb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aaeb1d4d94d8094beb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 先寫入爬蟲抓到的文章\n",
        "write_articles_to_sheet(articles)\n",
        "\n",
        "# 再讀取剛寫入的資料\n",
        "records = read_articles_from_sheet()\n",
        "print(f\"Sheet 讀取資料筆數: {len(records)}\")\n",
        "for r in records[:5]:  # 印前5筆確認\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xRXKehFz6co",
        "outputId": "6f8ba296-7f70-4c04-ec6b-bfc795d76647"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet 讀取資料筆數: 10\n",
            "{'標題': '[新聞] 「小辣椒」準備回歸漫威！葛妮絲派特洛', '作者': 'abiann', '日期': '10/24', '連結': 'https://www.ptt.cc/bbs/movie/M.1761321124.A.BBB.html'}\n",
            "{'標題': '[討論] 鏈鋸人 北美提前場 340萬', '作者': 'razzL1225', '日期': '10/25', '連結': 'https://www.ptt.cc/bbs/movie/M.1761321611.A.DD3.html'}\n",
            "{'標題': '[普好雷] 頭文字D 20週年 4K修復版', '作者': 'yulbin98', '日期': '10/25', '連結': 'https://www.ptt.cc/bbs/movie/M.1761323729.A.67A.html'}\n",
            "{'標題': '[新聞] 電影賠錢他還是賺 李奧納多《一戰再戰》', '作者': 'godofsex', '日期': '10/25', '連結': 'https://www.ptt.cc/bbs/movie/M.1761325800.A.291.html'}\n",
            "{'標題': '[好雷] 拿坡里的美麗傳說', '作者': 'steelgate', '日期': '10/25', '連結': 'https://www.ptt.cc/bbs/movie/M.1761326678.A.10C.html'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 從 Sheet 讀出的 records\n",
        "top_keywords = get_top_keywords(records, top_n=5)\n",
        "print(\"前 5 熱門關鍵詞:\")\n",
        "for word, score in top_keywords:\n",
        "    print(word, score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJjRAknI1-2J",
        "outputId": "0b0b02ac-31d0-4e81-bad3-fd9e0ebcca3f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "前 5 熱門關鍵詞:\n",
            "公告 0.11376588207522505\n",
            "340 0.09309790139542415\n",
            "北美 0.09309790139542415\n",
            "提前 0.09309790139542415\n",
            "鏈鋸人 0.09309790139542415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------\n",
        "# 套件安裝\n",
        "# ------------------------\n",
        "!pip install --quiet gspread google-auth openai gradio jieba scikit-learn\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import openai\n",
        "\n",
        "# 直接從環境變數讀取\n",
        "openai.api_key = os.environ.get('gemini')\n",
        "\n",
        "# ------------------------\n",
        "# Google Sheet OAuth 授權（Colab）\n",
        "# ------------------------\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = '爬蟲資料'\n",
        "STAT_SHEET_NAME = '關鍵詞統計'\n",
        "\n",
        "# ------------------------\n",
        "# 停用詞\n",
        "# ------------------------\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])\n",
        "\n",
        "# ------------------------\n",
        "# PTT 爬蟲\n",
        "# ------------------------\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']  # 上一頁\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1  # 最新頁 = 上一頁+1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"無法取得起始頁頁碼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A (已刪除或不可存取)\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ------------------------\n",
        "# Sheet 存取\n",
        "# ------------------------\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['標題', '作者', '日期', '連結'])\n",
        "    values = [[a['title'], a['author'], a['date'], a['href']] for a in articles_data]\n",
        "    worksheet.append_rows(values)\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['詞彙', '平均 TF-IDF'])\n",
        "    values = [[w, score] for w, score in keywords]\n",
        "    worksheet.append_rows(values)\n",
        "\n",
        "# ------------------------\n",
        "# TF-IDF 關鍵詞分析\n",
        "# ------------------------\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for record in records:\n",
        "        title_text = record['標題']\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', '', title_text)\n",
        "        words = jieba.lcut(cleaned_text, cut_all=False)\n",
        "        filtered_words = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered_words))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_tfidf_scores = defaultdict(float)\n",
        "    for doc_weights in tfidf_array:\n",
        "        for i, weight in enumerate(doc_weights):\n",
        "            avg_tfidf_scores[feature_names[i]] += weight\n",
        "    num_documents = len(document_list)\n",
        "    for word in avg_tfidf_scores:\n",
        "        avg_tfidf_scores[word] /= num_documents\n",
        "    sorted_avg_tfidf = sorted(avg_tfidf_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "    return sorted_avg_tfidf[:top_n]\n",
        "\n",
        "# ------------------------\n",
        "# Gemini API 洞察生成 (OpenAI >=1.0)\n",
        "# ------------------------\n",
        "def generate_insights(keywords):\n",
        "    try:\n",
        "        openai.api_key = os.environ.get('gemini')  # 從 Colab Secrets 讀取\n",
        "        prompt = f\"以下是文章熱門關鍵詞：{', '.join([w for w,_ in keywords])}\\n\" \\\n",
        "                 f\"請生成 5 句洞察摘要 + 一段 120 字結論。\"\n",
        "\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gemini-1.5\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"API 呼叫失敗: {e}\"\n",
        "\n",
        "# ------------------------\n",
        "# 主程式\n",
        "# ------------------------\n",
        "def run_all(start_url=\"https://www.ptt.cc/bbs/movie/index.html\", top_n=10):\n",
        "    print(\"抓取文章...\")\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    print(f\"抓取完成: {len(articles)} 篇文章\")\n",
        "\n",
        "    print(\"寫入 Sheet...\")\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    print(\"讀取 Sheet...\")\n",
        "    records = read_articles_from_sheet()\n",
        "\n",
        "    print(\"TF-IDF 分析熱門詞...\")\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    print(\"呼叫 Gemini API 生成洞察...\")\n",
        "    insights = generate_insights(top_keywords)\n",
        "    print(\"完成 ✅\")\n",
        "\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ------------------------\n",
        "# Gradio 介面\n",
        "# ------------------------\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## PTT 電影版文章關鍵詞分析 + 洞察生成 (OAuth)\")\n",
        "    start_url_input = gr.Textbox(label=\"起始頁網址\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"熱門詞前 N 名\")\n",
        "    run_button = gr.Button(\"執行\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"詞彙\", \"平均 TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"洞察摘要 + 結論\", lines=10)  # 多行文字\n",
        "\n",
        "    run_button.click(\n",
        "        run_all,\n",
        "        inputs=[start_url_input, top_n_input],\n",
        "        outputs=[keywords_output, insights_output]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "NnyE2ohC38f6",
        "outputId": "87164cf7-72eb-464f-d80a-bb4b9da7803a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://638a112a44e786f76c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://638a112a44e786f76c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gspread google-auth google-generativeai gradio jieba scikit-learn beautifulsoup4 requests"
      ],
      "metadata": {
        "id": "3Hoem4cld1R1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# 🔑 Gemini API 設定\n",
        "# ============================================================\n",
        "# ⚠️ 你要先在 Colab 左側選單「⚙️設定 → Secrets」中建立 key 名稱：gemini\n",
        "genai.configure(api_key=os.environ.get(\"gemini\"))\n",
        "\n",
        "# ============================================================\n",
        "# 🧾 Google Sheet OAuth 授權（Colab）\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 你的試算表網址\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "\n",
        "RAW_SHEET_NAME = '爬蟲資料'\n",
        "STAT_SHEET_NAME = '關鍵詞統計'\n",
        "\n",
        "# ============================================================\n",
        "# 🧹 停用詞\n",
        "# ============================================================\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])\n",
        "\n",
        "# ============================================================\n",
        "# 🕷️ PTT 爬蟲\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"⚠️ 無法取得起始頁頁碼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# 📊 Google Sheet 操作\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['標題', '作者', '日期', '連結'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['詞彙', '平均 TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# 🧠 TF-IDF 關鍵詞分析\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['標題']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# ✨ Gemini 洞察生成\n",
        "# ============================================================\n",
        "def generate_insights(keywords):\n",
        "    try:\n",
        "        prompt = (\n",
        "            f\"以下是 PTT 電影版熱門關鍵詞：{', '.join([w for w,_ in keywords])}\\n\"\n",
        "            f\"請用中文生成：\\n\"\n",
        "            f\"1. 五句洞察摘要（每句以「•」開頭）\\n\"\n",
        "            f\"2. 一段約 120 字的結論。\"\n",
        "        )\n",
        "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"❌ API 呼叫失敗：{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# ⚙️ 主流程\n",
        "# ============================================================\n",
        "def run_all(start_url=\"https://www.ptt.cc/bbs/movie/index.html\", top_n=10):\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    records = read_articles_from_sheet()\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    insights = generate_insights(top_keywords)\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ============================================================\n",
        "# 🎨 Gradio 介面\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🎬 PTT 電影版 關鍵詞分析 + Gemini 洞察摘要\")\n",
        "    start_url_input = gr.Textbox(label=\"起始頁網址\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"熱門詞前 N 名\")\n",
        "    run_button = gr.Button(\"執行分析\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"詞彙\", \"平均 TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"洞察摘要 + 結論\", lines=10)  # ✅ 多行顯示\n",
        "    run_button.click(run_all, inputs=[start_url_input, top_n_input], outputs=[keywords_output, insights_output])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "kGQusFP7euUT",
        "outputId": "46799afd-3902-42db-dc8c-eada32569b39"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://286fcf5a2c4dcf5b23.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://286fcf5a2c4dcf5b23.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# 🧾 Google Sheet OAuth 授權（Colab）\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = '爬蟲資料'\n",
        "STAT_SHEET_NAME = '關鍵詞統計'\n",
        "\n",
        "# ============================================================\n",
        "# 🧹 停用詞\n",
        "# ============================================================\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])\n",
        "\n",
        "# ============================================================\n",
        "# 🕷️ PTT 爬蟲\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"⚠️ 無法取得起始頁頁碼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# 📊 Google Sheet 操作\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['標題', '作者', '日期', '連結'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['詞彙', '平均 TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# 🧠 TF-IDF 關鍵詞分析\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['標題']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# ✨ Gemini 洞察生成（執行時輸入 API Key）\n",
        "# ============================================================\n",
        "def generate_insights(keywords, user_api_key):\n",
        "    if not user_api_key:\n",
        "        return \"⚠️ 請輸入有效的 Gemini API Key。\"\n",
        "\n",
        "    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent\"\n",
        "    prompt = (\n",
        "        f\"以下是 PTT 電影版熱門關鍵詞：{', '.join([w for w,_ in keywords])}\\n\"\n",
        "        f\"請用中文生成：\\n\"\n",
        "        f\"1. 五句洞察摘要（每句以「•」開頭）\\n\"\n",
        "        f\"2. 一段約 120 字的結論。\"\n",
        "    )\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": user_api_key}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data, timeout=60)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['candidates'][0]['content']['parts'][0]['text']\n",
        "        else:\n",
        "            return f\"❌ API 錯誤: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ API 呼叫失敗：{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# ⚙️ 主流程\n",
        "# ============================================================\n",
        "def run_all(start_url, top_n, api_key):\n",
        "    articles = fetch_ptt_articles(start_url, pages=10)\n",
        "    write_articles_to_sheet(articles)\n",
        "\n",
        "    records = read_articles_from_sheet()\n",
        "    top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "    write_keywords_to_sheet(top_keywords)\n",
        "\n",
        "    insights = generate_insights(top_keywords, api_key)\n",
        "    return top_keywords, insights\n",
        "\n",
        "# ============================================================\n",
        "# 🎨 Gradio 介面\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🎬 PTT 電影版 關鍵詞分析 + Gemini 洞察摘要 (API Key 輸入版)\")\n",
        "    api_key_input = gr.Textbox(label=\"🔑 請輸入你的 Gemini API Key\", type=\"password\", placeholder=\"AIza 或 g- 開頭的金鑰\")\n",
        "    start_url_input = gr.Textbox(label=\"起始頁網址\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "    top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"熱門詞前 N 名\")\n",
        "    run_button = gr.Button(\"🚀 執行分析\")\n",
        "    keywords_output = gr.Dataframe(headers=[\"詞彙\", \"平均 TF-IDF\"])\n",
        "    insights_output = gr.Textbox(label=\"洞察摘要 + 結論\", lines=10)\n",
        "\n",
        "    run_button.click(run_all, inputs=[start_url_input, top_n_input, api_key_input], outputs=[keywords_output, insights_output])\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "8TiBVzEYnX6i",
        "outputId": "b1326e93-5624-4d13-c85b-515fc7f15d7c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://162d7484de2755df24.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://162d7484de2755df24.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import jieba\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import gradio as gr\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# 🧾 Google Sheet 授權\n",
        "# ============================================================\n",
        "auth.authenticate_user()\n",
        "creds, _ = default(scopes=['https://www.googleapis.com/auth/spreadsheets'])\n",
        "gc = gspread.authorize(creds)\n",
        "SHEET_URL = 'https://docs.google.com/spreadsheets/d/1ZrA1VIiUl2lJ1SXIdSPq1jRvIyqI1LsbiJ77BoVb8Tg/edit#gid=0'\n",
        "sh = gc.open_by_url(SHEET_URL)\n",
        "RAW_SHEET_NAME = '爬蟲資料'\n",
        "STAT_SHEET_NAME = '關鍵詞統計'\n",
        "\n",
        "# ============================================================\n",
        "# 🧹 停用詞\n",
        "# ============================================================\n",
        "stopwords = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和', '討論', '分享'])\n",
        "\n",
        "# ============================================================\n",
        "# 🕷️ PTT 爬蟲\n",
        "# ============================================================\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\n",
        "                  '(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "def extract_index_split(url):\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def get_last_index(url):\n",
        "    response = requests.get(url, headers=headers, timeout=5)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    btns = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if btns:\n",
        "        prev_link = btns.find_all('a')[1]['href']\n",
        "        match = re.search(r'index(\\d+).html', prev_link)\n",
        "        if match:\n",
        "            return int(match.group(1)) + 1\n",
        "    return None\n",
        "\n",
        "def fetch_ptt_articles(start_url, pages=10):\n",
        "    articles_data = []\n",
        "    START_INDEX = extract_index_split(start_url)\n",
        "    if START_INDEX is None:\n",
        "        START_INDEX = get_last_index(start_url)\n",
        "    if START_INDEX is None:\n",
        "        print(\"⚠️ 無法取得起始頁頁碼\")\n",
        "        return []\n",
        "\n",
        "    BASE_URL = \"https://www.ptt.cc/bbs/movie/index\"\n",
        "    stop_index = START_INDEX - pages\n",
        "    for idx in range(START_INDEX, stop_index, -1):\n",
        "        url = f\"{BASE_URL}{idx}.html\"\n",
        "        response = requests.get(url, headers=headers, timeout=5)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        for article in soup.find_all('div', class_='r-ent'):\n",
        "            title_tag = article.find('div', class_='title').find('a')\n",
        "            if title_tag:\n",
        "                title = title_tag.text.strip()\n",
        "                href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "            else:\n",
        "                title = article.find('div', class_='title').text.strip()\n",
        "                href = \"N/A\"\n",
        "            author = article.find('div', class_='author').text.strip()\n",
        "            date = article.find('div', class_='date').text.strip()\n",
        "            articles_data.append({\n",
        "                'title': title,\n",
        "                'author': author,\n",
        "                'date': date,\n",
        "                'href': href\n",
        "            })\n",
        "    return articles_data\n",
        "\n",
        "# ============================================================\n",
        "# 📊 Google Sheet 操作\n",
        "# ============================================================\n",
        "def write_articles_to_sheet(articles_data):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=RAW_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['標題', '作者', '日期', '連結'])\n",
        "    for a in articles_data:\n",
        "        worksheet.append_row([a['title'], a['author'], a['date'], a['href']])\n",
        "\n",
        "def read_articles_from_sheet():\n",
        "    try:\n",
        "        worksheet = sh.worksheet(RAW_SHEET_NAME)\n",
        "        return worksheet.get_all_records()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        return []\n",
        "\n",
        "def write_keywords_to_sheet(keywords):\n",
        "    try:\n",
        "        worksheet = sh.worksheet(STAT_SHEET_NAME)\n",
        "        worksheet.clear()\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = sh.add_worksheet(title=STAT_SHEET_NAME, rows=\"100\", cols=\"20\")\n",
        "    worksheet.append_row(['詞彙', '平均 TF-IDF'])\n",
        "    for w, v in keywords:\n",
        "        worksheet.append_row([w, v])\n",
        "\n",
        "# ============================================================\n",
        "# 🧠 TF-IDF 分析\n",
        "# ============================================================\n",
        "def get_top_keywords(records, top_n=10):\n",
        "    document_list = []\n",
        "    for r in records:\n",
        "        text = r['標題']\n",
        "        cleaned = re.sub(r'[^\\w\\s]', '', text)\n",
        "        words = jieba.lcut(cleaned, cut_all=False)\n",
        "        filtered = [w.strip() for w in words if w.strip() and len(w.strip())>1 and w.strip() not in stopwords]\n",
        "        document_list.append(\" \".join(filtered))\n",
        "\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(document_list)\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "    tfidf_array = tfidf_matrix.toarray()\n",
        "\n",
        "    avg_scores = defaultdict(float)\n",
        "    for doc in tfidf_array:\n",
        "        for i, weight in enumerate(doc):\n",
        "            avg_scores[feature_names[i]] += weight\n",
        "    num_docs = len(document_list)\n",
        "    for w in avg_scores:\n",
        "        avg_scores[w] /= num_docs\n",
        "    sorted_avg = sorted(avg_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_avg[:top_n]\n",
        "\n",
        "# ============================================================\n",
        "# 🤖 Gemini API 洞察生成\n",
        "# ============================================================\n",
        "def generate_insights(keywords, user_api_key):\n",
        "    if not user_api_key:\n",
        "        return \"⚠️ 請輸入有效的 Gemini API Key。\"\n",
        "\n",
        "    GEMINI_API_URL = \"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent\"\n",
        "    prompt = (\n",
        "        f\"以下是 PTT 電影版熱門關鍵詞：{', '.join([w for w,_ in keywords])}\\n\"\n",
        "        f\"請用中文生成：\\n\"\n",
        "        f\"1. 五句洞察摘要（每句以「•」開頭）\\n\"\n",
        "        f\"2. 一段約 120 字的結論。\"\n",
        "    )\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {\"key\": user_api_key}\n",
        "    data = {\"contents\": [{\"parts\": [{\"text\": prompt}]}]}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(GEMINI_API_URL, headers=headers, params=params, json=data, timeout=60)\n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result['candidates'][0]['content']['parts'][0]['text']\n",
        "        else:\n",
        "            return f\"❌ API 錯誤: {response.status_code} - {response.text}\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ API 呼叫失敗：{e}\"\n",
        "\n",
        "# ============================================================\n",
        "# ⚙️ Gradio 多分頁介面（限制爬蟲頁數）\n",
        "# ============================================================\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🎬 PTT 電影版 關鍵詞分析系統 (多分頁介面)\")\n",
        "\n",
        "    with gr.Tab(\"🕷️ 爬蟲結果\"):\n",
        "        start_url_input = gr.Textbox(label=\"PTT 起始頁網址\", value=\"https://www.ptt.cc/bbs/movie/index.html\")\n",
        "        page_slider = gr.Slider(1, 5, value=1, step=1, label=\"爬取頁數（建議 1～3 頁）\")\n",
        "        run_button = gr.Button(\"🚀 執行爬蟲\")\n",
        "        articles_output = gr.Dataframe(headers=[\"標題\", \"作者\", \"日期\", \"連結\"], label=\"爬蟲結果\")\n",
        "\n",
        "        def run_crawler(start_url, pages):\n",
        "            gr.Info(f\"開始爬取 {pages} 頁資料，請稍候...\")\n",
        "            articles = fetch_ptt_articles(start_url, pages=pages)\n",
        "            if not articles:\n",
        "                return []\n",
        "            write_articles_to_sheet(articles)\n",
        "            data = [[a['title'], a['author'], a['date'], a['href']] for a in articles]\n",
        "            gr.Info(f\"✅ 成功爬取 {len(data)} 筆文章！\")\n",
        "            return data\n",
        "\n",
        "        run_button.click(run_crawler, inputs=[start_url_input, page_slider], outputs=articles_output)\n",
        "\n",
        "    with gr.Tab(\"🔠 熱門詞分析\"):\n",
        "        top_n_input = gr.Slider(1, 20, value=10, step=1, label=\"熱門詞前 N 名\")\n",
        "        run_tfidf_button = gr.Button(\"📊 執行分析\")\n",
        "        keywords_output = gr.Dataframe(headers=[\"詞彙\", \"平均 TF-IDF\"], label=\"TF-IDF 結果\")\n",
        "\n",
        "        def run_tfidf(top_n):\n",
        "            gr.Info(\"📈 正在進行 TF-IDF 分析...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"⚠️ 尚未有爬蟲資料，請先到第一頁執行爬蟲！\")\n",
        "                return []\n",
        "            top_keywords = get_top_keywords(records, top_n=top_n)\n",
        "            write_keywords_to_sheet(top_keywords)\n",
        "            gr.Info(\"✅ 分析完成！\")\n",
        "            return top_keywords\n",
        "\n",
        "        run_tfidf_button.click(run_tfidf, inputs=top_n_input, outputs=keywords_output)\n",
        "\n",
        "    with gr.Tab(\"🤖 AI 洞察摘要\"):\n",
        "        api_key_input = gr.Textbox(label=\"🔑 請輸入你的 Gemini API Key\", type=\"password\", placeholder=\"AIza 或 g- 開頭的金鑰\")\n",
        "        run_ai_button = gr.Button(\"✨ 生成摘要\")\n",
        "        ai_output = gr.Textbox(label=\"AI 洞察摘要 + 結論\", lines=12)\n",
        "\n",
        "        def run_ai(api_key):\n",
        "            gr.Info(\"🤖 正在請求 Gemini API...\")\n",
        "            records = read_articles_from_sheet()\n",
        "            if not records:\n",
        "                gr.Warning(\"⚠️ 尚未有爬蟲資料，請先到第一頁執行爬蟲！\")\n",
        "                return \"⚠️ 尚無資料\"\n",
        "            top_keywords = get_top_keywords(records, top_n=10)\n",
        "            insights = generate_insights(top_keywords, api_key)\n",
        "            return insights\n",
        "\n",
        "        run_ai_button.click(run_ai, inputs=api_key_input, outputs=ai_output)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "X6oDcllJqB5V",
        "outputId": "85739867-3001-4f6d-f796-0b2e8998b3ba"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a76869bbcf46b385c3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a76869bbcf46b385c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}